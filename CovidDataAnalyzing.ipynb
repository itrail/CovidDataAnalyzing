{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovidDataAnalyzing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRFovqPOXUCLfUfm8BSlWE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itrail/CovidDataAnalyzing/blob/main/CovidDataAnalyzing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvzhk04YYklr",
        "outputId": "d994fea1-db59-4a87-815c-710ed1c0475a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5edWpu_mXuR3"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import json\n",
        "from itertools import islice\n",
        "from datetime import timedelta, date, datetime, timezone\n",
        "from openpyxl import load_workbook\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objects as go\n",
        "from numpy import mean, average\n",
        "import random"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHG73YdD3lu7"
      },
      "source": [
        "#creating json file with excel covid19 data \n",
        "\n",
        "def create_json():\n",
        "  covid_data = []\n",
        "  #open a spreadsheet and sheet\n",
        "  wb = load_workbook('covid19.xlsx')\n",
        "  sheet = wb['newCases2021']\n",
        "\n",
        "  #copy row by row with loop\n",
        "  for row in islice(sheet.values, 1, sheet.max_row):\n",
        "      data = OrderedDict()\n",
        "      day = row[0]\n",
        "      day  = day.strftime(\"%d.%m.%Y\")\n",
        "      data['date'] = day\n",
        "      data['cases'] = str(row[1])\n",
        "      covid_data.append(data)\n",
        "  newlist = sorted(covid_data, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "  j = json.dumps(newlist) \n",
        "\n",
        "  #save data in json file\n",
        "  with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vmjpa4BCZsP"
      },
      "source": [
        "def update_json():\n",
        "  with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "    json_object = json.load(f)\n",
        "    f.close()\n",
        "  #open a spreadsheet and sheet\n",
        "  wb = load_workbook('covid19.xlsx')\n",
        "  sheet = wb['newCases2020']\n",
        "\n",
        "  #copy row by row with loop\n",
        "  for row in islice(sheet.values, 1, sheet.max_row):\n",
        "      data = OrderedDict()\n",
        "      day = row[0]\n",
        "      day  = day.strftime(\"%d.%m.%Y\")\n",
        "      data['date'] = day\n",
        "      data['cases'] = str(row[1])\n",
        "      json_object.append(data)\n",
        "  newlist = sorted(json_object, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "  j = json.dumps(newlist) \n",
        "  with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)\n",
        "\n",
        "update_json()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLhM0pGa9TZJ"
      },
      "source": [
        "#create_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgwePQKFsvkw",
        "outputId": "c5fd7d78-35ae-46e9-b96e-d2fb5d90644d"
      },
      "source": [
        "import requests\n",
        "\n",
        "#data actualization\n",
        "covid_data=[]\n",
        "#url of webpage with covid data\n",
        "url = 'https://www.worldometers.info/coronavirus/country/poland/'\n",
        "\n",
        "#get the page content\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "#find lists, here's data about new cases and deaths\n",
        "data_iterator = iter(soup.find_all('li', {'class': 'news_li'}))\n",
        "\n",
        "#delta is variable to substracting date, if its before 12 data probably hasn't been updated\n",
        "now = datetime.now(timezone(timedelta(hours=2)))\n",
        "if now.hour >= 11:\n",
        "  delta = 0\n",
        "else:\n",
        "  delta = 1\n",
        "\n",
        "#getting todays date\n",
        "today = date.today()\n",
        "#loop for all obtained data\n",
        "with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "  json_object = json.load(f)\n",
        "  f.close()\n",
        "days = []\n",
        "for item in json_object:\n",
        "  days.append(item['date'])\n",
        "iterator = 0;\n",
        "while True:\n",
        "    try:\n",
        "      #substracting dates\n",
        "      day  = today - timedelta(days=delta)\n",
        "      day  = day .strftime(\"%d.%m.%Y\")\n",
        "      #getting the next row and cleaning the info\n",
        "      newData = next(data_iterator).text\n",
        "      newData = newData.split(\" new cases and \", 1)\n",
        "      newCases = newData[0]\n",
        "      newDeaths= newData[1].replace(' new deaths in Poland\\xa0[source]', '')\n",
        "      newCases = newCases.replace(',', '')\n",
        "      data = {\"date\": day, \"cases\": newCases, }\n",
        "\n",
        "      #saving data if is not in json file\n",
        "      if data['date'] not in days:\n",
        "        print(data)\n",
        "        json_object.append(data)\n",
        "        \n",
        "      print(day  + \": \" + newCases)\n",
        "      delta += 1\n",
        "      iterator += 1\n",
        "    except StopIteration:\n",
        "      break\n",
        "\n",
        "#sorting by dates\n",
        "newlist = sorted(json_object, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "j = json.dumps(newlist) \n",
        "with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "09.06.2021: 428\n",
            "08.06.2021: 532\n",
            "07.06.2021: 195\n",
            "06.06.2021: 310\n",
            "05.06.2021: 415\n",
            "04.06.2021: 317\n",
            "03.06.2021: 572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQZjLbxD6v5"
      },
      "source": [
        "#print the data\n",
        "with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "  json_object = json.load(f)\n",
        "  f.close()\n",
        "\n",
        "cases = []\n",
        "days = []\n",
        "for item in json_object:\n",
        "  print(item)\n",
        "  cases.append(int(item['cases']))\n",
        "  days.append(item['date'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzUAqh7pkDjV",
        "outputId": "f83ebb2c-6553-4be3-e713-e5de56aa83c4"
      },
      "source": [
        "average = 0\n",
        "for n in range(1, 8):\n",
        "  i = -8 + n\n",
        "  average = ((n-1)*average+ cases[i])/n\n",
        "  print(str(cases[i]) + \":\" + str(average))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "572:572.0\n",
            "317:444.5\n",
            "415:434.6666666666667\n",
            "310:403.5\n",
            "195:361.8\n",
            "532:390.1666666666667\n",
            "428:395.57142857142856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAb7jTvuoIuD",
        "outputId": "61d151aa-5d92-49da-bdda-51e79f3214e4"
      },
      "source": [
        "today = date.today()\n",
        "n=0\n",
        "sum=0\n",
        "for day in days:\n",
        "  date_dt2 = datetime.strptime(day, '%d.%m.%Y')\n",
        "  if date_dt2.month == today.month-1:\n",
        "    n=n+1\n",
        "    #print(cases[days.index(day)])\n",
        "    sum=sum+cases[days.index(day)]\n",
        "    \n",
        "last_month_avg = sum/n\n",
        "print(last_month_avg)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1470.532258064516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "oqR51LuIh6a2",
        "outputId": "91779cbc-8b6f-4ed9-8a7a-245afbb9fb16"
      },
      "source": [
        "#plotting covid cases\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=days, y=cases, name='Covid Cases', mode='markers+lines'))\n",
        "fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [last_month_avg], name='Last month average', mode='lines'))\n",
        "#fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [average], name='Last 7 days average', mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [mean(cases)], name='Todays Average', mode='lines'))\n",
        "fig.update_layout(width=1300, height=500, title='Number of covid19 cases by day in 2021', xaxis_title='Days', yaxis_title='Cases')\n",
        "fig.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ad5a6096-2f97-44b9-bb00-44f2fab8ed74\" class=\"plotly-graph-div\" style=\"height:500px; width:1300px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ad5a6096-2f97-44b9-bb00-44f2fab8ed74\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ad5a6096-2f97-44b9-bb00-44f2fab8ed74',\n",
              "                        [{\"mode\": \"markers+lines\", \"name\": \"Covid Cases\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\"], \"y\": [0, 0, 0, 0, 0, 0, 1, 0, 4, 1, 5, 6, 5, 9, 20, 17, 36, 21, 52, 61, 49, 68, 70, 111, 98, 116, 152, 150, 170, 168, 249, 224, 193, 256, 243, 392, 437, 244, 475, 311, 435, 357, 370, 380, 401, 318, 260, 268, 380, 336, 457, 334, 515, 306, 263, 313, 342, 381, 381, 344, 285, 316, 422, 300, 228, 270, 318, 313, 406, 311, 303, 337, 288, 345, 330, 556, 322, 411, 401, 241, 272, 356, 382, 471, 403, 472, 316, 361, 341, 443, 396, 352, 333, 412, 219, 374, 236, 292, 361, 362, 576, 575, 599, 400, 282, 359, 376, 440, 375, 396, 407, 450, 314, 352, 309, 311, 296, 300, 294, 298, 276, 319, 193, 247, 239, 382, 371, 259, 314, 231, 205, 257, 277, 262, 265, 305, 370, 299, 267, 264, 333, 353, 339, 358, 279, 399, 380, 418, 458, 584, 443, 337, 502, 512, 615, 657, 658, 548, 575, 680, 640, 726, 809, 843, 624, 619, 551, 715, 811, 825, 778, 594, 595, 597, 735, 767, 903, 900, 581, 548, 763, 729, 887, 791, 759, 631, 502, 550, 595, 612, 691, 567, 437, 302, 400, 421, 506, 594, 603, 502, 377, 605, 600, 837, 757, 1002, 910, 748, 711, 974, 1136, 1587, 1584, 1350, 1306, 1326, 1552, 1967, 2292, 2367, 1934, 2006, 2236, 3003, 4280, 4739, 5300, 4178, 4394, 5068, 6526, 8099, 7705, 9622, 8536, 7482, 9291, 10040, 12107, 13632, 13628, 11742, 10241, 16300, 18820, 20156, 21629, 21897, 17171, 15578, 19364, 24692, 27143, 27086, 27875, 24785, 21713, 25454, 25221, 22683, 24051, 25571, 21854, 20816, 19152, 19883, 23975, 22464, 24213, 17856, 15002, 32733, 15356, 16690, 17304, 15177, 11482, 5736, 9113, 13823, 14863, 13236, 12427, 9176, 4421, 8310, 12166, 13750, 13105, 11499, 8976, 4896, 6874, 12455, 11953, 11010, 11246, 8590, 4633, 7192, 12358, 13115, 9081, 4878, 3842, 3211, 7624, 12780, 13464, 10896, 7006, 5782, 4385, 7596, 14220, 12119, 8763, 10744, 9133, 4863, 5394, 9126, 9436, 7979, 7292, 5970, 3332, 4890, 6943, 7008, 6693, 6304, 4566, 2674, 4603, 6790, 7153, 6145, 5864, 4711, 2504, 4326, 6801, 6495, 6053, 5966, 4725, 2431, 3999, 6960, 7013, 6378, 6585, 5334, 2542, 5176, 8699, 9074, 8772, 8509, 7040, 3891, 6304, 12147, 12143, 11536, 12097, 10101, 4786, 7936, 15698, 15253, 15831, 14855, 13569, 6169, 9953, 17277, 21111, 18873, 21063, 17272, 10895, 14394, 25053, 27274, 25996, 26456, 21850, 14579, 16740, 30802, 34150, 35145, 31759, 29266, 16973, 20862, 32891, 35253, 30541, 28073, 22958, 9921, 8246, 14908, 27890, 28499, 24892, 21733, 12016, 13203, 21266, 21126, 17846, 15786, 12151, 7302, 9244, 13922, 12763, 10866, 9510, 7224, 3467, 5711, 8893, 8426, 6789, 6475, 4616, 2523, 2296, 3899, 6427, 6047, 4771, 3856, 2031, 3097, 3948, 3694, 3289, 2897, 2169, 1111, 1727, 2348, 2087, 1678, 1517, 1075, 559, 1000, 1267, 1227, 946, 775, 579, 333, 588, 659, 572, 317, 415, 310, 195, 532, 428]}, {\"mode\": \"lines\", \"name\": \"Last month average\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\"], \"y\": [1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516]}, {\"mode\": \"lines\", \"name\": \"Todays Average\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\"], \"y\": [6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036, 6132.829424307036]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Number of covid19 cases by day in 2021\"}, \"width\": 1300, \"xaxis\": {\"title\": {\"text\": \"Days\"}}, \"yaxis\": {\"title\": {\"text\": \"Cases\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ad5a6096-2f97-44b9-bb00-44f2fab8ed74');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDoOI7OvBEwe"
      },
      "source": [
        "#libraries for creating neural network\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWPAcZn7xGAA"
      },
      "source": [
        "def split_sequence(seq, n_steps):\n",
        "  IN = []\n",
        "  OUT = []\n",
        "  for i in range(len(seq)-n_steps):\n",
        "    TEMP = []\n",
        "    for j in range(i,n_steps):\n",
        "      TEMP.append(seq[j])\n",
        "    IN.append(TEMP)\n",
        "    OUT.append(seq[j+1])\n",
        "    n_steps=n_steps+1\n",
        "  return IN,OUT"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMCkOinmxJCG",
        "outputId": "036c48c5-cfd8-4767-d9cd-8b97bbd61cf9"
      },
      "source": [
        "#splitting the sequences of 14-days covid datasets\n",
        "n = 14\n",
        "X, Y = split_sequence(cases, n)\n",
        "\n",
        "#splitting for validation data and training data\n",
        "\n",
        "Validation_X = []\n",
        "Validation_Y = []\n",
        "i=0\n",
        "limit = 0.2*len(X)\n",
        "while(i!=limit):\n",
        "    r=random.randint(1,len(X))-1\n",
        "    Validation_X.append(X[r])\n",
        "    Validation_Y.append(Y[r])\n",
        "    del X[r], Y[r]\n",
        "    i+=1\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "Validation_X = np.array(Validation_X)\n",
        "Validation_Y = np.array(Validation_Y)\n",
        "#for i in range(len(Validation_X)):\n",
        "#    print(Validation_X[i], Validation_Y[i])\n",
        "\n",
        "#print of training data set\n",
        "for i in range(len(X)):\n",
        "    print(X[i], Y[i])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 4 1 5 6 5 9] 20\n",
            "[ 0  0  0  0  0  1  0  4  1  5  6  5  9 20] 17\n",
            "[ 0  0  0  0  1  0  4  1  5  6  5  9 20 17] 36\n",
            "[ 0  0  0  1  0  4  1  5  6  5  9 20 17 36] 21\n",
            "[ 0  1  0  4  1  5  6  5  9 20 17 36 21 52] 61\n",
            "[ 1  0  4  1  5  6  5  9 20 17 36 21 52 61] 49\n",
            "[ 0  4  1  5  6  5  9 20 17 36 21 52 61 49] 68\n",
            "[ 4  1  5  6  5  9 20 17 36 21 52 61 49 68] 70\n",
            "[ 1  5  6  5  9 20 17 36 21 52 61 49 68 70] 111\n",
            "[  5   6   5   9  20  17  36  21  52  61  49  68  70 111] 98\n",
            "[  6   5   9  20  17  36  21  52  61  49  68  70 111  98] 116\n",
            "[  5   9  20  17  36  21  52  61  49  68  70 111  98 116] 152\n",
            "[  9  20  17  36  21  52  61  49  68  70 111  98 116 152] 150\n",
            "[ 20  17  36  21  52  61  49  68  70 111  98 116 152 150] 170\n",
            "[ 17  36  21  52  61  49  68  70 111  98 116 152 150 170] 168\n",
            "[ 36  21  52  61  49  68  70 111  98 116 152 150 170 168] 249\n",
            "[ 21  52  61  49  68  70 111  98 116 152 150 170 168 249] 224\n",
            "[ 52  61  49  68  70 111  98 116 152 150 170 168 249 224] 193\n",
            "[ 61  49  68  70 111  98 116 152 150 170 168 249 224 193] 256\n",
            "[ 49  68  70 111  98 116 152 150 170 168 249 224 193 256] 243\n",
            "[ 70 111  98 116 152 150 170 168 249 224 193 256 243 392] 437\n",
            "[ 98 116 152 150 170 168 249 224 193 256 243 392 437 244] 475\n",
            "[116 152 150 170 168 249 224 193 256 243 392 437 244 475] 311\n",
            "[152 150 170 168 249 224 193 256 243 392 437 244 475 311] 435\n",
            "[150 170 168 249 224 193 256 243 392 437 244 475 311 435] 357\n",
            "[170 168 249 224 193 256 243 392 437 244 475 311 435 357] 370\n",
            "[168 249 224 193 256 243 392 437 244 475 311 435 357 370] 380\n",
            "[249 224 193 256 243 392 437 244 475 311 435 357 370 380] 401\n",
            "[224 193 256 243 392 437 244 475 311 435 357 370 380 401] 318\n",
            "[193 256 243 392 437 244 475 311 435 357 370 380 401 318] 260\n",
            "[256 243 392 437 244 475 311 435 357 370 380 401 318 260] 268\n",
            "[243 392 437 244 475 311 435 357 370 380 401 318 260 268] 380\n",
            "[392 437 244 475 311 435 357 370 380 401 318 260 268 380] 336\n",
            "[437 244 475 311 435 357 370 380 401 318 260 268 380 336] 457\n",
            "[244 475 311 435 357 370 380 401 318 260 268 380 336 457] 334\n",
            "[311 435 357 370 380 401 318 260 268 380 336 457 334 515] 306\n",
            "[435 357 370 380 401 318 260 268 380 336 457 334 515 306] 263\n",
            "[357 370 380 401 318 260 268 380 336 457 334 515 306 263] 313\n",
            "[370 380 401 318 260 268 380 336 457 334 515 306 263 313] 342\n",
            "[380 401 318 260 268 380 336 457 334 515 306 263 313 342] 381\n",
            "[401 318 260 268 380 336 457 334 515 306 263 313 342 381] 381\n",
            "[318 260 268 380 336 457 334 515 306 263 313 342 381 381] 344\n",
            "[260 268 380 336 457 334 515 306 263 313 342 381 381 344] 285\n",
            "[268 380 336 457 334 515 306 263 313 342 381 381 344 285] 316\n",
            "[380 336 457 334 515 306 263 313 342 381 381 344 285 316] 422\n",
            "[457 334 515 306 263 313 342 381 381 344 285 316 422 300] 228\n",
            "[334 515 306 263 313 342 381 381 344 285 316 422 300 228] 270\n",
            "[515 306 263 313 342 381 381 344 285 316 422 300 228 270] 318\n",
            "[342 381 381 344 285 316 422 300 228 270 318 313 406 311] 303\n",
            "[381 381 344 285 316 422 300 228 270 318 313 406 311 303] 337\n",
            "[381 344 285 316 422 300 228 270 318 313 406 311 303 337] 288\n",
            "[285 316 422 300 228 270 318 313 406 311 303 337 288 345] 330\n",
            "[316 422 300 228 270 318 313 406 311 303 337 288 345 330] 556\n",
            "[300 228 270 318 313 406 311 303 337 288 345 330 556 322] 411\n",
            "[270 318 313 406 311 303 337 288 345 330 556 322 411 401] 241\n",
            "[313 406 311 303 337 288 345 330 556 322 411 401 241 272] 356\n",
            "[406 311 303 337 288 345 330 556 322 411 401 241 272 356] 382\n",
            "[311 303 337 288 345 330 556 322 411 401 241 272 356 382] 471\n",
            "[303 337 288 345 330 556 322 411 401 241 272 356 382 471] 403\n",
            "[337 288 345 330 556 322 411 401 241 272 356 382 471 403] 472\n",
            "[345 330 556 322 411 401 241 272 356 382 471 403 472 316] 361\n",
            "[330 556 322 411 401 241 272 356 382 471 403 472 316 361] 341\n",
            "[411 401 241 272 356 382 471 403 472 316 361 341 443 396] 352\n",
            "[401 241 272 356 382 471 403 472 316 361 341 443 396 352] 333\n",
            "[272 356 382 471 403 472 316 361 341 443 396 352 333 412] 219\n",
            "[356 382 471 403 472 316 361 341 443 396 352 333 412 219] 374\n",
            "[382 471 403 472 316 361 341 443 396 352 333 412 219 374] 236\n",
            "[472 316 361 341 443 396 352 333 412 219 374 236 292 361] 362\n",
            "[316 361 341 443 396 352 333 412 219 374 236 292 361 362] 576\n",
            "[361 341 443 396 352 333 412 219 374 236 292 361 362 576] 575\n",
            "[352 333 412 219 374 236 292 361 362 576 575 599 400 282] 359\n",
            "[412 219 374 236 292 361 362 576 575 599 400 282 359 376] 440\n",
            "[219 374 236 292 361 362 576 575 599 400 282 359 376 440] 375\n",
            "[374 236 292 361 362 576 575 599 400 282 359 376 440 375] 396\n",
            "[236 292 361 362 576 575 599 400 282 359 376 440 375 396] 407\n",
            "[292 361 362 576 575 599 400 282 359 376 440 375 396 407] 450\n",
            "[361 362 576 575 599 400 282 359 376 440 375 396 407 450] 314\n",
            "[362 576 575 599 400 282 359 376 440 375 396 407 450 314] 352\n",
            "[576 575 599 400 282 359 376 440 375 396 407 450 314 352] 309\n",
            "[575 599 400 282 359 376 440 375 396 407 450 314 352 309] 311\n",
            "[599 400 282 359 376 440 375 396 407 450 314 352 309 311] 296\n",
            "[400 282 359 376 440 375 396 407 450 314 352 309 311 296] 300\n",
            "[282 359 376 440 375 396 407 450 314 352 309 311 296 300] 294\n",
            "[359 376 440 375 396 407 450 314 352 309 311 296 300 294] 298\n",
            "[376 440 375 396 407 450 314 352 309 311 296 300 294 298] 276\n",
            "[440 375 396 407 450 314 352 309 311 296 300 294 298 276] 319\n",
            "[396 407 450 314 352 309 311 296 300 294 298 276 319 193] 247\n",
            "[407 450 314 352 309 311 296 300 294 298 276 319 193 247] 239\n",
            "[314 352 309 311 296 300 294 298 276 319 193 247 239 382] 371\n",
            "[352 309 311 296 300 294 298 276 319 193 247 239 382 371] 259\n",
            "[309 311 296 300 294 298 276 319 193 247 239 382 371 259] 314\n",
            "[311 296 300 294 298 276 319 193 247 239 382 371 259 314] 231\n",
            "[300 294 298 276 319 193 247 239 382 371 259 314 231 205] 257\n",
            "[294 298 276 319 193 247 239 382 371 259 314 231 205 257] 277\n",
            "[298 276 319 193 247 239 382 371 259 314 231 205 257 277] 262\n",
            "[276 319 193 247 239 382 371 259 314 231 205 257 277 262] 265\n",
            "[193 247 239 382 371 259 314 231 205 257 277 262 265 305] 370\n",
            "[247 239 382 371 259 314 231 205 257 277 262 265 305 370] 299\n",
            "[239 382 371 259 314 231 205 257 277 262 265 305 370 299] 267\n",
            "[382 371 259 314 231 205 257 277 262 265 305 370 299 267] 264\n",
            "[371 259 314 231 205 257 277 262 265 305 370 299 267 264] 333\n",
            "[314 231 205 257 277 262 265 305 370 299 267 264 333 353] 339\n",
            "[231 205 257 277 262 265 305 370 299 267 264 333 353 339] 358\n",
            "[205 257 277 262 265 305 370 299 267 264 333 353 339 358] 279\n",
            "[257 277 262 265 305 370 299 267 264 333 353 339 358 279] 399\n",
            "[277 262 265 305 370 299 267 264 333 353 339 358 279 399] 380\n",
            "[265 305 370 299 267 264 333 353 339 358 279 399 380 418] 458\n",
            "[370 299 267 264 333 353 339 358 279 399 380 418 458 584] 443\n",
            "[299 267 264 333 353 339 358 279 399 380 418 458 584 443] 337\n",
            "[264 333 353 339 358 279 399 380 418 458 584 443 337 502] 512\n",
            "[333 353 339 358 279 399 380 418 458 584 443 337 502 512] 615\n",
            "[353 339 358 279 399 380 418 458 584 443 337 502 512 615] 657\n",
            "[339 358 279 399 380 418 458 584 443 337 502 512 615 657] 658\n",
            "[358 279 399 380 418 458 584 443 337 502 512 615 657 658] 548\n",
            "[279 399 380 418 458 584 443 337 502 512 615 657 658 548] 575\n",
            "[399 380 418 458 584 443 337 502 512 615 657 658 548 575] 680\n",
            "[380 418 458 584 443 337 502 512 615 657 658 548 575 680] 640\n",
            "[418 458 584 443 337 502 512 615 657 658 548 575 680 640] 726\n",
            "[458 584 443 337 502 512 615 657 658 548 575 680 640 726] 809\n",
            "[584 443 337 502 512 615 657 658 548 575 680 640 726 809] 843\n",
            "[443 337 502 512 615 657 658 548 575 680 640 726 809 843] 624\n",
            "[502 512 615 657 658 548 575 680 640 726 809 843 624 619] 551\n",
            "[512 615 657 658 548 575 680 640 726 809 843 624 619 551] 715\n",
            "[615 657 658 548 575 680 640 726 809 843 624 619 551 715] 811\n",
            "[657 658 548 575 680 640 726 809 843 624 619 551 715 811] 825\n",
            "[658 548 575 680 640 726 809 843 624 619 551 715 811 825] 778\n",
            "[548 575 680 640 726 809 843 624 619 551 715 811 825 778] 594\n",
            "[680 640 726 809 843 624 619 551 715 811 825 778 594 595] 597\n",
            "[640 726 809 843 624 619 551 715 811 825 778 594 595 597] 735\n",
            "[726 809 843 624 619 551 715 811 825 778 594 595 597 735] 767\n",
            "[809 843 624 619 551 715 811 825 778 594 595 597 735 767] 903\n",
            "[843 624 619 551 715 811 825 778 594 595 597 735 767 903] 900\n",
            "[624 619 551 715 811 825 778 594 595 597 735 767 903 900] 581\n",
            "[619 551 715 811 825 778 594 595 597 735 767 903 900 581] 548\n",
            "[715 811 825 778 594 595 597 735 767 903 900 581 548 763] 729\n",
            "[811 825 778 594 595 597 735 767 903 900 581 548 763 729] 887\n",
            "[778 594 595 597 735 767 903 900 581 548 763 729 887 791] 759\n",
            "[594 595 597 735 767 903 900 581 548 763 729 887 791 759] 631\n",
            "[595 597 735 767 903 900 581 548 763 729 887 791 759 631] 502\n",
            "[597 735 767 903 900 581 548 763 729 887 791 759 631 502] 550\n",
            "[735 767 903 900 581 548 763 729 887 791 759 631 502 550] 595\n",
            "[767 903 900 581 548 763 729 887 791 759 631 502 550 595] 612\n",
            "[903 900 581 548 763 729 887 791 759 631 502 550 595 612] 691\n",
            "[581 548 763 729 887 791 759 631 502 550 595 612 691 567] 437\n",
            "[548 763 729 887 791 759 631 502 550 595 612 691 567 437] 302\n",
            "[763 729 887 791 759 631 502 550 595 612 691 567 437 302] 400\n",
            "[887 791 759 631 502 550 595 612 691 567 437 302 400 421] 506\n",
            "[791 759 631 502 550 595 612 691 567 437 302 400 421 506] 594\n",
            "[631 502 550 595 612 691 567 437 302 400 421 506 594 603] 502\n",
            "[502 550 595 612 691 567 437 302 400 421 506 594 603 502] 377\n",
            "[550 595 612 691 567 437 302 400 421 506 594 603 502 377] 605\n",
            "[595 612 691 567 437 302 400 421 506 594 603 502 377 605] 600\n",
            "[612 691 567 437 302 400 421 506 594 603 502 377 605 600] 837\n",
            "[567 437 302 400 421 506 594 603 502 377 605 600 837 757] 1002\n",
            "[ 437  302  400  421  506  594  603  502  377  605  600  837  757 1002] 910\n",
            "[ 302  400  421  506  594  603  502  377  605  600  837  757 1002  910] 748\n",
            "[ 400  421  506  594  603  502  377  605  600  837  757 1002  910  748] 711\n",
            "[ 421  506  594  603  502  377  605  600  837  757 1002  910  748  711] 974\n",
            "[ 506  594  603  502  377  605  600  837  757 1002  910  748  711  974] 1136\n",
            "[ 594  603  502  377  605  600  837  757 1002  910  748  711  974 1136] 1587\n",
            "[ 603  502  377  605  600  837  757 1002  910  748  711  974 1136 1587] 1584\n",
            "[ 377  605  600  837  757 1002  910  748  711  974 1136 1587 1584 1350] 1306\n",
            "[ 600  837  757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326] 1552\n",
            "[ 837  757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326 1552] 1967\n",
            "[ 910  748  711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367] 1934\n",
            "[ 748  711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934] 2006\n",
            "[ 711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006] 2236\n",
            "[ 974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236] 3003\n",
            "[1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003] 4280\n",
            "[1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280] 4739\n",
            "[1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739] 5300\n",
            "[1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300] 4178\n",
            "[1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178] 4394\n",
            "[1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394] 5068\n",
            "[2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099] 7705\n",
            "[2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705] 9622\n",
            "[1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622] 8536\n",
            "[2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536] 7482\n",
            "[2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536 7482] 9291\n",
            "[ 4280  4739  5300  4178  4394  5068  6526  8099  7705  9622  8536  7482\n",
            "  9291 10040] 12107\n",
            "[ 4739  5300  4178  4394  5068  6526  8099  7705  9622  8536  7482  9291\n",
            " 10040 12107] 13632\n",
            "[ 5300  4178  4394  5068  6526  8099  7705  9622  8536  7482  9291 10040\n",
            " 12107 13632] 13628\n",
            "[ 4178  4394  5068  6526  8099  7705  9622  8536  7482  9291 10040 12107\n",
            " 13632 13628] 11742\n",
            "[ 5068  6526  8099  7705  9622  8536  7482  9291 10040 12107 13632 13628\n",
            " 11742 10241] 16300\n",
            "[ 6526  8099  7705  9622  8536  7482  9291 10040 12107 13632 13628 11742\n",
            " 10241 16300] 18820\n",
            "[ 8099  7705  9622  8536  7482  9291 10040 12107 13632 13628 11742 10241\n",
            " 16300 18820] 20156\n",
            "[ 7705  9622  8536  7482  9291 10040 12107 13632 13628 11742 10241 16300\n",
            " 18820 20156] 21629\n",
            "[ 9622  8536  7482  9291 10040 12107 13632 13628 11742 10241 16300 18820\n",
            " 20156 21629] 21897\n",
            "[ 8536  7482  9291 10040 12107 13632 13628 11742 10241 16300 18820 20156\n",
            " 21629 21897] 17171\n",
            "[ 7482  9291 10040 12107 13632 13628 11742 10241 16300 18820 20156 21629\n",
            " 21897 17171] 15578\n",
            "[ 9291 10040 12107 13632 13628 11742 10241 16300 18820 20156 21629 21897\n",
            " 17171 15578] 19364\n",
            "[10040 12107 13632 13628 11742 10241 16300 18820 20156 21629 21897 17171\n",
            " 15578 19364] 24692\n",
            "[12107 13632 13628 11742 10241 16300 18820 20156 21629 21897 17171 15578\n",
            " 19364 24692] 27143\n",
            "[13632 13628 11742 10241 16300 18820 20156 21629 21897 17171 15578 19364\n",
            " 24692 27143] 27086\n",
            "[13628 11742 10241 16300 18820 20156 21629 21897 17171 15578 19364 24692\n",
            " 27143 27086] 27875\n",
            "[11742 10241 16300 18820 20156 21629 21897 17171 15578 19364 24692 27143\n",
            " 27086 27875] 24785\n",
            "[10241 16300 18820 20156 21629 21897 17171 15578 19364 24692 27143 27086\n",
            " 27875 24785] 21713\n",
            "[16300 18820 20156 21629 21897 17171 15578 19364 24692 27143 27086 27875\n",
            " 24785 21713] 25454\n",
            "[18820 20156 21629 21897 17171 15578 19364 24692 27143 27086 27875 24785\n",
            " 21713 25454] 25221\n",
            "[20156 21629 21897 17171 15578 19364 24692 27143 27086 27875 24785 21713\n",
            " 25454 25221] 22683\n",
            "[21897 17171 15578 19364 24692 27143 27086 27875 24785 21713 25454 25221\n",
            " 22683 24051] 25571\n",
            "[17171 15578 19364 24692 27143 27086 27875 24785 21713 25454 25221 22683\n",
            " 24051 25571] 21854\n",
            "[15578 19364 24692 27143 27086 27875 24785 21713 25454 25221 22683 24051\n",
            " 25571 21854] 20816\n",
            "[19364 24692 27143 27086 27875 24785 21713 25454 25221 22683 24051 25571\n",
            " 21854 20816] 19152\n",
            "[24692 27143 27086 27875 24785 21713 25454 25221 22683 24051 25571 21854\n",
            " 20816 19152] 19883\n",
            "[27143 27086 27875 24785 21713 25454 25221 22683 24051 25571 21854 20816\n",
            " 19152 19883] 23975\n",
            "[27086 27875 24785 21713 25454 25221 22683 24051 25571 21854 20816 19152\n",
            " 19883 23975] 22464\n",
            "[27875 24785 21713 25454 25221 22683 24051 25571 21854 20816 19152 19883\n",
            " 23975 22464] 24213\n",
            "[24785 21713 25454 25221 22683 24051 25571 21854 20816 19152 19883 23975\n",
            " 22464 24213] 17856\n",
            "[25454 25221 22683 24051 25571 21854 20816 19152 19883 23975 22464 24213\n",
            " 17856 15002] 32733\n",
            "[25221 22683 24051 25571 21854 20816 19152 19883 23975 22464 24213 17856\n",
            " 15002 32733] 15356\n",
            "[22683 24051 25571 21854 20816 19152 19883 23975 22464 24213 17856 15002\n",
            " 32733 15356] 16690\n",
            "[24051 25571 21854 20816 19152 19883 23975 22464 24213 17856 15002 32733\n",
            " 15356 16690] 17304\n",
            "[25571 21854 20816 19152 19883 23975 22464 24213 17856 15002 32733 15356\n",
            " 16690 17304] 15177\n",
            "[21854 20816 19152 19883 23975 22464 24213 17856 15002 32733 15356 16690\n",
            " 17304 15177] 11482\n",
            "[20816 19152 19883 23975 22464 24213 17856 15002 32733 15356 16690 17304\n",
            " 15177 11482] 5736\n",
            "[19152 19883 23975 22464 24213 17856 15002 32733 15356 16690 17304 15177\n",
            " 11482  5736] 9113\n",
            "[23975 22464 24213 17856 15002 32733 15356 16690 17304 15177 11482  5736\n",
            "  9113 13823] 14863\n",
            "[22464 24213 17856 15002 32733 15356 16690 17304 15177 11482  5736  9113\n",
            " 13823 14863] 13236\n",
            "[24213 17856 15002 32733 15356 16690 17304 15177 11482  5736  9113 13823\n",
            " 14863 13236] 12427\n",
            "[15002 32733 15356 16690 17304 15177 11482  5736  9113 13823 14863 13236\n",
            " 12427  9176] 4421\n",
            "[32733 15356 16690 17304 15177 11482  5736  9113 13823 14863 13236 12427\n",
            "  9176  4421] 8310\n",
            "[16690 17304 15177 11482  5736  9113 13823 14863 13236 12427  9176  4421\n",
            "  8310 12166] 13750\n",
            "[17304 15177 11482  5736  9113 13823 14863 13236 12427  9176  4421  8310\n",
            " 12166 13750] 13105\n",
            "[11482  5736  9113 13823 14863 13236 12427  9176  4421  8310 12166 13750\n",
            " 13105 11499] 8976\n",
            "[ 5736  9113 13823 14863 13236 12427  9176  4421  8310 12166 13750 13105\n",
            " 11499  8976] 4896\n",
            "[ 9113 13823 14863 13236 12427  9176  4421  8310 12166 13750 13105 11499\n",
            "  8976  4896] 6874\n",
            "[14863 13236 12427  9176  4421  8310 12166 13750 13105 11499  8976  4896\n",
            "  6874 12455] 11953\n",
            "[13236 12427  9176  4421  8310 12166 13750 13105 11499  8976  4896  6874\n",
            " 12455 11953] 11010\n",
            "[12427  9176  4421  8310 12166 13750 13105 11499  8976  4896  6874 12455\n",
            " 11953 11010] 11246\n",
            "[ 9176  4421  8310 12166 13750 13105 11499  8976  4896  6874 12455 11953\n",
            " 11010 11246] 8590\n",
            "[ 4421  8310 12166 13750 13105 11499  8976  4896  6874 12455 11953 11010\n",
            " 11246  8590] 4633\n",
            "[13750 13105 11499  8976  4896  6874 12455 11953 11010 11246  8590  4633\n",
            "  7192 12358] 13115\n",
            "[13105 11499  8976  4896  6874 12455 11953 11010 11246  8590  4633  7192\n",
            " 12358 13115] 9081\n",
            "[11499  8976  4896  6874 12455 11953 11010 11246  8590  4633  7192 12358\n",
            " 13115  9081] 4878\n",
            "[ 8976  4896  6874 12455 11953 11010 11246  8590  4633  7192 12358 13115\n",
            "  9081  4878] 3842\n",
            "[ 4896  6874 12455 11953 11010 11246  8590  4633  7192 12358 13115  9081\n",
            "  4878  3842] 3211\n",
            "[11953 11010 11246  8590  4633  7192 12358 13115  9081  4878  3842  3211\n",
            "  7624 12780] 13464\n",
            "[11010 11246  8590  4633  7192 12358 13115  9081  4878  3842  3211  7624\n",
            " 12780 13464] 10896\n",
            "[11246  8590  4633  7192 12358 13115  9081  4878  3842  3211  7624 12780\n",
            " 13464 10896] 7006\n",
            "[ 4633  7192 12358 13115  9081  4878  3842  3211  7624 12780 13464 10896\n",
            "  7006  5782] 4385\n",
            "[ 7192 12358 13115  9081  4878  3842  3211  7624 12780 13464 10896  7006\n",
            "  5782  4385] 7596\n",
            "[12358 13115  9081  4878  3842  3211  7624 12780 13464 10896  7006  5782\n",
            "  4385  7596] 14220\n",
            "[13115  9081  4878  3842  3211  7624 12780 13464 10896  7006  5782  4385\n",
            "  7596 14220] 12119\n",
            "[ 4878  3842  3211  7624 12780 13464 10896  7006  5782  4385  7596 14220\n",
            " 12119  8763] 10744\n",
            "[ 3842  3211  7624 12780 13464 10896  7006  5782  4385  7596 14220 12119\n",
            "  8763 10744] 9133\n",
            "[12780 13464 10896  7006  5782  4385  7596 14220 12119  8763 10744  9133\n",
            "  4863  5394] 9126\n",
            "[13464 10896  7006  5782  4385  7596 14220 12119  8763 10744  9133  4863\n",
            "  5394  9126] 9436\n",
            "[10896  7006  5782  4385  7596 14220 12119  8763 10744  9133  4863  5394\n",
            "  9126  9436] 7979\n",
            "[ 7006  5782  4385  7596 14220 12119  8763 10744  9133  4863  5394  9126\n",
            "  9436  7979] 7292\n",
            "[ 5782  4385  7596 14220 12119  8763 10744  9133  4863  5394  9126  9436\n",
            "  7979  7292] 5970\n",
            "[ 4385  7596 14220 12119  8763 10744  9133  4863  5394  9126  9436  7979\n",
            "  7292  5970] 3332\n",
            "[ 7596 14220 12119  8763 10744  9133  4863  5394  9126  9436  7979  7292\n",
            "  5970  3332] 4890\n",
            "[14220 12119  8763 10744  9133  4863  5394  9126  9436  7979  7292  5970\n",
            "  3332  4890] 6943\n",
            "[ 8763 10744  9133  4863  5394  9126  9436  7979  7292  5970  3332  4890\n",
            "  6943  7008] 6693\n",
            "[10744  9133  4863  5394  9126  9436  7979  7292  5970  3332  4890  6943\n",
            "  7008  6693] 6304\n",
            "[9133 4863 5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304] 4566\n",
            "[5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674] 4603\n",
            "[9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603] 6790\n",
            "[7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153] 6145\n",
            "[7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145] 5864\n",
            "[5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864] 4711\n",
            "[3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711] 2504\n",
            "[4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504] 4326\n",
            "[7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801] 6495\n",
            "[6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495] 6053\n",
            "[6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053] 5966\n",
            "[4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966] 4725\n",
            "[4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431] 3999\n",
            "[6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013] 6378\n",
            "[5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378] 6585\n",
            "[4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585] 5334\n",
            "[2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334] 2542\n",
            "[6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176] 8699\n",
            "[6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699] 9074\n",
            "[5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772] 8509\n",
            "[4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509] 7040\n",
            "[2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040] 3891\n",
            "[3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040 3891] 6304\n",
            "[6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040 3891 6304] 12147\n",
            "[ 7013  6378  6585  5334  2542  5176  8699  9074  8772  8509  7040  3891\n",
            "  6304 12147] 12143\n",
            "[ 5334  2542  5176  8699  9074  8772  8509  7040  3891  6304 12147 12143\n",
            " 11536 12097] 10101\n",
            "[ 2542  5176  8699  9074  8772  8509  7040  3891  6304 12147 12143 11536\n",
            " 12097 10101] 4786\n",
            "[ 5176  8699  9074  8772  8509  7040  3891  6304 12147 12143 11536 12097\n",
            " 10101  4786] 7936\n",
            "[ 8699  9074  8772  8509  7040  3891  6304 12147 12143 11536 12097 10101\n",
            "  4786  7936] 15698\n",
            "[ 9074  8772  8509  7040  3891  6304 12147 12143 11536 12097 10101  4786\n",
            "  7936 15698] 15253\n",
            "[ 8772  8509  7040  3891  6304 12147 12143 11536 12097 10101  4786  7936\n",
            " 15698 15253] 15831\n",
            "[ 8509  7040  3891  6304 12147 12143 11536 12097 10101  4786  7936 15698\n",
            " 15253 15831] 14855\n",
            "[ 7040  3891  6304 12147 12143 11536 12097 10101  4786  7936 15698 15253\n",
            " 15831 14855] 13569\n",
            "[ 3891  6304 12147 12143 11536 12097 10101  4786  7936 15698 15253 15831\n",
            " 14855 13569] 6169\n",
            "[12147 12143 11536 12097 10101  4786  7936 15698 15253 15831 14855 13569\n",
            "  6169  9953] 17277\n",
            "[12143 11536 12097 10101  4786  7936 15698 15253 15831 14855 13569  6169\n",
            "  9953 17277] 21111\n",
            "[11536 12097 10101  4786  7936 15698 15253 15831 14855 13569  6169  9953\n",
            " 17277 21111] 18873\n",
            "[12097 10101  4786  7936 15698 15253 15831 14855 13569  6169  9953 17277\n",
            " 21111 18873] 21063\n",
            "[10101  4786  7936 15698 15253 15831 14855 13569  6169  9953 17277 21111\n",
            " 18873 21063] 17272\n",
            "[ 4786  7936 15698 15253 15831 14855 13569  6169  9953 17277 21111 18873\n",
            " 21063 17272] 10895\n",
            "[15698 15253 15831 14855 13569  6169  9953 17277 21111 18873 21063 17272\n",
            " 10895 14394] 25053\n",
            "[15253 15831 14855 13569  6169  9953 17277 21111 18873 21063 17272 10895\n",
            " 14394 25053] 27274\n",
            "[15831 14855 13569  6169  9953 17277 21111 18873 21063 17272 10895 14394\n",
            " 25053 27274] 25996\n",
            "[14855 13569  6169  9953 17277 21111 18873 21063 17272 10895 14394 25053\n",
            " 27274 25996] 26456\n",
            "[13569  6169  9953 17277 21111 18873 21063 17272 10895 14394 25053 27274\n",
            " 25996 26456] 21850\n",
            "[ 9953 17277 21111 18873 21063 17272 10895 14394 25053 27274 25996 26456\n",
            " 21850 14579] 16740\n",
            "[17277 21111 18873 21063 17272 10895 14394 25053 27274 25996 26456 21850\n",
            " 14579 16740] 30802\n",
            "[21111 18873 21063 17272 10895 14394 25053 27274 25996 26456 21850 14579\n",
            " 16740 30802] 34150\n",
            "[18873 21063 17272 10895 14394 25053 27274 25996 26456 21850 14579 16740\n",
            " 30802 34150] 35145\n",
            "[21063 17272 10895 14394 25053 27274 25996 26456 21850 14579 16740 30802\n",
            " 34150 35145] 31759\n",
            "[17272 10895 14394 25053 27274 25996 26456 21850 14579 16740 30802 34150\n",
            " 35145 31759] 29266\n",
            "[14394 25053 27274 25996 26456 21850 14579 16740 30802 34150 35145 31759\n",
            " 29266 16973] 20862\n",
            "[25053 27274 25996 26456 21850 14579 16740 30802 34150 35145 31759 29266\n",
            " 16973 20862] 32891\n",
            "[27274 25996 26456 21850 14579 16740 30802 34150 35145 31759 29266 16973\n",
            " 20862 32891] 35253\n",
            "[25996 26456 21850 14579 16740 30802 34150 35145 31759 29266 16973 20862\n",
            " 32891 35253] 30541\n",
            "[26456 21850 14579 16740 30802 34150 35145 31759 29266 16973 20862 32891\n",
            " 35253 30541] 28073\n",
            "[21850 14579 16740 30802 34150 35145 31759 29266 16973 20862 32891 35253\n",
            " 30541 28073] 22958\n",
            "[14579 16740 30802 34150 35145 31759 29266 16973 20862 32891 35253 30541\n",
            " 28073 22958] 9921\n",
            "[16740 30802 34150 35145 31759 29266 16973 20862 32891 35253 30541 28073\n",
            " 22958  9921] 8246\n",
            "[30802 34150 35145 31759 29266 16973 20862 32891 35253 30541 28073 22958\n",
            "  9921  8246] 14908\n",
            "[34150 35145 31759 29266 16973 20862 32891 35253 30541 28073 22958  9921\n",
            "  8246 14908] 27890\n",
            "[35145 31759 29266 16973 20862 32891 35253 30541 28073 22958  9921  8246\n",
            " 14908 27890] 28499\n",
            "[31759 29266 16973 20862 32891 35253 30541 28073 22958  9921  8246 14908\n",
            " 27890 28499] 24892\n",
            "[29266 16973 20862 32891 35253 30541 28073 22958  9921  8246 14908 27890\n",
            " 28499 24892] 21733\n",
            "[16973 20862 32891 35253 30541 28073 22958  9921  8246 14908 27890 28499\n",
            " 24892 21733] 12016\n",
            "[20862 32891 35253 30541 28073 22958  9921  8246 14908 27890 28499 24892\n",
            " 21733 12016] 13203\n",
            "[32891 35253 30541 28073 22958  9921  8246 14908 27890 28499 24892 21733\n",
            " 12016 13203] 21266\n",
            "[30541 28073 22958  9921  8246 14908 27890 28499 24892 21733 12016 13203\n",
            " 21266 21126] 17846\n",
            "[28073 22958  9921  8246 14908 27890 28499 24892 21733 12016 13203 21266\n",
            " 21126 17846] 15786\n",
            "[22958  9921  8246 14908 27890 28499 24892 21733 12016 13203 21266 21126\n",
            " 17846 15786] 12151\n",
            "[ 9921  8246 14908 27890 28499 24892 21733 12016 13203 21266 21126 17846\n",
            " 15786 12151] 7302\n",
            "[14908 27890 28499 24892 21733 12016 13203 21266 21126 17846 15786 12151\n",
            "  7302  9244] 13922\n",
            "[28499 24892 21733 12016 13203 21266 21126 17846 15786 12151  7302  9244\n",
            " 13922 12763] 10866\n",
            "[24892 21733 12016 13203 21266 21126 17846 15786 12151  7302  9244 13922\n",
            " 12763 10866] 9510\n",
            "[21733 12016 13203 21266 21126 17846 15786 12151  7302  9244 13922 12763\n",
            " 10866  9510] 7224\n",
            "[12016 13203 21266 21126 17846 15786 12151  7302  9244 13922 12763 10866\n",
            "  9510  7224] 3467\n",
            "[13203 21266 21126 17846 15786 12151  7302  9244 13922 12763 10866  9510\n",
            "  7224  3467] 5711\n",
            "[21266 21126 17846 15786 12151  7302  9244 13922 12763 10866  9510  7224\n",
            "  3467  5711] 8893\n",
            "[21126 17846 15786 12151  7302  9244 13922 12763 10866  9510  7224  3467\n",
            "  5711  8893] 8426\n",
            "[15786 12151  7302  9244 13922 12763 10866  9510  7224  3467  5711  8893\n",
            "  8426  6789] 6475\n",
            "[12151  7302  9244 13922 12763 10866  9510  7224  3467  5711  8893  8426\n",
            "  6789  6475] 4616\n",
            "[ 9244 13922 12763 10866  9510  7224  3467  5711  8893  8426  6789  6475\n",
            "  4616  2523] 2296\n",
            "[12763 10866  9510  7224  3467  5711  8893  8426  6789  6475  4616  2523\n",
            "  2296  3899] 6427\n",
            "[10866  9510  7224  3467  5711  8893  8426  6789  6475  4616  2523  2296\n",
            "  3899  6427] 6047\n",
            "[9510 7224 3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047] 4771\n",
            "[7224 3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771] 3856\n",
            "[3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856] 2031\n",
            "[5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031] 3097\n",
            "[8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948] 3694\n",
            "[6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289] 2897\n",
            "[4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897] 2169\n",
            "[2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111] 1727\n",
            "[3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727] 2348\n",
            "[6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348] 2087\n",
            "[6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087] 1678\n",
            "[3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517] 1075\n",
            "[2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075] 559\n",
            "[3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559] 1000\n",
            "[3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000] 1267\n",
            "[3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267] 1227\n",
            "[2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946] 775\n",
            "[2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946  775] 579\n",
            "[1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946  775  579] 333\n",
            "[2348 2087 1678 1517 1075  559 1000 1267 1227  946  775  579  333  588] 659\n",
            "[2087 1678 1517 1075  559 1000 1267 1227  946  775  579  333  588  659] 572\n",
            "[1075  559 1000 1267 1227  946  775  579  333  588  659  572  317  415] 310\n",
            "[ 559 1000 1267 1227  946  775  579  333  588  659  572  317  415  310] 195\n",
            "[1267 1227  946  775  579  333  588  659  572  317  415  310  195  532] 428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0PLxD5xXyz"
      },
      "source": [
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "Validation_X = Validation_X.reshape((Validation_X.shape[0], Validation_X.shape[1], n_features))\n",
        "Y = Y.reshape((Y.shape[0], 1, n_features))\n",
        "Validation_Y = Validation_Y.reshape((Validation_Y.shape[0], 1, n_features))\n",
        "look_back = n"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_-ZW77mxava",
        "outputId": "147e07fa-83dd-4eb4-8ed4-d94fe2694f0f"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 14, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw8wRQf3BCKI"
      },
      "source": [
        "#creating the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    LSTM(50,\n",
        "        activation='relu',\n",
        "        input_shape=(look_back,1))\n",
        ")\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "num_epochs = 550"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEeHxQe8xk84",
        "outputId": "cde090cc-f33e-40ad-f5af-2c3f052cf777"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kBvWEfHxn5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cd95de-3cc7-4cdf-89af-3e3172a9bafd"
      },
      "source": [
        "history = model.fit(X, Y, epochs=num_epochs, validation_data=(X,Y), verbose=1)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/550\n",
            "12/12 [==============================] - 3s 64ms/step - loss: 7804.8268 - val_loss: 6656.0762\n",
            "Epoch 2/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6315.4256 - val_loss: 5221.9321\n",
            "Epoch 3/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4779.5919 - val_loss: 4610.2065\n",
            "Epoch 4/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4773.9381 - val_loss: 3953.1487\n",
            "Epoch 5/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4130.3638 - val_loss: 3911.2947\n",
            "Epoch 6/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3617.0379 - val_loss: 3578.3242\n",
            "Epoch 7/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3414.2736 - val_loss: 2772.1536\n",
            "Epoch 8/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2938.8346 - val_loss: 2489.3901\n",
            "Epoch 9/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2413.9637 - val_loss: 2348.7937\n",
            "Epoch 10/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2303.4851 - val_loss: 3294.9924\n",
            "Epoch 11/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3394.3427 - val_loss: 2636.5610\n",
            "Epoch 12/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2666.7071 - val_loss: 2763.3130\n",
            "Epoch 13/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2421.2029 - val_loss: 2710.4536\n",
            "Epoch 14/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2654.7813 - val_loss: 3033.7676\n",
            "Epoch 15/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2902.7201 - val_loss: 3022.3132\n",
            "Epoch 16/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2933.6903 - val_loss: 2980.0171\n",
            "Epoch 17/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2607.6214 - val_loss: 2728.4141\n",
            "Epoch 18/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2646.2183 - val_loss: 2210.5681\n",
            "Epoch 19/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2033.9974 - val_loss: 2419.8174\n",
            "Epoch 20/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2552.6601 - val_loss: 2945.7610\n",
            "Epoch 21/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2790.5885 - val_loss: 2305.0754\n",
            "Epoch 22/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2087.2141 - val_loss: 2128.6663\n",
            "Epoch 23/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1892.1601 - val_loss: 2008.5187\n",
            "Epoch 24/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2224.3844 - val_loss: 2117.6655\n",
            "Epoch 25/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2084.6749 - val_loss: 2147.1143\n",
            "Epoch 26/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1978.1358 - val_loss: 2087.0859\n",
            "Epoch 27/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1899.3141 - val_loss: 2091.6545\n",
            "Epoch 28/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2097.9985 - val_loss: 1900.5681\n",
            "Epoch 29/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1891.6038 - val_loss: 1955.9779\n",
            "Epoch 30/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2098.9626 - val_loss: 1736.5426\n",
            "Epoch 31/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1793.3926 - val_loss: 1775.0153\n",
            "Epoch 32/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1816.3174 - val_loss: 1943.4706\n",
            "Epoch 33/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1812.0139 - val_loss: 2204.1299\n",
            "Epoch 34/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2111.2152 - val_loss: 1999.5742\n",
            "Epoch 35/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2068.4459 - val_loss: 2135.7612\n",
            "Epoch 36/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2342.7597 - val_loss: 2151.6096\n",
            "Epoch 37/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1984.5765 - val_loss: 2140.1982\n",
            "Epoch 38/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2067.5135 - val_loss: 2493.3147\n",
            "Epoch 39/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2929.3933 - val_loss: 1961.9215\n",
            "Epoch 40/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2070.6988 - val_loss: 2026.3966\n",
            "Epoch 41/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2768.1547 - val_loss: 1988.7145\n",
            "Epoch 42/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2388.0844 - val_loss: 4120.1230\n",
            "Epoch 43/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4109.4793 - val_loss: 3621.7556\n",
            "Epoch 44/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2553.2987 - val_loss: 2116.1355\n",
            "Epoch 45/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1907.2449 - val_loss: 1869.7018\n",
            "Epoch 46/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1909.1564 - val_loss: 1753.4409\n",
            "Epoch 47/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1603.4483 - val_loss: 2191.9209\n",
            "Epoch 48/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2298.2689 - val_loss: 2665.4500\n",
            "Epoch 49/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3241.3601 - val_loss: 2018.3899\n",
            "Epoch 50/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1859.8899 - val_loss: 2139.9348\n",
            "Epoch 51/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2112.7004 - val_loss: 1912.9385\n",
            "Epoch 52/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1764.2518 - val_loss: 1889.5341\n",
            "Epoch 53/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1625.7564 - val_loss: 1624.0439\n",
            "Epoch 54/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1607.3754 - val_loss: 1680.7997\n",
            "Epoch 55/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1651.2076 - val_loss: 1752.5031\n",
            "Epoch 56/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1816.1501 - val_loss: 2364.0164\n",
            "Epoch 57/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2652.8553 - val_loss: 5819.7637\n",
            "Epoch 58/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4507.7287 - val_loss: 3547.0083\n",
            "Epoch 59/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2994.3824 - val_loss: 3293.7695\n",
            "Epoch 60/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3341.1905 - val_loss: 3619.8823\n",
            "Epoch 61/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3477.5580 - val_loss: 3552.9949\n",
            "Epoch 62/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2949.4358 - val_loss: 2333.3821\n",
            "Epoch 63/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2198.2806 - val_loss: 2159.8965\n",
            "Epoch 64/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2082.6907 - val_loss: 2209.9980\n",
            "Epoch 65/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2370.3317 - val_loss: 2139.7920\n",
            "Epoch 66/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2021.8851 - val_loss: 2118.2827\n",
            "Epoch 67/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1853.6705 - val_loss: 2104.4023\n",
            "Epoch 68/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2022.9446 - val_loss: 2135.9136\n",
            "Epoch 69/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2407.8720 - val_loss: 2107.1057\n",
            "Epoch 70/550\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2368.5639 - val_loss: 2200.0400\n",
            "Epoch 71/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2595.6826 - val_loss: 2436.3401\n",
            "Epoch 72/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2720.8517 - val_loss: 2522.5007\n",
            "Epoch 73/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2679.5339 - val_loss: 2842.9768\n",
            "Epoch 74/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2636.2337 - val_loss: 2277.9463\n",
            "Epoch 75/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2303.0393 - val_loss: 2104.6072\n",
            "Epoch 76/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1992.3799 - val_loss: 2052.4009\n",
            "Epoch 77/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2273.1698 - val_loss: 2066.6995\n",
            "Epoch 78/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1912.8886 - val_loss: 2099.9387\n",
            "Epoch 79/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2126.8731 - val_loss: 2038.0554\n",
            "Epoch 80/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2071.7278 - val_loss: 2015.9700\n",
            "Epoch 81/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2029.0086 - val_loss: 2038.4066\n",
            "Epoch 82/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2017.7422 - val_loss: 1939.1489\n",
            "Epoch 83/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1963.6319 - val_loss: 1926.8346\n",
            "Epoch 84/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1845.1916 - val_loss: 1800.9958\n",
            "Epoch 85/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1729.8774 - val_loss: 1779.5426\n",
            "Epoch 86/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2061.1850 - val_loss: 1708.7015\n",
            "Epoch 87/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1716.6686 - val_loss: 1677.0127\n",
            "Epoch 88/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1803.7358 - val_loss: 1695.3694\n",
            "Epoch 89/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1424.5940 - val_loss: 1717.0797\n",
            "Epoch 90/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1821.9478 - val_loss: 1618.2970\n",
            "Epoch 91/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1525.3292 - val_loss: 1608.5869\n",
            "Epoch 92/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1514.6170 - val_loss: 1563.8666\n",
            "Epoch 93/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1725.1450 - val_loss: 1592.1489\n",
            "Epoch 94/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1666.4650 - val_loss: 1510.1672\n",
            "Epoch 95/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1436.2462 - val_loss: 1518.0193\n",
            "Epoch 96/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1505.3624 - val_loss: 1507.9045\n",
            "Epoch 97/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1529.9106 - val_loss: 1589.2023\n",
            "Epoch 98/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1694.5487 - val_loss: 1596.0836\n",
            "Epoch 99/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1568.8610 - val_loss: 1571.7366\n",
            "Epoch 100/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1572.8966 - val_loss: 1572.5919\n",
            "Epoch 101/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1522.1062 - val_loss: 1612.6526\n",
            "Epoch 102/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1488.3561 - val_loss: 1623.0989\n",
            "Epoch 103/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1598.9698 - val_loss: 1634.1276\n",
            "Epoch 104/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1663.3414 - val_loss: 1628.2074\n",
            "Epoch 105/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1683.9380 - val_loss: 1644.5469\n",
            "Epoch 106/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1694.2688 - val_loss: 1623.2395\n",
            "Epoch 107/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1741.6435 - val_loss: 1594.8722\n",
            "Epoch 108/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1469.9191 - val_loss: 1583.2598\n",
            "Epoch 109/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1568.0605 - val_loss: 1805.2111\n",
            "Epoch 110/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1739.2239 - val_loss: 1795.5887\n",
            "Epoch 111/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1663.8001 - val_loss: 1806.8149\n",
            "Epoch 112/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1620.0996 - val_loss: 1814.7788\n",
            "Epoch 113/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1925.3011 - val_loss: 2051.1011\n",
            "Epoch 114/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2072.7872 - val_loss: 1942.3405\n",
            "Epoch 115/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1715.3963 - val_loss: 1952.2134\n",
            "Epoch 116/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1991.3619 - val_loss: 1994.0791\n",
            "Epoch 117/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2111.0762 - val_loss: 1986.3899\n",
            "Epoch 118/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1940.5799 - val_loss: 1986.8447\n",
            "Epoch 119/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1773.9758 - val_loss: 1890.2965\n",
            "Epoch 120/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1807.7879 - val_loss: 1845.1709\n",
            "Epoch 121/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1683.0166 - val_loss: 1816.0955\n",
            "Epoch 122/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1763.7996 - val_loss: 1783.4564\n",
            "Epoch 123/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1797.9420 - val_loss: 1744.0347\n",
            "Epoch 124/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1740.8114 - val_loss: 1759.3795\n",
            "Epoch 125/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1812.6497 - val_loss: 1807.8527\n",
            "Epoch 126/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1769.0913 - val_loss: 1743.3011\n",
            "Epoch 127/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1773.2051 - val_loss: 1746.8242\n",
            "Epoch 128/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2001.4090 - val_loss: 1736.2048\n",
            "Epoch 129/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1644.4814 - val_loss: 1959.4629\n",
            "Epoch 130/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2112.7572 - val_loss: 1791.8124\n",
            "Epoch 131/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1780.7538 - val_loss: 1813.0482\n",
            "Epoch 132/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1921.3452 - val_loss: 2951.1016\n",
            "Epoch 133/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4274.2396 - val_loss: 2871.6677\n",
            "Epoch 134/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2470.5855 - val_loss: 2499.6675\n",
            "Epoch 135/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2481.3513 - val_loss: 1743.1896\n",
            "Epoch 136/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2147.3214 - val_loss: 2031.0797\n",
            "Epoch 137/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2281.0381 - val_loss: 1889.5300\n",
            "Epoch 138/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1874.7766 - val_loss: 1827.6361\n",
            "Epoch 139/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1652.5789 - val_loss: 1914.8599\n",
            "Epoch 140/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2116.6020 - val_loss: 1891.0359\n",
            "Epoch 141/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1768.6268 - val_loss: 1962.7234\n",
            "Epoch 142/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1773.5983 - val_loss: 1895.7814\n",
            "Epoch 143/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1870.0563 - val_loss: 1873.7074\n",
            "Epoch 144/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1755.9067 - val_loss: 1732.2466\n",
            "Epoch 145/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1630.3674 - val_loss: 1590.8163\n",
            "Epoch 146/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1734.7867 - val_loss: 1650.4020\n",
            "Epoch 147/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1678.6722 - val_loss: 1807.2507\n",
            "Epoch 148/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1946.4767 - val_loss: 1585.7399\n",
            "Epoch 149/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1692.9933 - val_loss: 1639.2526\n",
            "Epoch 150/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1591.9161 - val_loss: 1611.1251\n",
            "Epoch 151/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1392.1497 - val_loss: 1646.4315\n",
            "Epoch 152/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1578.3007 - val_loss: 1651.7957\n",
            "Epoch 153/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1354.1721 - val_loss: 1631.1642\n",
            "Epoch 154/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1526.2262 - val_loss: 1806.8755\n",
            "Epoch 155/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2975.6517 - val_loss: 3073.1045\n",
            "Epoch 156/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2455.3779 - val_loss: 2276.2390\n",
            "Epoch 157/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2176.9106 - val_loss: 2311.4033\n",
            "Epoch 158/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2341.0023 - val_loss: 1634.2573\n",
            "Epoch 159/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1638.7963 - val_loss: 1452.9307\n",
            "Epoch 160/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1298.3028 - val_loss: 1415.1237\n",
            "Epoch 161/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1306.1563 - val_loss: 1511.7567\n",
            "Epoch 162/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1447.9647 - val_loss: 1676.4346\n",
            "Epoch 163/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1593.7664 - val_loss: 1362.6486\n",
            "Epoch 164/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1597.4607 - val_loss: 1698.0554\n",
            "Epoch 165/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1839.8570 - val_loss: 1534.9792\n",
            "Epoch 166/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1511.8516 - val_loss: 1454.4796\n",
            "Epoch 167/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1384.8986 - val_loss: 1432.0916\n",
            "Epoch 168/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1466.2612 - val_loss: 1378.8835\n",
            "Epoch 169/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1584.6599 - val_loss: 1635.5858\n",
            "Epoch 170/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1644.6410 - val_loss: 1407.1133\n",
            "Epoch 171/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1298.0620 - val_loss: 1354.7206\n",
            "Epoch 172/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1456.7820 - val_loss: 1372.3337\n",
            "Epoch 173/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1326.1274 - val_loss: 1528.0613\n",
            "Epoch 174/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1262.8440 - val_loss: 1505.4640\n",
            "Epoch 175/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1624.5738 - val_loss: 1473.9219\n",
            "Epoch 176/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1444.9490 - val_loss: 1414.8138\n",
            "Epoch 177/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1343.5543 - val_loss: 1397.3768\n",
            "Epoch 178/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1586.0143 - val_loss: 1406.4269\n",
            "Epoch 179/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1305.2095 - val_loss: 1439.3195\n",
            "Epoch 180/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1492.2928 - val_loss: 1357.1573\n",
            "Epoch 181/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1157.7391 - val_loss: 1535.8391\n",
            "Epoch 182/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1449.5781 - val_loss: 1448.6943\n",
            "Epoch 183/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1248.7052 - val_loss: 1417.2661\n",
            "Epoch 184/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1358.9733 - val_loss: 1390.1632\n",
            "Epoch 185/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1426.0118 - val_loss: 1408.4324\n",
            "Epoch 186/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1461.7312 - val_loss: 1385.2306\n",
            "Epoch 187/550\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1428.9705 - val_loss: 1356.4767\n",
            "Epoch 188/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1265.5046 - val_loss: 1346.4867\n",
            "Epoch 189/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1286.7709 - val_loss: 1344.7260\n",
            "Epoch 190/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1338.8587 - val_loss: 1334.7522\n",
            "Epoch 191/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1126.1467 - val_loss: 1348.5638\n",
            "Epoch 192/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1420.5658 - val_loss: 1288.1471\n",
            "Epoch 193/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1348.1150 - val_loss: 1279.0126\n",
            "Epoch 194/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1442.5582 - val_loss: 1372.0275\n",
            "Epoch 195/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1392.4021 - val_loss: 1302.0382\n",
            "Epoch 196/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1317.8094 - val_loss: 1321.0255\n",
            "Epoch 197/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1370.2017 - val_loss: 1432.5546\n",
            "Epoch 198/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1396.3261 - val_loss: 1417.0360\n",
            "Epoch 199/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1428.9153 - val_loss: 1421.6107\n",
            "Epoch 200/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1323.3501 - val_loss: 1414.3821\n",
            "Epoch 201/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1384.6730 - val_loss: 1432.6287\n",
            "Epoch 202/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1558.8935 - val_loss: 1432.0208\n",
            "Epoch 203/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1522.0519 - val_loss: 1414.7043\n",
            "Epoch 204/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1291.0504 - val_loss: 1348.9655\n",
            "Epoch 205/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1437.2184 - val_loss: 1364.3218\n",
            "Epoch 206/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1262.7107 - val_loss: 1331.6410\n",
            "Epoch 207/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1345.5605 - val_loss: 1378.1587\n",
            "Epoch 208/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1371.4461 - val_loss: 1354.6965\n",
            "Epoch 209/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1314.8819 - val_loss: 1362.4523\n",
            "Epoch 210/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1419.0997 - val_loss: 1311.2666\n",
            "Epoch 211/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1327.3216 - val_loss: 1283.4565\n",
            "Epoch 212/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1174.9972 - val_loss: 1298.3569\n",
            "Epoch 213/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1307.2746 - val_loss: 1340.3201\n",
            "Epoch 214/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1345.1434 - val_loss: 1312.4541\n",
            "Epoch 215/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1209.3535 - val_loss: 1269.3929\n",
            "Epoch 216/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1119.5993 - val_loss: 1177.4814\n",
            "Epoch 217/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1055.6255 - val_loss: 1395.5171\n",
            "Epoch 218/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1281.1920 - val_loss: 1278.9924\n",
            "Epoch 219/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1168.6905 - val_loss: 1158.4900\n",
            "Epoch 220/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1063.2630 - val_loss: 1110.1766\n",
            "Epoch 221/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 961.5086 - val_loss: 1199.7881\n",
            "Epoch 222/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1064.0081 - val_loss: 1237.4680\n",
            "Epoch 223/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1268.5722 - val_loss: 1245.6233\n",
            "Epoch 224/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1179.6920 - val_loss: 1276.7810\n",
            "Epoch 225/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1393.4632 - val_loss: 1271.0905\n",
            "Epoch 226/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1219.6336 - val_loss: 1228.7012\n",
            "Epoch 227/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1198.6997 - val_loss: 1235.1422\n",
            "Epoch 228/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1190.3403 - val_loss: 1213.0327\n",
            "Epoch 229/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1091.4487 - val_loss: 1205.5031\n",
            "Epoch 230/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1191.7761 - val_loss: 1169.0924\n",
            "Epoch 231/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1056.9485 - val_loss: 1189.9578\n",
            "Epoch 232/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1061.7474 - val_loss: 1170.5531\n",
            "Epoch 233/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1161.9006 - val_loss: 1200.2968\n",
            "Epoch 234/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1197.6344 - val_loss: 1235.1923\n",
            "Epoch 235/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1183.0238 - val_loss: 1170.9781\n",
            "Epoch 236/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1185.0397 - val_loss: 1122.9519\n",
            "Epoch 237/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1199.4244 - val_loss: 1159.2849\n",
            "Epoch 238/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1145.6207 - val_loss: 1148.1274\n",
            "Epoch 239/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1151.0841 - val_loss: 1157.6844\n",
            "Epoch 240/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1217.2297 - val_loss: 1203.7585\n",
            "Epoch 241/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1160.9444 - val_loss: 1113.3751\n",
            "Epoch 242/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1075.2229 - val_loss: 1138.2351\n",
            "Epoch 243/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1008.6377 - val_loss: 1173.1282\n",
            "Epoch 244/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1017.0001 - val_loss: 1405.6449\n",
            "Epoch 245/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1224.6129 - val_loss: 1824.9274\n",
            "Epoch 246/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2041.8896 - val_loss: 1849.7186\n",
            "Epoch 247/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1618.9764 - val_loss: 1644.7773\n",
            "Epoch 248/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1642.8520 - val_loss: 1950.5748\n",
            "Epoch 249/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1797.3939 - val_loss: 1810.8214\n",
            "Epoch 250/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1842.2366 - val_loss: 1587.1195\n",
            "Epoch 251/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1399.0677 - val_loss: 1357.8887\n",
            "Epoch 252/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1406.9407 - val_loss: 1449.2716\n",
            "Epoch 253/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1389.3620 - val_loss: 1317.8125\n",
            "Epoch 254/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1303.5786 - val_loss: 1926.1857\n",
            "Epoch 255/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2114.1460 - val_loss: 2262.2639\n",
            "Epoch 256/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2277.3600 - val_loss: 2016.7866\n",
            "Epoch 257/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1979.7765 - val_loss: 2035.7365\n",
            "Epoch 258/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2271.7430 - val_loss: 2959.6763\n",
            "Epoch 259/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3536.0790 - val_loss: 3519.8782\n",
            "Epoch 260/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3523.7603 - val_loss: 3485.1392\n",
            "Epoch 261/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3558.6222 - val_loss: 3238.4722\n",
            "Epoch 262/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3349.5968 - val_loss: 2551.4631\n",
            "Epoch 263/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2416.2285 - val_loss: 2391.6711\n",
            "Epoch 264/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2473.4207 - val_loss: 2349.0088\n",
            "Epoch 265/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2287.0431 - val_loss: 2272.2295\n",
            "Epoch 266/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2536.5108 - val_loss: 2266.9651\n",
            "Epoch 267/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2012.6210 - val_loss: 2193.3198\n",
            "Epoch 268/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2344.5208 - val_loss: 2151.2041\n",
            "Epoch 269/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2006.4054 - val_loss: 2166.6707\n",
            "Epoch 270/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2117.8706 - val_loss: 2140.0149\n",
            "Epoch 271/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2079.0171 - val_loss: 2112.3867\n",
            "Epoch 272/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2293.9604 - val_loss: 2080.1465\n",
            "Epoch 273/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2280.5112 - val_loss: 1859.2794\n",
            "Epoch 274/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1567.4749 - val_loss: 1763.4889\n",
            "Epoch 275/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2070.2077 - val_loss: 2202.4836\n",
            "Epoch 276/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2401.8823 - val_loss: 2305.4795\n",
            "Epoch 277/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2389.4745 - val_loss: 2711.0378\n",
            "Epoch 278/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2582.3538 - val_loss: 2633.6606\n",
            "Epoch 279/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2523.2572 - val_loss: 2553.0190\n",
            "Epoch 280/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2856.4798 - val_loss: 2510.9580\n",
            "Epoch 281/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2340.0269 - val_loss: 2369.1467\n",
            "Epoch 282/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2159.5191 - val_loss: 2072.1438\n",
            "Epoch 283/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1867.1050 - val_loss: 2130.5759\n",
            "Epoch 284/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2287.6229 - val_loss: 2332.7410\n",
            "Epoch 285/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2385.0879 - val_loss: 2278.9290\n",
            "Epoch 286/550\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1996.0308 - val_loss: 2162.2756\n",
            "Epoch 287/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2505.5059 - val_loss: 1933.0938\n",
            "Epoch 288/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1812.2527 - val_loss: 1932.6283\n",
            "Epoch 289/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1757.2825 - val_loss: 1904.3994\n",
            "Epoch 290/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1831.6978 - val_loss: 1821.6434\n",
            "Epoch 291/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1844.4135 - val_loss: 1755.6030\n",
            "Epoch 292/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1596.7541 - val_loss: 1720.1508\n",
            "Epoch 293/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1823.0978 - val_loss: 1671.1144\n",
            "Epoch 294/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1859.1364 - val_loss: 1612.2842\n",
            "Epoch 295/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1680.8636 - val_loss: 1520.6703\n",
            "Epoch 296/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1515.2541 - val_loss: 1645.9993\n",
            "Epoch 297/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1881.7385 - val_loss: 1812.2620\n",
            "Epoch 298/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1840.2408 - val_loss: 1687.4883\n",
            "Epoch 299/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1630.5128 - val_loss: 1547.9865\n",
            "Epoch 300/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1773.8011 - val_loss: 1486.0392\n",
            "Epoch 301/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1514.5921 - val_loss: 1469.2188\n",
            "Epoch 302/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1386.8131 - val_loss: 1466.0331\n",
            "Epoch 303/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1607.4406 - val_loss: 1466.7661\n",
            "Epoch 304/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1460.1536 - val_loss: 1458.3333\n",
            "Epoch 305/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1610.8135 - val_loss: 1450.6011\n",
            "Epoch 306/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1285.8491 - val_loss: 1448.8754\n",
            "Epoch 307/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1398.1321 - val_loss: 1446.9143\n",
            "Epoch 308/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1351.5208 - val_loss: 1445.2390\n",
            "Epoch 309/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1558.1023 - val_loss: 1444.0497\n",
            "Epoch 310/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1482.2395 - val_loss: 1443.0424\n",
            "Epoch 311/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1368.3242 - val_loss: 1441.7336\n",
            "Epoch 312/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1477.9939 - val_loss: 1440.5587\n",
            "Epoch 313/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1444.6247 - val_loss: 1439.5083\n",
            "Epoch 314/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1480.7873 - val_loss: 1438.7142\n",
            "Epoch 315/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1446.1656 - val_loss: 1437.4161\n",
            "Epoch 316/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1608.3773 - val_loss: 1436.1837\n",
            "Epoch 317/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1476.2279 - val_loss: 1435.1437\n",
            "Epoch 318/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1418.0060 - val_loss: 1434.1483\n",
            "Epoch 319/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1489.4629 - val_loss: 1433.1237\n",
            "Epoch 320/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1468.4353 - val_loss: 1432.0284\n",
            "Epoch 321/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1307.8787 - val_loss: 1431.0326\n",
            "Epoch 322/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1620.8687 - val_loss: 1429.9369\n",
            "Epoch 323/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1514.4079 - val_loss: 1428.8594\n",
            "Epoch 324/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1537.6308 - val_loss: 1427.9510\n",
            "Epoch 325/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1204.5993 - val_loss: 1427.1031\n",
            "Epoch 326/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1432.8639 - val_loss: 1426.2927\n",
            "Epoch 327/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1455.7351 - val_loss: 1425.5120\n",
            "Epoch 328/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1310.8309 - val_loss: 1424.7483\n",
            "Epoch 329/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1545.4926 - val_loss: 1424.0322\n",
            "Epoch 330/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1440.9271 - val_loss: 1423.2548\n",
            "Epoch 331/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1442.8112 - val_loss: 1422.3235\n",
            "Epoch 332/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1654.1473 - val_loss: 1421.6628\n",
            "Epoch 333/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1425.1855 - val_loss: 1420.8470\n",
            "Epoch 334/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1527.3875 - val_loss: 1420.0280\n",
            "Epoch 335/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1320.3876 - val_loss: 1419.1733\n",
            "Epoch 336/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1353.8873 - val_loss: 1418.3149\n",
            "Epoch 337/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1395.4298 - val_loss: 1417.4779\n",
            "Epoch 338/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1489.9842 - val_loss: 1416.8622\n",
            "Epoch 339/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1293.3727 - val_loss: 1416.2078\n",
            "Epoch 340/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1534.4494 - val_loss: 1415.4492\n",
            "Epoch 341/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1319.3034 - val_loss: 1415.4955\n",
            "Epoch 342/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1367.8410 - val_loss: 1414.3925\n",
            "Epoch 343/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1407.7201 - val_loss: 1413.7408\n",
            "Epoch 344/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1429.9959 - val_loss: 1413.0824\n",
            "Epoch 345/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1517.2097 - val_loss: 1412.4673\n",
            "Epoch 346/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1380.5697 - val_loss: 1411.5929\n",
            "Epoch 347/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1535.9760 - val_loss: 1411.2623\n",
            "Epoch 348/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1461.8436 - val_loss: 1410.6799\n",
            "Epoch 349/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1451.9188 - val_loss: 1409.8269\n",
            "Epoch 350/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1601.8427 - val_loss: 1409.1466\n",
            "Epoch 351/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1434.4451 - val_loss: 1408.9200\n",
            "Epoch 352/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1288.3841 - val_loss: 1408.2264\n",
            "Epoch 353/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1249.3025 - val_loss: 1407.4775\n",
            "Epoch 354/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1369.0464 - val_loss: 1406.9976\n",
            "Epoch 355/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1395.0318 - val_loss: 1406.1312\n",
            "Epoch 356/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1442.0552 - val_loss: 1405.9218\n",
            "Epoch 357/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1323.6643 - val_loss: 1405.0214\n",
            "Epoch 358/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1425.7792 - val_loss: 1404.4901\n",
            "Epoch 359/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1584.1897 - val_loss: 1403.8245\n",
            "Epoch 360/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1407.5778 - val_loss: 1403.5659\n",
            "Epoch 361/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1454.9342 - val_loss: 1402.5579\n",
            "Epoch 362/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1402.1011 - val_loss: 1402.0839\n",
            "Epoch 363/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1428.8777 - val_loss: 1401.5502\n",
            "Epoch 364/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1339.5630 - val_loss: 1401.3101\n",
            "Epoch 365/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1228.8066 - val_loss: 1400.5709\n",
            "Epoch 366/550\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1210.4474 - val_loss: 1400.0531\n",
            "Epoch 367/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1448.1136 - val_loss: 1399.4026\n",
            "Epoch 368/550\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1341.7350 - val_loss: 1398.6515\n",
            "Epoch 369/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1336.7032 - val_loss: 1399.0056\n",
            "Epoch 370/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1509.3176 - val_loss: 1397.8442\n",
            "Epoch 371/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1442.2615 - val_loss: 1397.0653\n",
            "Epoch 372/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1317.0807 - val_loss: 1396.4720\n",
            "Epoch 373/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1357.4885 - val_loss: 1396.0220\n",
            "Epoch 374/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1475.1413 - val_loss: 1396.3580\n",
            "Epoch 375/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1262.0571 - val_loss: 1395.3392\n",
            "Epoch 376/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1408.1943 - val_loss: 1394.9972\n",
            "Epoch 377/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1456.0511 - val_loss: 1394.9211\n",
            "Epoch 378/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1628.1256 - val_loss: 1394.0046\n",
            "Epoch 379/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1513.4691 - val_loss: 1393.5380\n",
            "Epoch 380/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1466.0739 - val_loss: 1393.2820\n",
            "Epoch 381/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1376.8829 - val_loss: 1393.7041\n",
            "Epoch 382/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1372.4463 - val_loss: 1392.3899\n",
            "Epoch 383/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1314.9240 - val_loss: 1392.3101\n",
            "Epoch 384/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1383.1687 - val_loss: 1391.4619\n",
            "Epoch 385/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1423.5629 - val_loss: 1391.2889\n",
            "Epoch 386/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1301.1596 - val_loss: 1390.7507\n",
            "Epoch 387/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1229.2948 - val_loss: 1390.2640\n",
            "Epoch 388/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1430.8177 - val_loss: 1390.2159\n",
            "Epoch 389/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1282.5459 - val_loss: 1389.3068\n",
            "Epoch 390/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1478.9669 - val_loss: 1389.1500\n",
            "Epoch 391/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1495.0562 - val_loss: 1388.5822\n",
            "Epoch 392/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1223.6803 - val_loss: 1388.0392\n",
            "Epoch 393/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1386.6532 - val_loss: 1388.0415\n",
            "Epoch 394/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1328.4478 - val_loss: 1387.4672\n",
            "Epoch 395/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1334.2461 - val_loss: 1386.7811\n",
            "Epoch 396/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1511.8686 - val_loss: 1386.4255\n",
            "Epoch 397/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1389.2759 - val_loss: 1386.1075\n",
            "Epoch 398/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1368.2473 - val_loss: 1385.6874\n",
            "Epoch 399/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1247.9953 - val_loss: 1385.1771\n",
            "Epoch 400/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1290.4221 - val_loss: 1385.3112\n",
            "Epoch 401/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1524.5440 - val_loss: 1384.3932\n",
            "Epoch 402/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1431.8141 - val_loss: 1384.1095\n",
            "Epoch 403/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1468.1764 - val_loss: 1383.6555\n",
            "Epoch 404/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1460.1807 - val_loss: 1383.2722\n",
            "Epoch 405/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1413.8585 - val_loss: 1382.3242\n",
            "Epoch 406/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1280.6435 - val_loss: 1382.0447\n",
            "Epoch 407/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1436.4998 - val_loss: 1381.9078\n",
            "Epoch 408/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1471.8172 - val_loss: 1381.3138\n",
            "Epoch 409/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1380.3377 - val_loss: 1380.5900\n",
            "Epoch 410/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1521.7906 - val_loss: 1379.9919\n",
            "Epoch 411/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1398.0717 - val_loss: 1379.5077\n",
            "Epoch 412/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1451.7454 - val_loss: 1378.9669\n",
            "Epoch 413/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1419.9278 - val_loss: 1378.9982\n",
            "Epoch 414/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1423.7277 - val_loss: 1377.9565\n",
            "Epoch 415/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1366.5017 - val_loss: 1377.9053\n",
            "Epoch 416/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1348.9584 - val_loss: 1376.8456\n",
            "Epoch 417/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1337.9620 - val_loss: 1376.6040\n",
            "Epoch 418/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1258.5481 - val_loss: 1375.7976\n",
            "Epoch 419/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1355.9801 - val_loss: 1375.6738\n",
            "Epoch 420/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1225.7242 - val_loss: 1374.7588\n",
            "Epoch 421/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1321.1934 - val_loss: 1374.1198\n",
            "Epoch 422/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1317.0487 - val_loss: 1373.5580\n",
            "Epoch 423/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1354.7412 - val_loss: 1373.4695\n",
            "Epoch 424/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1439.8461 - val_loss: 1372.7222\n",
            "Epoch 425/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1481.6972 - val_loss: 1371.7704\n",
            "Epoch 426/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1268.2516 - val_loss: 1371.2412\n",
            "Epoch 427/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1419.1513 - val_loss: 1370.6249\n",
            "Epoch 428/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1405.1252 - val_loss: 1370.0859\n",
            "Epoch 429/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1370.6064 - val_loss: 1369.5774\n",
            "Epoch 430/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1458.0215 - val_loss: 1368.9833\n",
            "Epoch 431/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1458.6615 - val_loss: 1368.8036\n",
            "Epoch 432/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1472.8548 - val_loss: 1369.1378\n",
            "Epoch 433/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1304.1828 - val_loss: 1367.7302\n",
            "Epoch 434/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1507.2688 - val_loss: 1366.9021\n",
            "Epoch 435/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1366.0953 - val_loss: 1366.4716\n",
            "Epoch 436/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1377.7129 - val_loss: 1366.0924\n",
            "Epoch 437/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1184.6854 - val_loss: 1365.6730\n",
            "Epoch 438/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1427.7965 - val_loss: 1365.2993\n",
            "Epoch 439/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1490.4543 - val_loss: 1364.7950\n",
            "Epoch 440/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1583.3470 - val_loss: 1364.1475\n",
            "Epoch 441/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1389.9322 - val_loss: 1363.5698\n",
            "Epoch 442/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1425.2218 - val_loss: 1363.2129\n",
            "Epoch 443/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1345.8368 - val_loss: 1362.6373\n",
            "Epoch 444/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1370.9231 - val_loss: 1362.1211\n",
            "Epoch 445/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1366.1207 - val_loss: 1361.7268\n",
            "Epoch 446/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1293.5345 - val_loss: 1361.1017\n",
            "Epoch 447/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1376.7630 - val_loss: 1360.5756\n",
            "Epoch 448/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1420.5966 - val_loss: 1359.9683\n",
            "Epoch 449/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1277.2183 - val_loss: 1356.9803\n",
            "Epoch 450/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1310.5170 - val_loss: 1356.0413\n",
            "Epoch 451/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1450.4426 - val_loss: 1358.8639\n",
            "Epoch 452/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1442.6766 - val_loss: 1361.9252\n",
            "Epoch 453/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1396.5513 - val_loss: 1361.4419\n",
            "Epoch 454/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1522.0725 - val_loss: 1360.2872\n",
            "Epoch 455/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1353.7338 - val_loss: 1356.8306\n",
            "Epoch 456/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1430.8693 - val_loss: 1354.8192\n",
            "Epoch 457/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1298.8863 - val_loss: 1348.5315\n",
            "Epoch 458/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1314.4486 - val_loss: 1344.7819\n",
            "Epoch 459/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1469.5362 - val_loss: 1339.5760\n",
            "Epoch 460/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1342.4214 - val_loss: 1334.8755\n",
            "Epoch 461/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1357.2615 - val_loss: 1338.5853\n",
            "Epoch 462/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1331.3094 - val_loss: 1337.7639\n",
            "Epoch 463/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1363.8036 - val_loss: 1340.6342\n",
            "Epoch 464/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1227.4554 - val_loss: 1337.5809\n",
            "Epoch 465/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1491.5414 - val_loss: 1329.9611\n",
            "Epoch 466/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1450.8769 - val_loss: 1329.6622\n",
            "Epoch 467/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1289.3979 - val_loss: 1328.9263\n",
            "Epoch 468/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1404.2940 - val_loss: 1327.6393\n",
            "Epoch 469/550\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1220.2396 - val_loss: 1326.6670\n",
            "Epoch 470/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1401.3774 - val_loss: 1326.8877\n",
            "Epoch 471/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1603.9080 - val_loss: 1331.1849\n",
            "Epoch 472/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1304.3801 - val_loss: 1329.5320\n",
            "Epoch 473/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1262.3305 - val_loss: 1320.0608\n",
            "Epoch 474/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1208.3894 - val_loss: 1318.4490\n",
            "Epoch 475/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1350.7367 - val_loss: 1320.6171\n",
            "Epoch 476/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1315.0906 - val_loss: 1319.6958\n",
            "Epoch 477/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1278.1970 - val_loss: 1318.6584\n",
            "Epoch 478/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1397.9981 - val_loss: 1317.9341\n",
            "Epoch 479/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1338.2634 - val_loss: 1317.3005\n",
            "Epoch 480/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1232.3030 - val_loss: 1316.2719\n",
            "Epoch 481/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1260.1484 - val_loss: 1315.7817\n",
            "Epoch 482/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1260.4560 - val_loss: 1314.4764\n",
            "Epoch 483/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1247.0107 - val_loss: 1313.9253\n",
            "Epoch 484/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1232.6881 - val_loss: 1318.1707\n",
            "Epoch 485/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1334.9130 - val_loss: 1315.2605\n",
            "Epoch 486/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1469.5754 - val_loss: 1315.8635\n",
            "Epoch 487/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1338.1386 - val_loss: 1312.2537\n",
            "Epoch 488/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1387.9618 - val_loss: 1314.7993\n",
            "Epoch 489/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1282.0373 - val_loss: 1313.4756\n",
            "Epoch 490/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1281.6078 - val_loss: 1311.2634\n",
            "Epoch 491/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1348.4607 - val_loss: 1308.9526\n",
            "Epoch 492/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1355.0222 - val_loss: 1312.3003\n",
            "Epoch 493/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1297.1915 - val_loss: 1320.5221\n",
            "Epoch 494/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1356.9524 - val_loss: 1316.2390\n",
            "Epoch 495/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1147.2498 - val_loss: 1315.4301\n",
            "Epoch 496/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1335.6436 - val_loss: 1309.8146\n",
            "Epoch 497/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1368.5463 - val_loss: 1309.7427\n",
            "Epoch 498/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1212.5372 - val_loss: 1307.9659\n",
            "Epoch 499/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1349.2844 - val_loss: 1306.5829\n",
            "Epoch 500/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1324.7742 - val_loss: 1305.5431\n",
            "Epoch 501/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1360.0089 - val_loss: 1308.6238\n",
            "Epoch 502/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1309.2579 - val_loss: 1308.7479\n",
            "Epoch 503/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1427.3768 - val_loss: 1312.4830\n",
            "Epoch 504/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1418.9046 - val_loss: 1301.2992\n",
            "Epoch 505/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1129.8378 - val_loss: 1301.7401\n",
            "Epoch 506/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1046.4491 - val_loss: 1300.6294\n",
            "Epoch 507/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1366.2610 - val_loss: 1321.4080\n",
            "Epoch 508/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1307.1062 - val_loss: 1329.6835\n",
            "Epoch 509/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1390.1983 - val_loss: 1328.7155\n",
            "Epoch 510/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1464.1540 - val_loss: 1328.3921\n",
            "Epoch 511/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1546.1879 - val_loss: 1327.6428\n",
            "Epoch 512/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1369.6266 - val_loss: 1326.3147\n",
            "Epoch 513/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1164.9513 - val_loss: 1320.2411\n",
            "Epoch 514/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1197.2033 - val_loss: 1317.2102\n",
            "Epoch 515/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1335.4423 - val_loss: 1315.5234\n",
            "Epoch 516/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1146.1705 - val_loss: 1314.4302\n",
            "Epoch 517/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1228.9960 - val_loss: 1313.3228\n",
            "Epoch 518/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1365.7116 - val_loss: 1312.6262\n",
            "Epoch 519/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1269.8346 - val_loss: 1311.2725\n",
            "Epoch 520/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1254.4974 - val_loss: 1311.3883\n",
            "Epoch 521/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1490.1744 - val_loss: 1303.3370\n",
            "Epoch 522/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1383.6628 - val_loss: 1288.9559\n",
            "Epoch 523/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1334.0315 - val_loss: 1303.9478\n",
            "Epoch 524/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1439.0102 - val_loss: 1298.5675\n",
            "Epoch 525/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1288.0777 - val_loss: 1294.1847\n",
            "Epoch 526/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1301.2614 - val_loss: 1285.5952\n",
            "Epoch 527/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1205.9837 - val_loss: 1287.7314\n",
            "Epoch 528/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1164.6772 - val_loss: 1297.0424\n",
            "Epoch 529/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1220.4650 - val_loss: 1292.5132\n",
            "Epoch 530/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1483.5181 - val_loss: 1301.6608\n",
            "Epoch 531/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1548.4503 - val_loss: 1300.9503\n",
            "Epoch 532/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1410.5103 - val_loss: 1300.2457\n",
            "Epoch 533/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1277.0010 - val_loss: 1299.0922\n",
            "Epoch 534/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1124.1415 - val_loss: 1298.3164\n",
            "Epoch 535/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1305.1548 - val_loss: 1297.7285\n",
            "Epoch 536/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1221.7958 - val_loss: 1297.2308\n",
            "Epoch 537/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1185.7653 - val_loss: 1296.3358\n",
            "Epoch 538/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1259.5520 - val_loss: 1296.3905\n",
            "Epoch 539/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1178.9196 - val_loss: 1294.9225\n",
            "Epoch 540/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1379.7189 - val_loss: 1294.2073\n",
            "Epoch 541/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1304.1115 - val_loss: 1292.9648\n",
            "Epoch 542/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1244.9580 - val_loss: 1292.4781\n",
            "Epoch 543/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1385.6986 - val_loss: 1291.3002\n",
            "Epoch 544/550\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1405.7618 - val_loss: 1290.6367\n",
            "Epoch 545/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1256.2530 - val_loss: 1287.8627\n",
            "Epoch 546/550\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1321.4095 - val_loss: 1278.2728\n",
            "Epoch 547/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1320.6640 - val_loss: 1276.1688\n",
            "Epoch 548/550\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1324.1282 - val_loss: 1306.5248\n",
            "Epoch 549/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1345.5457 - val_loss: 1310.4513\n",
            "Epoch 550/550\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1178.9744 - val_loss: 1284.0663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMlcJAHyMHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "84d4f2ea-21ab-4f93-d737-8d92323b7cce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['training'])\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTcpQhNZYAH"
      },
      "source": [
        "#saving a model\n",
        "\n",
        "model.save(\"covid_prediction.h5\")\n",
        "!cp \"covid_prediction.h5\" \"/content/gdrive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAfI5HUVapfP",
        "outputId": "14454f4d-a13b-4198-aef2-50c55f3d6cca"
      },
      "source": [
        "#loading a model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/gdrive/My Drive/covid_prediction.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "UlZ9xkvTFg3N",
        "outputId": "0ce03e57-b703-407d-ec12-bd40da3c3ae2"
      },
      "source": [
        "prediction = model.predict(Y)\n",
        "close_test = Y.reshape((-1))\n",
        "prediction = prediction.reshape((-1))\n",
        "\n",
        "absolute_errors = np.abs(np.subtract(close_test, prediction))\n",
        "relative_errors = np.divide(absolute_errors, close_test) * 100\n",
        "\n",
        "trace2 = go.Scatter(\n",
        "    x = [i for i in range (0, 199)],\n",
        "    y = prediction,\n",
        "    name = 'Prediction',\n",
        "    mode='lines',\n",
        "    line=dict(width=4, color='Green')\n",
        ")\n",
        "trace3 = go.Scatter(\n",
        "    x = [i for i in range (0, 199)],\n",
        "    y = close_test,\n",
        "    mode='markers+lines',\n",
        "    name = 'Test Data'\n",
        ")\n",
        "layout = go.Layout(\n",
        "    title = \"Covid Cases\",\n",
        "    xaxis = {'title' : \"Date\"},\n",
        "    yaxis = {'title' : \"Cases\"}\n",
        ")\n",
        "fig = go.Figure(data=[trace2, trace3], layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 14, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14, 1), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"3b2ffc97-4078-41a0-ba7d-5fd159dbd416\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"3b2ffc97-4078-41a0-ba7d-5fd159dbd416\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '3b2ffc97-4078-41a0-ba7d-5fd159dbd416',\n",
              "                        [{\"line\": {\"color\": \"Green\", \"width\": 4}, \"mode\": \"lines\", \"name\": \"Prediction\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198], \"y\": [7540.734375, 6893.966796875, 5649.38720703125, 3165.875732421875, 4632.634765625, 6565.4052734375, 6626.5986328125, 6330.04638671875, 5963.8271484375, 4327.6083984375, 2546.409912109375, 4362.4423828125, 6421.365234375, 6763.10791015625, 5814.13818359375, 5549.5947265625, 4464.11669921875, 2386.36572265625, 4101.66455078125, 6431.72119140625, 6143.6416015625, 5727.5263671875, 5645.62060546875, 4477.29736328125, 2317.640869140625, 3793.81396484375, 6581.41015625, 6631.3056640625, 6033.49365234375, 6228.37158203125, 5050.6328125, 2422.140380859375, 4901.88623046875, 8218.568359375, 8571.607421875, 8287.2939453125, 8039.6962890625, 6656.72509765625, 3692.138916015625, 5963.8271484375, 11464.6455078125, 11460.8798828125, 10889.4267578125, 11417.5732421875, 9538.4638671875, 4534.7255859375, 7500.25244140625, 14807.6884765625, 14388.748046875, 14932.8994140625, 14014.056640625, 12803.3681640625, 5836.732421875, 9399.130859375, 16294.2177734375, 19903.6875, 17796.75390625, 19858.501953125, 16289.5107421875, 10285.9658203125, 13580.0546875, 23614.83203125, 25705.767578125, 24502.609375, 24935.673828125, 20599.408203125, 13754.2197265625, 15788.66796875, 29027.158203125, 32179.0859375, 33115.8203125, 29928.115234375, 27581.111328125, 16008.021484375, 19669.271484375, 30993.822265625, 33217.49609375, 28781.443359375, 26457.974609375, 21642.525390625, 9369.005859375, 7792.0986328125, 14063.9541015625, 26285.693359375, 26859.02734375, 23463.263671875, 20489.259765625, 11341.31640625, 12458.8017578125, 20049.609375, 19917.810546875, 16829.89453125, 14890.53515625, 11468.4111328125, 6903.3818359375, 8731.6533203125, 13135.6962890625, 12044.5712890625, 10258.6650390625, 8982.0751953125, 6829.94873046875, 3292.9697265625, 5405.5546875, 8401.2080078125, 7961.55810546875, 6420.42431640625, 6124.8125, 4374.68115234375, 2404.252685546875, 2190.546630859375, 3699.67041015625, 6079.6240234375, 5721.8779296875, 4520.60400390625, 3659.18896484375, 1941.065673828125, 2944.637939453125, 3745.801025390625, 3506.676025390625, 3125.393798828125, 2756.350341796875, 2070.984130859375, 1074.943359375, 1654.868896484375, 2239.501220703125, 1993.786376953125, 1608.738525390625, 1457.1669921875, 1041.0517578125, 555.2697143554688, 970.4437866210938, 1221.8076171875, 1184.150146484375, 919.6063232421875, 758.6205444335938, 574.0984497070312, 342.484130859375, 582.5714111328125]}, {\"mode\": \"markers+lines\", \"name\": \"Test Data\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198], \"y\": [7979, 7292, 5970, 3332, 4890, 6943, 7008, 6693, 6304, 4566, 2674, 4603, 6790, 7153, 6145, 5864, 4711, 2504, 4326, 6801, 6495, 6053, 5966, 4725, 2431, 3999, 6960, 7013, 6378, 6585, 5334, 2542, 5176, 8699, 9074, 8772, 8509, 7040, 3891, 6304, 12147, 12143, 11536, 12097, 10101, 4786, 7936, 15698, 15253, 15831, 14855, 13569, 6169, 9953, 17277, 21111, 18873, 21063, 17272, 10895, 14394, 25053, 27274, 25996, 26456, 21850, 14579, 16740, 30802, 34150, 35145, 31759, 29266, 16973, 20862, 32891, 35253, 30541, 28073, 22958, 9921, 8246, 14908, 27890, 28499, 24892, 21733, 12016, 13203, 21266, 21126, 17846, 15786, 12151, 7302, 9244, 13922, 12763, 10866, 9510, 7224, 3467, 5711, 8893, 8426, 6789, 6475, 4616, 2523, 2296, 3899, 6427, 6047, 4771, 3856, 2031, 3097, 3948, 3694, 3289, 2897, 2169, 1111, 1727, 2348, 2087, 1678, 1517, 1075, 559, 1000, 1267, 1227, 946, 775, 579, 333, 588]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Covid Cases\"}, \"xaxis\": {\"title\": {\"text\": \"Date\"}}, \"yaxis\": {\"title\": {\"text\": \"Cases\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3b2ffc97-4078-41a0-ba7d-5fd159dbd416');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkM4Jt9-6ssT",
        "outputId": "962d91dc-7d0c-45f5-8451-af55a13dbc86"
      },
      "source": [
        "# The median of absolute errors\n",
        "print(\"Mediana bedu bezwzgldnego wynosi: \" + str(np.median(absolute_errors)))\n",
        "print(\"Najwieksza pomyka wynosi blisko: \"+ str(int(np.ceil(max(relative_errors)))) + \" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mediana bedu bezwzgldnego wynosi: 382.484619140625\n",
            "Najwieksza pomyka wynosi blisko: 6 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqAnI6LoVAn_",
        "outputId": "bd51f4ec-b9cd-4cee-8561-4d6e8443f13e"
      },
      "source": [
        "np.argmax(relative_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO6Cq23g805i",
        "outputId": "e3ebfb1d-e028-43e3-8ef7-6be01a126cd3"
      },
      "source": [
        "# Relative errors [%]\n",
        "np.round(relative_errors, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.49, 5.46, 5.37, 4.99, 5.26, 5.44, 5.44, 5.42, 5.4 , 5.22, 4.77,\n",
              "       5.23, 5.43, 5.45, 5.38, 5.36, 5.24, 4.7 , 5.19, 5.43, 5.41, 5.38,\n",
              "       5.37, 5.24, 4.66, 5.13, 5.44, 5.44, 5.4 , 5.42, 5.31, 4.72, 5.3 ,\n",
              "       5.52, 5.54, 5.53, 5.52, 5.44, 5.11, 5.4 , 5.62, 5.62, 5.6 , 5.62,\n",
              "       5.57, 5.25, 5.49, 5.67, 5.67, 5.67, 5.66, 5.64, 5.39, 5.56, 5.69,\n",
              "       5.72, 5.7 , 5.72, 5.69, 5.59, 5.65, 5.74, 5.75, 5.74, 5.75, 5.72,\n",
              "       5.66, 5.68, 5.76, 5.77, 5.77, 5.76, 5.76, 5.69, 5.72, 5.77, 5.77,\n",
              "       5.76, 5.75, 5.73, 5.56, 5.5 , 5.66, 5.75, 5.75, 5.74, 5.72, 5.61,\n",
              "       5.64, 5.72, 5.72, 5.69, 5.67, 5.62, 5.46, 5.54, 5.65, 5.63, 5.59,\n",
              "       5.55, 5.45, 5.02, 5.35, 5.53, 5.51, 5.43, 5.41, 5.23, 4.71, 4.59,\n",
              "       5.11, 5.4 , 5.38, 5.25, 5.1 , 4.43, 4.92, 5.12, 5.07, 4.97, 4.86,\n",
              "       4.52, 3.25, 4.18, 4.62, 4.47, 4.13, 3.94, 3.16, 0.67, 2.96, 3.57,\n",
              "       3.49, 2.79, 2.11, 0.85, 2.85, 0.92])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lppqRsrHyGaI",
        "outputId": "bc8a6f77-0816-4cf3-c718-6d2853a2bd01"
      },
      "source": [
        "#next day covid cases prediction\n",
        "def predict_next_day(test_data):\n",
        "  test_data = test_data.reshape((1, 14, n_features))\n",
        "  return int(np.round(model.predict(test_data, verbose=1)))\n",
        "next_day = predict_next_day(np.array(cases[-14:]))\n",
        "print(next_day)\n",
        "print(\"Przewidywany margines bdu: [\" + str(np.round(next_day - np.median((relative_errors/100)*next_day))) + \" ; \" +  str(np.round(next_day + np.median((relative_errors/100)*next_day))) + \"]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "502\n",
            "Przewidywany margines bdu: [475.0 ; 529.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ed_oBnUWJb-",
        "outputId": "58fc3054-274e-448f-e956-b01dc74f7aaf"
      },
      "source": [
        "np.median(absolute_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "382.484619140625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsHbfapDLaa5",
        "outputId": "95b746f9-a611-4e49-b490-a6801c8db77d"
      },
      "source": [
        "#coefficient of variance\n",
        "np.std(cases)/np.mean(cases) * 100 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.83784931354369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLKkytzdHg8k",
        "outputId": "78ac8e7e-ed69-4ca6-f946-4b8920f5c13c"
      },
      "source": [
        "len(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPRke2yOEhq3",
        "outputId": "4ccd9cfa-ed3f-4c89-9816-c7233f4dea4a"
      },
      "source": [
        "len(close_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}