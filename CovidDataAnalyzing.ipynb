{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovidDataAnalyzing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+PywqPTASMkvG/f15pYj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itrail/CovidDataAnalyzing/blob/main/CovidDataAnalyzing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvzhk04YYklr",
        "outputId": "62da0d68-8c34-4ce6-f715-c5de337f3d4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5edWpu_mXuR3"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import json\n",
        "from itertools import islice\n",
        "from datetime import timedelta, date, datetime, timezone\n",
        "from openpyxl import load_workbook\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objects as go\n",
        "from numpy import mean, average\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHG73YdD3lu7"
      },
      "source": [
        "#creating json file with excel covid19 data \n",
        "\n",
        "def create_json():\n",
        "  covid_data = []\n",
        "  #open a spreadsheet and sheet\n",
        "  wb = load_workbook('covid19.xlsx')\n",
        "  sheet = wb['newCases2021']\n",
        "\n",
        "  #copy row by row with loop\n",
        "  for row in islice(sheet.values, 1, sheet.max_row):\n",
        "      data = OrderedDict()\n",
        "      day = row[0]\n",
        "      day  = day.strftime(\"%d.%m.%Y\")\n",
        "      data['date'] = day\n",
        "      data['cases'] = str(row[1])\n",
        "      covid_data.append(data)\n",
        "  newlist = sorted(covid_data, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "  j = json.dumps(newlist) \n",
        "\n",
        "  #save data in json file\n",
        "  with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vmjpa4BCZsP"
      },
      "source": [
        "def update_json():\n",
        "  with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "    json_object = json.load(f)\n",
        "    f.close()\n",
        "  #open a spreadsheet and sheet\n",
        "  wb = load_workbook('covid19.xlsx')\n",
        "  sheet = wb['newCases2020']\n",
        "\n",
        "  #copy row by row with loop\n",
        "  for row in islice(sheet.values, 1, sheet.max_row):\n",
        "      data = OrderedDict()\n",
        "      day = row[0]\n",
        "      day  = day.strftime(\"%d.%m.%Y\")\n",
        "      data['date'] = day\n",
        "      data['cases'] = str(row[1])\n",
        "      json_object.append(data)\n",
        "  newlist = sorted(json_object, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "  j = json.dumps(newlist) \n",
        "  with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)\n",
        "\n",
        "#update_json()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLhM0pGa9TZJ"
      },
      "source": [
        "#create_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgwePQKFsvkw",
        "outputId": "b24ea3c6-b551-46b1-8b01-6be5d52876f3"
      },
      "source": [
        "import requests\n",
        "\n",
        "#data actualization\n",
        "covid_data=[]\n",
        "#url of webpage with covid data\n",
        "url = 'https://www.worldometers.info/coronavirus/country/poland/'\n",
        "\n",
        "#get the page content\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "#find lists, here's data about new cases and deaths\n",
        "data_iterator = iter(soup.find_all('li', {'class': 'news_li'}))\n",
        "\n",
        "#delta is variable to substracting date, if its before 12 data probably hasn't been updated\n",
        "now = datetime.now(timezone(timedelta(hours=2)))\n",
        "if now.hour >= 11:\n",
        "  delta = 0\n",
        "else:\n",
        "  delta = 1\n",
        "\n",
        "#getting todays date\n",
        "today = date.today()\n",
        "#loop for all obtained data\n",
        "with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "  json_object = json.load(f)\n",
        "  f.close()\n",
        "days = []\n",
        "for item in json_object:\n",
        "  days.append(item['date'])\n",
        "iterator = 0;\n",
        "while True:\n",
        "    try:\n",
        "      #substracting dates\n",
        "      day  = today - timedelta(days=delta)\n",
        "      day  = day .strftime(\"%d.%m.%Y\")\n",
        "      #getting the next row and cleaning the info\n",
        "      newData = next(data_iterator).text\n",
        "      newData = newData.split(\" new cases and \", 1)\n",
        "      newCases = newData[0]\n",
        "      newDeaths= newData[1].replace(' new deaths in Poland\\xa0[source]', '')\n",
        "      newCases = newCases.replace(',', '')\n",
        "      data = {\"date\": day, \"cases\": newCases, }\n",
        "\n",
        "      #saving data if is not in json file\n",
        "      if data['date'] not in days:\n",
        "        print(data)\n",
        "        json_object.append(data)\n",
        "        \n",
        "      print(day  + \": \" + newCases)\n",
        "      delta += 1\n",
        "      iterator += 1\n",
        "    except StopIteration:\n",
        "      break\n",
        "\n",
        "#sorting by dates\n",
        "newlist = sorted(json_object, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "j = json.dumps(newlist) \n",
        "with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'date': '21.06.2021', 'cases': '73'}\n",
            "21.06.2021: 73\n",
            "20.06.2021: 133\n",
            "19.06.2021: 168\n",
            "18.06.2021: 190\n",
            "17.06.2021: 218\n",
            "16.06.2021: 238\n",
            "15.06.2021: 216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQZjLbxD6v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c4902f-cf18-413d-8f34-7bf03f820634"
      },
      "source": [
        "#print the data\n",
        "with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "  json_object = json.load(f)\n",
        "  f.close()\n",
        "\n",
        "cases = []\n",
        "days = []\n",
        "for item in json_object:\n",
        "  print(item)\n",
        "  cases.append(int(item['cases']))\n",
        "  days.append(item['date'])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'date': '27.02.2020', 'cases': '0'}\n",
            "{'date': '28.02.2020', 'cases': '0'}\n",
            "{'date': '29.02.2020', 'cases': '0'}\n",
            "{'date': '01.03.2020', 'cases': '0'}\n",
            "{'date': '02.03.2020', 'cases': '0'}\n",
            "{'date': '03.03.2020', 'cases': '0'}\n",
            "{'date': '04.03.2020', 'cases': '1'}\n",
            "{'date': '05.03.2020', 'cases': '0'}\n",
            "{'date': '06.03.2020', 'cases': '4'}\n",
            "{'date': '07.03.2020', 'cases': '1'}\n",
            "{'date': '08.03.2020', 'cases': '5'}\n",
            "{'date': '09.03.2020', 'cases': '6'}\n",
            "{'date': '10.03.2020', 'cases': '5'}\n",
            "{'date': '11.03.2020', 'cases': '9'}\n",
            "{'date': '12.03.2020', 'cases': '20'}\n",
            "{'date': '13.03.2020', 'cases': '17'}\n",
            "{'date': '14.03.2020', 'cases': '36'}\n",
            "{'date': '15.03.2020', 'cases': '21'}\n",
            "{'date': '16.03.2020', 'cases': '52'}\n",
            "{'date': '17.03.2020', 'cases': '61'}\n",
            "{'date': '18.03.2020', 'cases': '49'}\n",
            "{'date': '19.03.2020', 'cases': '68'}\n",
            "{'date': '20.03.2020', 'cases': '70'}\n",
            "{'date': '21.03.2020', 'cases': '111'}\n",
            "{'date': '22.03.2020', 'cases': '98'}\n",
            "{'date': '23.03.2020', 'cases': '116'}\n",
            "{'date': '24.03.2020', 'cases': '152'}\n",
            "{'date': '25.03.2020', 'cases': '150'}\n",
            "{'date': '26.03.2020', 'cases': '170'}\n",
            "{'date': '27.03.2020', 'cases': '168'}\n",
            "{'date': '28.03.2020', 'cases': '249'}\n",
            "{'date': '29.03.2020', 'cases': '224'}\n",
            "{'date': '30.03.2020', 'cases': '193'}\n",
            "{'date': '31.03.2020', 'cases': '256'}\n",
            "{'date': '01.04.2020', 'cases': '243'}\n",
            "{'date': '02.04.2020', 'cases': '392'}\n",
            "{'date': '03.04.2020', 'cases': '437'}\n",
            "{'date': '04.04.2020', 'cases': '244'}\n",
            "{'date': '05.04.2020', 'cases': '475'}\n",
            "{'date': '06.04.2020', 'cases': '311'}\n",
            "{'date': '07.04.2020', 'cases': '435'}\n",
            "{'date': '08.04.2020', 'cases': '357'}\n",
            "{'date': '09.04.2020', 'cases': '370'}\n",
            "{'date': '10.04.2020', 'cases': '380'}\n",
            "{'date': '11.04.2020', 'cases': '401'}\n",
            "{'date': '12.04.2020', 'cases': '318'}\n",
            "{'date': '13.04.2020', 'cases': '260'}\n",
            "{'date': '14.04.2020', 'cases': '268'}\n",
            "{'date': '15.04.2020', 'cases': '380'}\n",
            "{'date': '16.04.2020', 'cases': '336'}\n",
            "{'date': '17.04.2020', 'cases': '457'}\n",
            "{'date': '18.04.2020', 'cases': '334'}\n",
            "{'date': '19.04.2020', 'cases': '515'}\n",
            "{'date': '20.04.2020', 'cases': '306'}\n",
            "{'date': '21.04.2020', 'cases': '263'}\n",
            "{'date': '22.04.2020', 'cases': '313'}\n",
            "{'date': '23.04.2020', 'cases': '342'}\n",
            "{'date': '24.04.2020', 'cases': '381'}\n",
            "{'date': '25.04.2020', 'cases': '381'}\n",
            "{'date': '26.04.2020', 'cases': '344'}\n",
            "{'date': '27.04.2020', 'cases': '285'}\n",
            "{'date': '28.04.2020', 'cases': '316'}\n",
            "{'date': '29.04.2020', 'cases': '422'}\n",
            "{'date': '30.04.2020', 'cases': '300'}\n",
            "{'date': '01.05.2020', 'cases': '228'}\n",
            "{'date': '02.05.2020', 'cases': '270'}\n",
            "{'date': '03.05.2020', 'cases': '318'}\n",
            "{'date': '04.05.2020', 'cases': '313'}\n",
            "{'date': '05.05.2020', 'cases': '406'}\n",
            "{'date': '06.05.2020', 'cases': '311'}\n",
            "{'date': '07.05.2020', 'cases': '303'}\n",
            "{'date': '08.05.2020', 'cases': '337'}\n",
            "{'date': '09.05.2020', 'cases': '288'}\n",
            "{'date': '10.05.2020', 'cases': '345'}\n",
            "{'date': '11.05.2020', 'cases': '330'}\n",
            "{'date': '12.05.2020', 'cases': '556'}\n",
            "{'date': '13.05.2020', 'cases': '322'}\n",
            "{'date': '14.05.2020', 'cases': '411'}\n",
            "{'date': '15.05.2020', 'cases': '401'}\n",
            "{'date': '16.05.2020', 'cases': '241'}\n",
            "{'date': '17.05.2020', 'cases': '272'}\n",
            "{'date': '18.05.2020', 'cases': '356'}\n",
            "{'date': '19.05.2020', 'cases': '382'}\n",
            "{'date': '20.05.2020', 'cases': '471'}\n",
            "{'date': '21.05.2020', 'cases': '403'}\n",
            "{'date': '22.05.2020', 'cases': '472'}\n",
            "{'date': '23.05.2020', 'cases': '316'}\n",
            "{'date': '24.05.2020', 'cases': '361'}\n",
            "{'date': '25.05.2020', 'cases': '341'}\n",
            "{'date': '26.05.2020', 'cases': '443'}\n",
            "{'date': '27.05.2020', 'cases': '396'}\n",
            "{'date': '28.05.2020', 'cases': '352'}\n",
            "{'date': '29.05.2020', 'cases': '333'}\n",
            "{'date': '30.05.2020', 'cases': '412'}\n",
            "{'date': '31.05.2020', 'cases': '219'}\n",
            "{'date': '01.06.2020', 'cases': '374'}\n",
            "{'date': '02.06.2020', 'cases': '236'}\n",
            "{'date': '03.06.2020', 'cases': '292'}\n",
            "{'date': '04.06.2020', 'cases': '361'}\n",
            "{'date': '05.06.2020', 'cases': '362'}\n",
            "{'date': '06.06.2020', 'cases': '576'}\n",
            "{'date': '07.06.2020', 'cases': '575'}\n",
            "{'date': '08.06.2020', 'cases': '599'}\n",
            "{'date': '09.06.2020', 'cases': '400'}\n",
            "{'date': '10.06.2020', 'cases': '282'}\n",
            "{'date': '11.06.2020', 'cases': '359'}\n",
            "{'date': '12.06.2020', 'cases': '376'}\n",
            "{'date': '13.06.2020', 'cases': '440'}\n",
            "{'date': '14.06.2020', 'cases': '375'}\n",
            "{'date': '15.06.2020', 'cases': '396'}\n",
            "{'date': '16.06.2020', 'cases': '407'}\n",
            "{'date': '17.06.2020', 'cases': '450'}\n",
            "{'date': '18.06.2020', 'cases': '314'}\n",
            "{'date': '19.06.2020', 'cases': '352'}\n",
            "{'date': '20.06.2020', 'cases': '309'}\n",
            "{'date': '21.06.2020', 'cases': '311'}\n",
            "{'date': '22.06.2020', 'cases': '296'}\n",
            "{'date': '23.06.2020', 'cases': '300'}\n",
            "{'date': '24.06.2020', 'cases': '294'}\n",
            "{'date': '25.06.2020', 'cases': '298'}\n",
            "{'date': '26.06.2020', 'cases': '276'}\n",
            "{'date': '27.06.2020', 'cases': '319'}\n",
            "{'date': '28.06.2020', 'cases': '193'}\n",
            "{'date': '29.06.2020', 'cases': '247'}\n",
            "{'date': '30.06.2020', 'cases': '239'}\n",
            "{'date': '01.07.2020', 'cases': '382'}\n",
            "{'date': '02.07.2020', 'cases': '371'}\n",
            "{'date': '03.07.2020', 'cases': '259'}\n",
            "{'date': '04.07.2020', 'cases': '314'}\n",
            "{'date': '05.07.2020', 'cases': '231'}\n",
            "{'date': '06.07.2020', 'cases': '205'}\n",
            "{'date': '07.07.2020', 'cases': '257'}\n",
            "{'date': '08.07.2020', 'cases': '277'}\n",
            "{'date': '09.07.2020', 'cases': '262'}\n",
            "{'date': '10.07.2020', 'cases': '265'}\n",
            "{'date': '11.07.2020', 'cases': '305'}\n",
            "{'date': '12.07.2020', 'cases': '370'}\n",
            "{'date': '13.07.2020', 'cases': '299'}\n",
            "{'date': '14.07.2020', 'cases': '267'}\n",
            "{'date': '15.07.2020', 'cases': '264'}\n",
            "{'date': '16.07.2020', 'cases': '333'}\n",
            "{'date': '17.07.2020', 'cases': '353'}\n",
            "{'date': '18.07.2020', 'cases': '339'}\n",
            "{'date': '19.07.2020', 'cases': '358'}\n",
            "{'date': '20.07.2020', 'cases': '279'}\n",
            "{'date': '21.07.2020', 'cases': '399'}\n",
            "{'date': '22.07.2020', 'cases': '380'}\n",
            "{'date': '23.07.2020', 'cases': '418'}\n",
            "{'date': '24.07.2020', 'cases': '458'}\n",
            "{'date': '25.07.2020', 'cases': '584'}\n",
            "{'date': '26.07.2020', 'cases': '443'}\n",
            "{'date': '27.07.2020', 'cases': '337'}\n",
            "{'date': '28.07.2020', 'cases': '502'}\n",
            "{'date': '29.07.2020', 'cases': '512'}\n",
            "{'date': '30.07.2020', 'cases': '615'}\n",
            "{'date': '31.07.2020', 'cases': '657'}\n",
            "{'date': '01.08.2020', 'cases': '658'}\n",
            "{'date': '02.08.2020', 'cases': '548'}\n",
            "{'date': '03.08.2020', 'cases': '575'}\n",
            "{'date': '04.08.2020', 'cases': '680'}\n",
            "{'date': '05.08.2020', 'cases': '640'}\n",
            "{'date': '06.08.2020', 'cases': '726'}\n",
            "{'date': '07.08.2020', 'cases': '809'}\n",
            "{'date': '08.08.2020', 'cases': '843'}\n",
            "{'date': '09.08.2020', 'cases': '624'}\n",
            "{'date': '10.08.2020', 'cases': '619'}\n",
            "{'date': '11.08.2020', 'cases': '551'}\n",
            "{'date': '12.08.2020', 'cases': '715'}\n",
            "{'date': '13.08.2020', 'cases': '811'}\n",
            "{'date': '14.08.2020', 'cases': '825'}\n",
            "{'date': '15.08.2020', 'cases': '778'}\n",
            "{'date': '16.08.2020', 'cases': '594'}\n",
            "{'date': '17.08.2020', 'cases': '595'}\n",
            "{'date': '18.08.2020', 'cases': '597'}\n",
            "{'date': '19.08.2020', 'cases': '735'}\n",
            "{'date': '20.08.2020', 'cases': '767'}\n",
            "{'date': '21.08.2020', 'cases': '903'}\n",
            "{'date': '22.08.2020', 'cases': '900'}\n",
            "{'date': '23.08.2020', 'cases': '581'}\n",
            "{'date': '24.08.2020', 'cases': '548'}\n",
            "{'date': '25.08.2020', 'cases': '763'}\n",
            "{'date': '26.08.2020', 'cases': '729'}\n",
            "{'date': '27.08.2020', 'cases': '887'}\n",
            "{'date': '28.08.2020', 'cases': '791'}\n",
            "{'date': '29.08.2020', 'cases': '759'}\n",
            "{'date': '30.08.2020', 'cases': '631'}\n",
            "{'date': '31.08.2020', 'cases': '502'}\n",
            "{'date': '01.09.2020', 'cases': '550'}\n",
            "{'date': '02.09.2020', 'cases': '595'}\n",
            "{'date': '03.09.2020', 'cases': '612'}\n",
            "{'date': '04.09.2020', 'cases': '691'}\n",
            "{'date': '05.09.2020', 'cases': '567'}\n",
            "{'date': '06.09.2020', 'cases': '437'}\n",
            "{'date': '07.09.2020', 'cases': '302'}\n",
            "{'date': '08.09.2020', 'cases': '400'}\n",
            "{'date': '09.09.2020', 'cases': '421'}\n",
            "{'date': '10.09.2020', 'cases': '506'}\n",
            "{'date': '11.09.2020', 'cases': '594'}\n",
            "{'date': '12.09.2020', 'cases': '603'}\n",
            "{'date': '13.09.2020', 'cases': '502'}\n",
            "{'date': '14.09.2020', 'cases': '377'}\n",
            "{'date': '15.09.2020', 'cases': '605'}\n",
            "{'date': '16.09.2020', 'cases': '600'}\n",
            "{'date': '17.09.2020', 'cases': '837'}\n",
            "{'date': '18.09.2020', 'cases': '757'}\n",
            "{'date': '19.09.2020', 'cases': '1002'}\n",
            "{'date': '20.09.2020', 'cases': '910'}\n",
            "{'date': '21.09.2020', 'cases': '748'}\n",
            "{'date': '22.09.2020', 'cases': '711'}\n",
            "{'date': '23.09.2020', 'cases': '974'}\n",
            "{'date': '24.09.2020', 'cases': '1136'}\n",
            "{'date': '25.09.2020', 'cases': '1587'}\n",
            "{'date': '26.09.2020', 'cases': '1584'}\n",
            "{'date': '27.09.2020', 'cases': '1350'}\n",
            "{'date': '28.09.2020', 'cases': '1306'}\n",
            "{'date': '29.09.2020', 'cases': '1326'}\n",
            "{'date': '30.09.2020', 'cases': '1552'}\n",
            "{'date': '01.10.2020', 'cases': '1967'}\n",
            "{'date': '02.10.2020', 'cases': '2292'}\n",
            "{'date': '03.10.2020', 'cases': '2367'}\n",
            "{'date': '04.10.2020', 'cases': '1934'}\n",
            "{'date': '05.10.2020', 'cases': '2006'}\n",
            "{'date': '06.10.2020', 'cases': '2236'}\n",
            "{'date': '07.10.2020', 'cases': '3003'}\n",
            "{'date': '08.10.2020', 'cases': '4280'}\n",
            "{'date': '09.10.2020', 'cases': '4739'}\n",
            "{'date': '10.10.2020', 'cases': '5300'}\n",
            "{'date': '11.10.2020', 'cases': '4178'}\n",
            "{'date': '12.10.2020', 'cases': '4394'}\n",
            "{'date': '13.10.2020', 'cases': '5068'}\n",
            "{'date': '14.10.2020', 'cases': '6526'}\n",
            "{'date': '15.10.2020', 'cases': '8099'}\n",
            "{'date': '16.10.2020', 'cases': '7705'}\n",
            "{'date': '17.10.2020', 'cases': '9622'}\n",
            "{'date': '18.10.2020', 'cases': '8536'}\n",
            "{'date': '19.10.2020', 'cases': '7482'}\n",
            "{'date': '20.10.2020', 'cases': '9291'}\n",
            "{'date': '21.10.2020', 'cases': '10040'}\n",
            "{'date': '22.10.2020', 'cases': '12107'}\n",
            "{'date': '23.10.2020', 'cases': '13632'}\n",
            "{'date': '24.10.2020', 'cases': '13628'}\n",
            "{'date': '25.10.2020', 'cases': '11742'}\n",
            "{'date': '26.10.2020', 'cases': '10241'}\n",
            "{'date': '27.10.2020', 'cases': '16300'}\n",
            "{'date': '28.10.2020', 'cases': '18820'}\n",
            "{'date': '29.10.2020', 'cases': '20156'}\n",
            "{'date': '30.10.2020', 'cases': '21629'}\n",
            "{'date': '31.10.2020', 'cases': '21897'}\n",
            "{'date': '01.11.2020', 'cases': '17171'}\n",
            "{'date': '02.11.2020', 'cases': '15578'}\n",
            "{'date': '03.11.2020', 'cases': '19364'}\n",
            "{'date': '04.11.2020', 'cases': '24692'}\n",
            "{'date': '05.11.2020', 'cases': '27143'}\n",
            "{'date': '06.11.2020', 'cases': '27086'}\n",
            "{'date': '07.11.2020', 'cases': '27875'}\n",
            "{'date': '08.11.2020', 'cases': '24785'}\n",
            "{'date': '09.11.2020', 'cases': '21713'}\n",
            "{'date': '10.11.2020', 'cases': '25454'}\n",
            "{'date': '11.11.2020', 'cases': '25221'}\n",
            "{'date': '12.11.2020', 'cases': '22683'}\n",
            "{'date': '13.11.2020', 'cases': '24051'}\n",
            "{'date': '14.11.2020', 'cases': '25571'}\n",
            "{'date': '15.11.2020', 'cases': '21854'}\n",
            "{'date': '16.11.2020', 'cases': '20816'}\n",
            "{'date': '17.11.2020', 'cases': '19152'}\n",
            "{'date': '18.11.2020', 'cases': '19883'}\n",
            "{'date': '19.11.2020', 'cases': '23975'}\n",
            "{'date': '20.11.2020', 'cases': '22464'}\n",
            "{'date': '21.11.2020', 'cases': '24213'}\n",
            "{'date': '22.11.2020', 'cases': '17856'}\n",
            "{'date': '23.11.2020', 'cases': '15002'}\n",
            "{'date': '24.11.2020', 'cases': '32733'}\n",
            "{'date': '25.11.2020', 'cases': '15356'}\n",
            "{'date': '26.11.2020', 'cases': '16690'}\n",
            "{'date': '27.11.2020', 'cases': '17304'}\n",
            "{'date': '28.11.2020', 'cases': '15177'}\n",
            "{'date': '29.11.2020', 'cases': '11482'}\n",
            "{'date': '30.11.2020', 'cases': '5736'}\n",
            "{'date': '01.12.2020', 'cases': '9113'}\n",
            "{'date': '02.12.2020', 'cases': '13823'}\n",
            "{'date': '03.12.2020', 'cases': '14863'}\n",
            "{'date': '04.12.2020', 'cases': '13236'}\n",
            "{'date': '05.12.2020', 'cases': '12427'}\n",
            "{'date': '06.12.2020', 'cases': '9176'}\n",
            "{'date': '07.12.2020', 'cases': '4421'}\n",
            "{'date': '08.12.2020', 'cases': '8310'}\n",
            "{'date': '09.12.2020', 'cases': '12166'}\n",
            "{'date': '10.12.2020', 'cases': '13750'}\n",
            "{'date': '11.12.2020', 'cases': '13105'}\n",
            "{'date': '12.12.2020', 'cases': '11499'}\n",
            "{'date': '13.12.2020', 'cases': '8976'}\n",
            "{'date': '14.12.2020', 'cases': '4896'}\n",
            "{'date': '15.12.2020', 'cases': '6874'}\n",
            "{'date': '16.12.2020', 'cases': '12455'}\n",
            "{'date': '17.12.2020', 'cases': '11953'}\n",
            "{'date': '18.12.2020', 'cases': '11010'}\n",
            "{'date': '19.12.2020', 'cases': '11246'}\n",
            "{'date': '20.12.2020', 'cases': '8590'}\n",
            "{'date': '21.12.2020', 'cases': '4633'}\n",
            "{'date': '22.12.2020', 'cases': '7192'}\n",
            "{'date': '23.12.2020', 'cases': '12358'}\n",
            "{'date': '24.12.2020', 'cases': '13115'}\n",
            "{'date': '25.12.2020', 'cases': '9081'}\n",
            "{'date': '26.12.2020', 'cases': '4878'}\n",
            "{'date': '27.12.2020', 'cases': '3842'}\n",
            "{'date': '28.12.2020', 'cases': '3211'}\n",
            "{'date': '29.12.2020', 'cases': '7624'}\n",
            "{'date': '30.12.2020', 'cases': '12780'}\n",
            "{'date': '31.12.2020', 'cases': '13464'}\n",
            "{'date': '01.01.2021', 'cases': '10896'}\n",
            "{'date': '02.01.2021', 'cases': '7006'}\n",
            "{'date': '03.01.2021', 'cases': '5782'}\n",
            "{'date': '04.01.2021', 'cases': '4385'}\n",
            "{'date': '05.01.2021', 'cases': '7596'}\n",
            "{'date': '06.01.2021', 'cases': '14220'}\n",
            "{'date': '07.01.2021', 'cases': '12119'}\n",
            "{'date': '08.01.2021', 'cases': '8763'}\n",
            "{'date': '09.01.2021', 'cases': '10744'}\n",
            "{'date': '10.01.2021', 'cases': '9133'}\n",
            "{'date': '11.01.2021', 'cases': '4863'}\n",
            "{'date': '12.01.2021', 'cases': '5394'}\n",
            "{'date': '13.01.2021', 'cases': '9126'}\n",
            "{'date': '14.01.2021', 'cases': '9436'}\n",
            "{'date': '15.01.2021', 'cases': '7979'}\n",
            "{'date': '16.01.2021', 'cases': '7292'}\n",
            "{'date': '17.01.2021', 'cases': '5970'}\n",
            "{'date': '18.01.2021', 'cases': '3332'}\n",
            "{'date': '19.01.2021', 'cases': '4890'}\n",
            "{'date': '20.01.2021', 'cases': '6943'}\n",
            "{'date': '21.01.2021', 'cases': '7008'}\n",
            "{'date': '22.01.2021', 'cases': '6693'}\n",
            "{'date': '23.01.2021', 'cases': '6304'}\n",
            "{'date': '24.01.2021', 'cases': '4566'}\n",
            "{'date': '25.01.2021', 'cases': '2674'}\n",
            "{'date': '26.01.2021', 'cases': '4603'}\n",
            "{'date': '27.01.2021', 'cases': '6790'}\n",
            "{'date': '28.01.2021', 'cases': '7153'}\n",
            "{'date': '29.01.2021', 'cases': '6145'}\n",
            "{'date': '30.01.2021', 'cases': '5864'}\n",
            "{'date': '31.01.2021', 'cases': '4711'}\n",
            "{'date': '01.02.2021', 'cases': '2504'}\n",
            "{'date': '02.02.2021', 'cases': '4326'}\n",
            "{'date': '03.02.2021', 'cases': '6801'}\n",
            "{'date': '04.02.2021', 'cases': '6495'}\n",
            "{'date': '05.02.2021', 'cases': '6053'}\n",
            "{'date': '06.02.2021', 'cases': '5966'}\n",
            "{'date': '07.02.2021', 'cases': '4725'}\n",
            "{'date': '08.02.2021', 'cases': '2431'}\n",
            "{'date': '09.02.2021', 'cases': '3999'}\n",
            "{'date': '10.02.2021', 'cases': '6960'}\n",
            "{'date': '11.02.2021', 'cases': '7013'}\n",
            "{'date': '12.02.2021', 'cases': '6378'}\n",
            "{'date': '13.02.2021', 'cases': '6585'}\n",
            "{'date': '14.02.2021', 'cases': '5334'}\n",
            "{'date': '15.02.2021', 'cases': '2542'}\n",
            "{'date': '16.02.2021', 'cases': '5176'}\n",
            "{'date': '17.02.2021', 'cases': '8699'}\n",
            "{'date': '18.02.2021', 'cases': '9074'}\n",
            "{'date': '19.02.2021', 'cases': '8772'}\n",
            "{'date': '20.02.2021', 'cases': '8509'}\n",
            "{'date': '21.02.2021', 'cases': '7040'}\n",
            "{'date': '22.02.2021', 'cases': '3891'}\n",
            "{'date': '23.02.2021', 'cases': '6304'}\n",
            "{'date': '24.02.2021', 'cases': '12147'}\n",
            "{'date': '25.02.2021', 'cases': '12143'}\n",
            "{'date': '26.02.2021', 'cases': '11536'}\n",
            "{'date': '27.02.2021', 'cases': '12097'}\n",
            "{'date': '28.02.2021', 'cases': '10101'}\n",
            "{'date': '01.03.2021', 'cases': '4786'}\n",
            "{'date': '02.03.2021', 'cases': '7936'}\n",
            "{'date': '03.03.2021', 'cases': '15698'}\n",
            "{'date': '04.03.2021', 'cases': '15253'}\n",
            "{'date': '05.03.2021', 'cases': '15831'}\n",
            "{'date': '06.03.2021', 'cases': '14855'}\n",
            "{'date': '07.03.2021', 'cases': '13569'}\n",
            "{'date': '08.03.2021', 'cases': '6169'}\n",
            "{'date': '09.03.2021', 'cases': '9953'}\n",
            "{'date': '10.03.2021', 'cases': '17277'}\n",
            "{'date': '11.03.2021', 'cases': '21111'}\n",
            "{'date': '12.03.2021', 'cases': '18873'}\n",
            "{'date': '13.03.2021', 'cases': '21063'}\n",
            "{'date': '14.03.2021', 'cases': '17272'}\n",
            "{'date': '15.03.2021', 'cases': '10895'}\n",
            "{'date': '16.03.2021', 'cases': '14394'}\n",
            "{'date': '17.03.2021', 'cases': '25053'}\n",
            "{'date': '18.03.2021', 'cases': '27274'}\n",
            "{'date': '19.03.2021', 'cases': '25996'}\n",
            "{'date': '20.03.2021', 'cases': '26456'}\n",
            "{'date': '21.03.2021', 'cases': '21850'}\n",
            "{'date': '22.03.2021', 'cases': '14579'}\n",
            "{'date': '23.03.2021', 'cases': '16740'}\n",
            "{'date': '24.03.2021', 'cases': '30802'}\n",
            "{'date': '25.03.2021', 'cases': '34150'}\n",
            "{'date': '26.03.2021', 'cases': '35145'}\n",
            "{'date': '27.03.2021', 'cases': '31759'}\n",
            "{'date': '28.03.2021', 'cases': '29266'}\n",
            "{'date': '29.03.2021', 'cases': '16973'}\n",
            "{'date': '30.03.2021', 'cases': '20862'}\n",
            "{'date': '31.03.2021', 'cases': '32891'}\n",
            "{'date': '01.04.2021', 'cases': '35253'}\n",
            "{'date': '02.04.2021', 'cases': '30541'}\n",
            "{'date': '03.04.2021', 'cases': '28073'}\n",
            "{'date': '04.04.2021', 'cases': '22958'}\n",
            "{'date': '05.04.2021', 'cases': '9921'}\n",
            "{'date': '06.04.2021', 'cases': '8246'}\n",
            "{'date': '07.04.2021', 'cases': '14908'}\n",
            "{'date': '08.04.2021', 'cases': '27890'}\n",
            "{'date': '09.04.2021', 'cases': '28499'}\n",
            "{'date': '10.04.2021', 'cases': '24892'}\n",
            "{'date': '11.04.2021', 'cases': '21733'}\n",
            "{'date': '12.04.2021', 'cases': '12016'}\n",
            "{'date': '13.04.2021', 'cases': '13203'}\n",
            "{'date': '14.04.2021', 'cases': '21266'}\n",
            "{'date': '15.04.2021', 'cases': '21126'}\n",
            "{'date': '16.04.2021', 'cases': '17846'}\n",
            "{'date': '17.04.2021', 'cases': '15786'}\n",
            "{'date': '18.04.2021', 'cases': '12151'}\n",
            "{'date': '19.04.2021', 'cases': '7302'}\n",
            "{'date': '20.04.2021', 'cases': '9244'}\n",
            "{'date': '21.04.2021', 'cases': '13922'}\n",
            "{'date': '22.04.2021', 'cases': '12763'}\n",
            "{'date': '23.04.2021', 'cases': '10866'}\n",
            "{'date': '24.04.2021', 'cases': '9510'}\n",
            "{'date': '25.04.2021', 'cases': '7224'}\n",
            "{'date': '26.04.2021', 'cases': '3467'}\n",
            "{'date': '27.04.2021', 'cases': '5711'}\n",
            "{'date': '28.04.2021', 'cases': '8893'}\n",
            "{'date': '29.04.2021', 'cases': '8426'}\n",
            "{'date': '30.04.2021', 'cases': '6789'}\n",
            "{'date': '01.05.2021', 'cases': '6475'}\n",
            "{'date': '02.05.2021', 'cases': '4616'}\n",
            "{'date': '03.05.2021', 'cases': '2523'}\n",
            "{'date': '04.05.2021', 'cases': '2296'}\n",
            "{'date': '05.05.2021', 'cases': '3899'}\n",
            "{'date': '06.05.2021', 'cases': '6427'}\n",
            "{'date': '07.05.2021', 'cases': '6047'}\n",
            "{'date': '08.05.2021', 'cases': '4771'}\n",
            "{'date': '09.05.2021', 'cases': '3856'}\n",
            "{'date': '10.05.2021', 'cases': '2031'}\n",
            "{'date': '11.05.2021', 'cases': '3097'}\n",
            "{'date': '12.05.2021', 'cases': '3948'}\n",
            "{'date': '13.05.2021', 'cases': '3694'}\n",
            "{'date': '14.05.2021', 'cases': '3289'}\n",
            "{'date': '15.05.2021', 'cases': '2897'}\n",
            "{'date': '16.05.2021', 'cases': '2169'}\n",
            "{'date': '17.05.2021', 'cases': '1111'}\n",
            "{'date': '18.05.2021', 'cases': '1727'}\n",
            "{'date': '19.05.2021', 'cases': '2348'}\n",
            "{'date': '20.05.2021', 'cases': '2087'}\n",
            "{'date': '21.05.2021', 'cases': '1678'}\n",
            "{'date': '22.05.2021', 'cases': '1517'}\n",
            "{'date': '23.05.2021', 'cases': '1075'}\n",
            "{'date': '24.05.2021', 'cases': '559'}\n",
            "{'date': '25.05.2021', 'cases': '1000'}\n",
            "{'date': '26.05.2021', 'cases': '1267'}\n",
            "{'date': '27.05.2021', 'cases': '1227'}\n",
            "{'date': '28.05.2021', 'cases': '946'}\n",
            "{'date': '29.05.2021', 'cases': '775'}\n",
            "{'date': '30.05.2021', 'cases': '579'}\n",
            "{'date': '31.05.2021', 'cases': '333'}\n",
            "{'date': '01.06.2021', 'cases': '588'}\n",
            "{'date': '02.06.2021', 'cases': '659'}\n",
            "{'date': '03.06.2021', 'cases': '572'}\n",
            "{'date': '04.06.2021', 'cases': '317'}\n",
            "{'date': '05.06.2021', 'cases': '415'}\n",
            "{'date': '06.06.2021', 'cases': '310'}\n",
            "{'date': '07.06.2021', 'cases': '195'}\n",
            "{'date': '08.06.2021', 'cases': '532'}\n",
            "{'date': '09.06.2021', 'cases': '428'}\n",
            "{'date': '10.06.2021', 'cases': '382'}\n",
            "{'date': '11.06.2021', 'cases': '341'}\n",
            "{'date': '12.06.2021', 'cases': '238'}\n",
            "{'date': '13.06.2021', 'cases': '226'}\n",
            "{'date': '14.06.2021', 'cases': '140'}\n",
            "{'date': '15.06.2021', 'cases': '215'}\n",
            "{'date': '16.06.2021', 'cases': '238'}\n",
            "{'date': '17.06.2021', 'cases': '218'}\n",
            "{'date': '18.06.2021', 'cases': '190'}\n",
            "{'date': '19.06.2021', 'cases': '168'}\n",
            "{'date': '20.06.2021', 'cases': '133'}\n",
            "{'date': '21.06.2021', 'cases': '73'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzUAqh7pkDjV",
        "outputId": "5d645589-046a-4b72-9f3d-b8225710c739"
      },
      "source": [
        "average = 0\n",
        "for n in range(1, 8):\n",
        "  i = -8 + n\n",
        "  average = ((n-1)*average+ cases[i])/n\n",
        "  print(str(cases[i]) + \":\" + str(average))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "215:215.0\n",
            "238:226.5\n",
            "218:223.66666666666666\n",
            "190:215.25\n",
            "168:205.8\n",
            "133:193.66666666666666\n",
            "73:176.42857142857142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAb7jTvuoIuD",
        "outputId": "3d5f68b1-3e1e-4afe-b5ce-a84cff8da580"
      },
      "source": [
        "today = date.today()\n",
        "n=0\n",
        "sum=0\n",
        "for day in days:\n",
        "  date_dt2 = datetime.strptime(day, '%d.%m.%Y')\n",
        "  if date_dt2.month == today.month-1:\n",
        "    n=n+1\n",
        "    #print(cases[days.index(day)])\n",
        "    sum=sum+cases[days.index(day)]\n",
        "    \n",
        "last_month_avg = sum/n\n",
        "print(last_month_avg)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1470.532258064516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "oqR51LuIh6a2",
        "outputId": "a0142d72-ec9c-4ab0-e18b-5da1e31e894d"
      },
      "source": [
        "#plotting covid cases\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=days, y=cases, name='Covid Cases', mode='markers+lines'))\n",
        "fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [last_month_avg], name='Last month average', mode='lines'))\n",
        "#fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [average], name='Last 7 days average', mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [mean(cases)], name='Todays Average', mode='lines'))\n",
        "fig.update_layout(width=1300, height=500, title='Number of covid19 cases by day in 2021', xaxis_title='Days', yaxis_title='Cases')\n",
        "fig.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"248acecd-0191-4825-b7b3-e2a8454f6c8a\" class=\"plotly-graph-div\" style=\"height:500px; width:1300px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"248acecd-0191-4825-b7b3-e2a8454f6c8a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '248acecd-0191-4825-b7b3-e2a8454f6c8a',\n",
              "                        [{\"mode\": \"markers+lines\", \"name\": \"Covid Cases\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\", \"10.06.2021\", \"11.06.2021\", \"12.06.2021\", \"13.06.2021\", \"14.06.2021\", \"15.06.2021\", \"16.06.2021\", \"17.06.2021\", \"18.06.2021\", \"19.06.2021\", \"20.06.2021\", \"21.06.2021\"], \"y\": [0, 0, 0, 0, 0, 0, 1, 0, 4, 1, 5, 6, 5, 9, 20, 17, 36, 21, 52, 61, 49, 68, 70, 111, 98, 116, 152, 150, 170, 168, 249, 224, 193, 256, 243, 392, 437, 244, 475, 311, 435, 357, 370, 380, 401, 318, 260, 268, 380, 336, 457, 334, 515, 306, 263, 313, 342, 381, 381, 344, 285, 316, 422, 300, 228, 270, 318, 313, 406, 311, 303, 337, 288, 345, 330, 556, 322, 411, 401, 241, 272, 356, 382, 471, 403, 472, 316, 361, 341, 443, 396, 352, 333, 412, 219, 374, 236, 292, 361, 362, 576, 575, 599, 400, 282, 359, 376, 440, 375, 396, 407, 450, 314, 352, 309, 311, 296, 300, 294, 298, 276, 319, 193, 247, 239, 382, 371, 259, 314, 231, 205, 257, 277, 262, 265, 305, 370, 299, 267, 264, 333, 353, 339, 358, 279, 399, 380, 418, 458, 584, 443, 337, 502, 512, 615, 657, 658, 548, 575, 680, 640, 726, 809, 843, 624, 619, 551, 715, 811, 825, 778, 594, 595, 597, 735, 767, 903, 900, 581, 548, 763, 729, 887, 791, 759, 631, 502, 550, 595, 612, 691, 567, 437, 302, 400, 421, 506, 594, 603, 502, 377, 605, 600, 837, 757, 1002, 910, 748, 711, 974, 1136, 1587, 1584, 1350, 1306, 1326, 1552, 1967, 2292, 2367, 1934, 2006, 2236, 3003, 4280, 4739, 5300, 4178, 4394, 5068, 6526, 8099, 7705, 9622, 8536, 7482, 9291, 10040, 12107, 13632, 13628, 11742, 10241, 16300, 18820, 20156, 21629, 21897, 17171, 15578, 19364, 24692, 27143, 27086, 27875, 24785, 21713, 25454, 25221, 22683, 24051, 25571, 21854, 20816, 19152, 19883, 23975, 22464, 24213, 17856, 15002, 32733, 15356, 16690, 17304, 15177, 11482, 5736, 9113, 13823, 14863, 13236, 12427, 9176, 4421, 8310, 12166, 13750, 13105, 11499, 8976, 4896, 6874, 12455, 11953, 11010, 11246, 8590, 4633, 7192, 12358, 13115, 9081, 4878, 3842, 3211, 7624, 12780, 13464, 10896, 7006, 5782, 4385, 7596, 14220, 12119, 8763, 10744, 9133, 4863, 5394, 9126, 9436, 7979, 7292, 5970, 3332, 4890, 6943, 7008, 6693, 6304, 4566, 2674, 4603, 6790, 7153, 6145, 5864, 4711, 2504, 4326, 6801, 6495, 6053, 5966, 4725, 2431, 3999, 6960, 7013, 6378, 6585, 5334, 2542, 5176, 8699, 9074, 8772, 8509, 7040, 3891, 6304, 12147, 12143, 11536, 12097, 10101, 4786, 7936, 15698, 15253, 15831, 14855, 13569, 6169, 9953, 17277, 21111, 18873, 21063, 17272, 10895, 14394, 25053, 27274, 25996, 26456, 21850, 14579, 16740, 30802, 34150, 35145, 31759, 29266, 16973, 20862, 32891, 35253, 30541, 28073, 22958, 9921, 8246, 14908, 27890, 28499, 24892, 21733, 12016, 13203, 21266, 21126, 17846, 15786, 12151, 7302, 9244, 13922, 12763, 10866, 9510, 7224, 3467, 5711, 8893, 8426, 6789, 6475, 4616, 2523, 2296, 3899, 6427, 6047, 4771, 3856, 2031, 3097, 3948, 3694, 3289, 2897, 2169, 1111, 1727, 2348, 2087, 1678, 1517, 1075, 559, 1000, 1267, 1227, 946, 775, 579, 333, 588, 659, 572, 317, 415, 310, 195, 532, 428, 382, 341, 238, 226, 140, 215, 238, 218, 190, 168, 133, 73]}, {\"mode\": \"lines\", \"name\": \"Last month average\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\", \"10.06.2021\", \"11.06.2021\", \"12.06.2021\", \"13.06.2021\", \"14.06.2021\", \"15.06.2021\", \"16.06.2021\", \"17.06.2021\", \"18.06.2021\", \"19.06.2021\", \"20.06.2021\", \"21.06.2021\"], \"y\": [1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516]}, {\"mode\": \"lines\", \"name\": \"Todays Average\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\", \"10.06.2021\", \"11.06.2021\", \"12.06.2021\", \"13.06.2021\", \"14.06.2021\", \"15.06.2021\", \"16.06.2021\", \"17.06.2021\", \"18.06.2021\", \"19.06.2021\", \"20.06.2021\", \"21.06.2021\"], \"y\": [5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846, 5985.153846153846]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Number of covid19 cases by day in 2021\"}, \"width\": 1300, \"xaxis\": {\"title\": {\"text\": \"Days\"}}, \"yaxis\": {\"title\": {\"text\": \"Cases\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('248acecd-0191-4825-b7b3-e2a8454f6c8a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDoOI7OvBEwe"
      },
      "source": [
        "#libraries for creating neural network\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWPAcZn7xGAA"
      },
      "source": [
        "def split_sequence(seq, n_steps):\n",
        "  IN = []\n",
        "  OUT = []\n",
        "  for i in range(len(seq)-n_steps):\n",
        "    TEMP = []\n",
        "    for j in range(i,n_steps):\n",
        "      TEMP.append(seq[j])\n",
        "    IN.append(TEMP)\n",
        "    OUT.append(seq[j+1])\n",
        "    n_steps=n_steps+1\n",
        "  print(len(IN))\n",
        "  return IN,OUT"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMCkOinmxJCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5888e531-d5a5-412d-a2d7-379d3a3c5714"
      },
      "source": [
        "#splitting the sequences of 14-days covid datasets\n",
        "n = 14\n",
        "X, Y = split_sequence(cases, n)\n",
        "limit = 0.2*len(X)\n",
        "\n",
        "#splitting for validation data and training data\n",
        "Validation_X = []\n",
        "Validation_Y = []\n",
        "i=0\n",
        "while(i<limit):\n",
        "    r=random.randint(1,len(X))\n",
        "    r=r-1\n",
        "    Validation_X.append(X[r])\n",
        "    Validation_Y.append(Y[r])\n",
        "    del X[r], Y[r]\n",
        "    i+=1\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "Validation_X = np.array(Validation_X)\n",
        "Validation_Y = np.array(Validation_Y)\n",
        "\n",
        "#for i in range(len(Validation_X)):\n",
        "#    print(Validation_X[i], Validation_Y[i])\n",
        "\n",
        "#print of training data set\n",
        "for i in range(len(X)):\n",
        "    print(X[i], Y[i])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "467\n",
            "[ 0  0  0  0  0  1  0  4  1  5  6  5  9 20] 17\n",
            "[ 0  0  0  1  0  4  1  5  6  5  9 20 17 36] 21\n",
            "[ 0  0  1  0  4  1  5  6  5  9 20 17 36 21] 52\n",
            "[ 0  1  0  4  1  5  6  5  9 20 17 36 21 52] 61\n",
            "[ 0  4  1  5  6  5  9 20 17 36 21 52 61 49] 68\n",
            "[ 4  1  5  6  5  9 20 17 36 21 52 61 49 68] 70\n",
            "[ 1  5  6  5  9 20 17 36 21 52 61 49 68 70] 111\n",
            "[  5   6   5   9  20  17  36  21  52  61  49  68  70 111] 98\n",
            "[  6   5   9  20  17  36  21  52  61  49  68  70 111  98] 116\n",
            "[  5   9  20  17  36  21  52  61  49  68  70 111  98 116] 152\n",
            "[ 20  17  36  21  52  61  49  68  70 111  98 116 152 150] 170\n",
            "[ 17  36  21  52  61  49  68  70 111  98 116 152 150 170] 168\n",
            "[ 52  61  49  68  70 111  98 116 152 150 170 168 249 224] 193\n",
            "[ 61  49  68  70 111  98 116 152 150 170 168 249 224 193] 256\n",
            "[ 49  68  70 111  98 116 152 150 170 168 249 224 193 256] 243\n",
            "[ 68  70 111  98 116 152 150 170 168 249 224 193 256 243] 392\n",
            "[111  98 116 152 150 170 168 249 224 193 256 243 392 437] 244\n",
            "[116 152 150 170 168 249 224 193 256 243 392 437 244 475] 311\n",
            "[152 150 170 168 249 224 193 256 243 392 437 244 475 311] 435\n",
            "[150 170 168 249 224 193 256 243 392 437 244 475 311 435] 357\n",
            "[170 168 249 224 193 256 243 392 437 244 475 311 435 357] 370\n",
            "[168 249 224 193 256 243 392 437 244 475 311 435 357 370] 380\n",
            "[249 224 193 256 243 392 437 244 475 311 435 357 370 380] 401\n",
            "[224 193 256 243 392 437 244 475 311 435 357 370 380 401] 318\n",
            "[193 256 243 392 437 244 475 311 435 357 370 380 401 318] 260\n",
            "[256 243 392 437 244 475 311 435 357 370 380 401 318 260] 268\n",
            "[243 392 437 244 475 311 435 357 370 380 401 318 260 268] 380\n",
            "[392 437 244 475 311 435 357 370 380 401 318 260 268 380] 336\n",
            "[244 475 311 435 357 370 380 401 318 260 268 380 336 457] 334\n",
            "[475 311 435 357 370 380 401 318 260 268 380 336 457 334] 515\n",
            "[435 357 370 380 401 318 260 268 380 336 457 334 515 306] 263\n",
            "[370 380 401 318 260 268 380 336 457 334 515 306 263 313] 342\n",
            "[380 401 318 260 268 380 336 457 334 515 306 263 313 342] 381\n",
            "[401 318 260 268 380 336 457 334 515 306 263 313 342 381] 381\n",
            "[260 268 380 336 457 334 515 306 263 313 342 381 381 344] 285\n",
            "[268 380 336 457 334 515 306 263 313 342 381 381 344 285] 316\n",
            "[380 336 457 334 515 306 263 313 342 381 381 344 285 316] 422\n",
            "[336 457 334 515 306 263 313 342 381 381 344 285 316 422] 300\n",
            "[457 334 515 306 263 313 342 381 381 344 285 316 422 300] 228\n",
            "[334 515 306 263 313 342 381 381 344 285 316 422 300 228] 270\n",
            "[515 306 263 313 342 381 381 344 285 316 422 300 228 270] 318\n",
            "[306 263 313 342 381 381 344 285 316 422 300 228 270 318] 313\n",
            "[263 313 342 381 381 344 285 316 422 300 228 270 318 313] 406\n",
            "[313 342 381 381 344 285 316 422 300 228 270 318 313 406] 311\n",
            "[342 381 381 344 285 316 422 300 228 270 318 313 406 311] 303\n",
            "[381 381 344 285 316 422 300 228 270 318 313 406 311 303] 337\n",
            "[381 344 285 316 422 300 228 270 318 313 406 311 303 337] 288\n",
            "[344 285 316 422 300 228 270 318 313 406 311 303 337 288] 345\n",
            "[285 316 422 300 228 270 318 313 406 311 303 337 288 345] 330\n",
            "[316 422 300 228 270 318 313 406 311 303 337 288 345 330] 556\n",
            "[422 300 228 270 318 313 406 311 303 337 288 345 330 556] 322\n",
            "[228 270 318 313 406 311 303 337 288 345 330 556 322 411] 401\n",
            "[270 318 313 406 311 303 337 288 345 330 556 322 411 401] 241\n",
            "[318 313 406 311 303 337 288 345 330 556 322 411 401 241] 272\n",
            "[313 406 311 303 337 288 345 330 556 322 411 401 241 272] 356\n",
            "[337 288 345 330 556 322 411 401 241 272 356 382 471 403] 472\n",
            "[288 345 330 556 322 411 401 241 272 356 382 471 403 472] 316\n",
            "[345 330 556 322 411 401 241 272 356 382 471 403 472 316] 361\n",
            "[330 556 322 411 401 241 272 356 382 471 403 472 316 361] 341\n",
            "[556 322 411 401 241 272 356 382 471 403 472 316 361 341] 443\n",
            "[322 411 401 241 272 356 382 471 403 472 316 361 341 443] 396\n",
            "[411 401 241 272 356 382 471 403 472 316 361 341 443 396] 352\n",
            "[401 241 272 356 382 471 403 472 316 361 341 443 396 352] 333\n",
            "[272 356 382 471 403 472 316 361 341 443 396 352 333 412] 219\n",
            "[356 382 471 403 472 316 361 341 443 396 352 333 412 219] 374\n",
            "[382 471 403 472 316 361 341 443 396 352 333 412 219 374] 236\n",
            "[471 403 472 316 361 341 443 396 352 333 412 219 374 236] 292\n",
            "[403 472 316 361 341 443 396 352 333 412 219 374 236 292] 361\n",
            "[472 316 361 341 443 396 352 333 412 219 374 236 292 361] 362\n",
            "[316 361 341 443 396 352 333 412 219 374 236 292 361 362] 576\n",
            "[361 341 443 396 352 333 412 219 374 236 292 361 362 576] 575\n",
            "[341 443 396 352 333 412 219 374 236 292 361 362 576 575] 599\n",
            "[443 396 352 333 412 219 374 236 292 361 362 576 575 599] 400\n",
            "[352 333 412 219 374 236 292 361 362 576 575 599 400 282] 359\n",
            "[333 412 219 374 236 292 361 362 576 575 599 400 282 359] 376\n",
            "[412 219 374 236 292 361 362 576 575 599 400 282 359 376] 440\n",
            "[219 374 236 292 361 362 576 575 599 400 282 359 376 440] 375\n",
            "[374 236 292 361 362 576 575 599 400 282 359 376 440 375] 396\n",
            "[236 292 361 362 576 575 599 400 282 359 376 440 375 396] 407\n",
            "[292 361 362 576 575 599 400 282 359 376 440 375 396 407] 450\n",
            "[361 362 576 575 599 400 282 359 376 440 375 396 407 450] 314\n",
            "[362 576 575 599 400 282 359 376 440 375 396 407 450 314] 352\n",
            "[576 575 599 400 282 359 376 440 375 396 407 450 314 352] 309\n",
            "[575 599 400 282 359 376 440 375 396 407 450 314 352 309] 311\n",
            "[282 359 376 440 375 396 407 450 314 352 309 311 296 300] 294\n",
            "[359 376 440 375 396 407 450 314 352 309 311 296 300 294] 298\n",
            "[376 440 375 396 407 450 314 352 309 311 296 300 294 298] 276\n",
            "[440 375 396 407 450 314 352 309 311 296 300 294 298 276] 319\n",
            "[375 396 407 450 314 352 309 311 296 300 294 298 276 319] 193\n",
            "[396 407 450 314 352 309 311 296 300 294 298 276 319 193] 247\n",
            "[407 450 314 352 309 311 296 300 294 298 276 319 193 247] 239\n",
            "[450 314 352 309 311 296 300 294 298 276 319 193 247 239] 382\n",
            "[314 352 309 311 296 300 294 298 276 319 193 247 239 382] 371\n",
            "[352 309 311 296 300 294 298 276 319 193 247 239 382 371] 259\n",
            "[309 311 296 300 294 298 276 319 193 247 239 382 371 259] 314\n",
            "[311 296 300 294 298 276 319 193 247 239 382 371 259 314] 231\n",
            "[296 300 294 298 276 319 193 247 239 382 371 259 314 231] 205\n",
            "[300 294 298 276 319 193 247 239 382 371 259 314 231 205] 257\n",
            "[298 276 319 193 247 239 382 371 259 314 231 205 257 277] 262\n",
            "[276 319 193 247 239 382 371 259 314 231 205 257 277 262] 265\n",
            "[319 193 247 239 382 371 259 314 231 205 257 277 262 265] 305\n",
            "[193 247 239 382 371 259 314 231 205 257 277 262 265 305] 370\n",
            "[247 239 382 371 259 314 231 205 257 277 262 265 305 370] 299\n",
            "[239 382 371 259 314 231 205 257 277 262 265 305 370 299] 267\n",
            "[382 371 259 314 231 205 257 277 262 265 305 370 299 267] 264\n",
            "[371 259 314 231 205 257 277 262 265 305 370 299 267 264] 333\n",
            "[259 314 231 205 257 277 262 265 305 370 299 267 264 333] 353\n",
            "[314 231 205 257 277 262 265 305 370 299 267 264 333 353] 339\n",
            "[231 205 257 277 262 265 305 370 299 267 264 333 353 339] 358\n",
            "[205 257 277 262 265 305 370 299 267 264 333 353 339 358] 279\n",
            "[277 262 265 305 370 299 267 264 333 353 339 358 279 399] 380\n",
            "[265 305 370 299 267 264 333 353 339 358 279 399 380 418] 458\n",
            "[305 370 299 267 264 333 353 339 358 279 399 380 418 458] 584\n",
            "[370 299 267 264 333 353 339 358 279 399 380 418 458 584] 443\n",
            "[299 267 264 333 353 339 358 279 399 380 418 458 584 443] 337\n",
            "[264 333 353 339 358 279 399 380 418 458 584 443 337 502] 512\n",
            "[353 339 358 279 399 380 418 458 584 443 337 502 512 615] 657\n",
            "[339 358 279 399 380 418 458 584 443 337 502 512 615 657] 658\n",
            "[358 279 399 380 418 458 584 443 337 502 512 615 657 658] 548\n",
            "[279 399 380 418 458 584 443 337 502 512 615 657 658 548] 575\n",
            "[399 380 418 458 584 443 337 502 512 615 657 658 548 575] 680\n",
            "[380 418 458 584 443 337 502 512 615 657 658 548 575 680] 640\n",
            "[418 458 584 443 337 502 512 615 657 658 548 575 680 640] 726\n",
            "[458 584 443 337 502 512 615 657 658 548 575 680 640 726] 809\n",
            "[584 443 337 502 512 615 657 658 548 575 680 640 726 809] 843\n",
            "[443 337 502 512 615 657 658 548 575 680 640 726 809 843] 624\n",
            "[337 502 512 615 657 658 548 575 680 640 726 809 843 624] 619\n",
            "[502 512 615 657 658 548 575 680 640 726 809 843 624 619] 551\n",
            "[615 657 658 548 575 680 640 726 809 843 624 619 551 715] 811\n",
            "[658 548 575 680 640 726 809 843 624 619 551 715 811 825] 778\n",
            "[548 575 680 640 726 809 843 624 619 551 715 811 825 778] 594\n",
            "[575 680 640 726 809 843 624 619 551 715 811 825 778 594] 595\n",
            "[680 640 726 809 843 624 619 551 715 811 825 778 594 595] 597\n",
            "[640 726 809 843 624 619 551 715 811 825 778 594 595 597] 735\n",
            "[726 809 843 624 619 551 715 811 825 778 594 595 597 735] 767\n",
            "[809 843 624 619 551 715 811 825 778 594 595 597 735 767] 903\n",
            "[843 624 619 551 715 811 825 778 594 595 597 735 767 903] 900\n",
            "[624 619 551 715 811 825 778 594 595 597 735 767 903 900] 581\n",
            "[619 551 715 811 825 778 594 595 597 735 767 903 900 581] 548\n",
            "[551 715 811 825 778 594 595 597 735 767 903 900 581 548] 763\n",
            "[715 811 825 778 594 595 597 735 767 903 900 581 548 763] 729\n",
            "[811 825 778 594 595 597 735 767 903 900 581 548 763 729] 887\n",
            "[825 778 594 595 597 735 767 903 900 581 548 763 729 887] 791\n",
            "[778 594 595 597 735 767 903 900 581 548 763 729 887 791] 759\n",
            "[594 595 597 735 767 903 900 581 548 763 729 887 791 759] 631\n",
            "[595 597 735 767 903 900 581 548 763 729 887 791 759 631] 502\n",
            "[597 735 767 903 900 581 548 763 729 887 791 759 631 502] 550\n",
            "[735 767 903 900 581 548 763 729 887 791 759 631 502 550] 595\n",
            "[767 903 900 581 548 763 729 887 791 759 631 502 550 595] 612\n",
            "[903 900 581 548 763 729 887 791 759 631 502 550 595 612] 691\n",
            "[900 581 548 763 729 887 791 759 631 502 550 595 612 691] 567\n",
            "[581 548 763 729 887 791 759 631 502 550 595 612 691 567] 437\n",
            "[548 763 729 887 791 759 631 502 550 595 612 691 567 437] 302\n",
            "[763 729 887 791 759 631 502 550 595 612 691 567 437 302] 400\n",
            "[729 887 791 759 631 502 550 595 612 691 567 437 302 400] 421\n",
            "[887 791 759 631 502 550 595 612 691 567 437 302 400 421] 506\n",
            "[791 759 631 502 550 595 612 691 567 437 302 400 421 506] 594\n",
            "[759 631 502 550 595 612 691 567 437 302 400 421 506 594] 603\n",
            "[631 502 550 595 612 691 567 437 302 400 421 506 594 603] 502\n",
            "[502 550 595 612 691 567 437 302 400 421 506 594 603 502] 377\n",
            "[550 595 612 691 567 437 302 400 421 506 594 603 502 377] 605\n",
            "[595 612 691 567 437 302 400 421 506 594 603 502 377 605] 600\n",
            "[612 691 567 437 302 400 421 506 594 603 502 377 605 600] 837\n",
            "[691 567 437 302 400 421 506 594 603 502 377 605 600 837] 757\n",
            "[ 437  302  400  421  506  594  603  502  377  605  600  837  757 1002] 910\n",
            "[ 302  400  421  506  594  603  502  377  605  600  837  757 1002  910] 748\n",
            "[ 421  506  594  603  502  377  605  600  837  757 1002  910  748  711] 974\n",
            "[ 506  594  603  502  377  605  600  837  757 1002  910  748  711  974] 1136\n",
            "[ 594  603  502  377  605  600  837  757 1002  910  748  711  974 1136] 1587\n",
            "[ 603  502  377  605  600  837  757 1002  910  748  711  974 1136 1587] 1584\n",
            "[ 377  605  600  837  757 1002  910  748  711  974 1136 1587 1584 1350] 1306\n",
            "[ 605  600  837  757 1002  910  748  711  974 1136 1587 1584 1350 1306] 1326\n",
            "[ 600  837  757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326] 1552\n",
            "[ 837  757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326 1552] 1967\n",
            "[ 757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326 1552 1967] 2292\n",
            "[ 910  748  711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367] 1934\n",
            "[ 711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006] 2236\n",
            "[ 974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236] 3003\n",
            "[1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003] 4280\n",
            "[1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739] 5300\n",
            "[1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394] 5068\n",
            "[1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526] 8099\n",
            "[2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099] 7705\n",
            "[2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536] 7482\n",
            "[2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536 7482] 9291\n",
            "[3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536 7482 9291] 10040\n",
            "[ 4280  4739  5300  4178  4394  5068  6526  8099  7705  9622  8536  7482\n",
            "  9291 10040] 12107\n",
            "[ 4739  5300  4178  4394  5068  6526  8099  7705  9622  8536  7482  9291\n",
            " 10040 12107] 13632\n",
            "[ 4178  4394  5068  6526  8099  7705  9622  8536  7482  9291 10040 12107\n",
            " 13632 13628] 11742\n",
            "[ 4394  5068  6526  8099  7705  9622  8536  7482  9291 10040 12107 13632\n",
            " 13628 11742] 10241\n",
            "[ 8099  7705  9622  8536  7482  9291 10040 12107 13632 13628 11742 10241\n",
            " 16300 18820] 20156\n",
            "[ 7705  9622  8536  7482  9291 10040 12107 13632 13628 11742 10241 16300\n",
            " 18820 20156] 21629\n",
            "[ 9622  8536  7482  9291 10040 12107 13632 13628 11742 10241 16300 18820\n",
            " 20156 21629] 21897\n",
            "[ 8536  7482  9291 10040 12107 13632 13628 11742 10241 16300 18820 20156\n",
            " 21629 21897] 17171\n",
            "[ 9291 10040 12107 13632 13628 11742 10241 16300 18820 20156 21629 21897\n",
            " 17171 15578] 19364\n",
            "[12107 13632 13628 11742 10241 16300 18820 20156 21629 21897 17171 15578\n",
            " 19364 24692] 27143\n",
            "[13632 13628 11742 10241 16300 18820 20156 21629 21897 17171 15578 19364\n",
            " 24692 27143] 27086\n",
            "[13628 11742 10241 16300 18820 20156 21629 21897 17171 15578 19364 24692\n",
            " 27143 27086] 27875\n",
            "[11742 10241 16300 18820 20156 21629 21897 17171 15578 19364 24692 27143\n",
            " 27086 27875] 24785\n",
            "[10241 16300 18820 20156 21629 21897 17171 15578 19364 24692 27143 27086\n",
            " 27875 24785] 21713\n",
            "[16300 18820 20156 21629 21897 17171 15578 19364 24692 27143 27086 27875\n",
            " 24785 21713] 25454\n",
            "[20156 21629 21897 17171 15578 19364 24692 27143 27086 27875 24785 21713\n",
            " 25454 25221] 22683\n",
            "[21629 21897 17171 15578 19364 24692 27143 27086 27875 24785 21713 25454\n",
            " 25221 22683] 24051\n",
            "[21897 17171 15578 19364 24692 27143 27086 27875 24785 21713 25454 25221\n",
            " 22683 24051] 25571\n",
            "[17171 15578 19364 24692 27143 27086 27875 24785 21713 25454 25221 22683\n",
            " 24051 25571] 21854\n",
            "[15578 19364 24692 27143 27086 27875 24785 21713 25454 25221 22683 24051\n",
            " 25571 21854] 20816\n",
            "[19364 24692 27143 27086 27875 24785 21713 25454 25221 22683 24051 25571\n",
            " 21854 20816] 19152\n",
            "[27143 27086 27875 24785 21713 25454 25221 22683 24051 25571 21854 20816\n",
            " 19152 19883] 23975\n",
            "[27086 27875 24785 21713 25454 25221 22683 24051 25571 21854 20816 19152\n",
            " 19883 23975] 22464\n",
            "[27875 24785 21713 25454 25221 22683 24051 25571 21854 20816 19152 19883\n",
            " 23975 22464] 24213\n",
            "[21713 25454 25221 22683 24051 25571 21854 20816 19152 19883 23975 22464\n",
            " 24213 17856] 15002\n",
            "[22683 24051 25571 21854 20816 19152 19883 23975 22464 24213 17856 15002\n",
            " 32733 15356] 16690\n",
            "[24051 25571 21854 20816 19152 19883 23975 22464 24213 17856 15002 32733\n",
            " 15356 16690] 17304\n",
            "[25571 21854 20816 19152 19883 23975 22464 24213 17856 15002 32733 15356\n",
            " 16690 17304] 15177\n",
            "[21854 20816 19152 19883 23975 22464 24213 17856 15002 32733 15356 16690\n",
            " 17304 15177] 11482\n",
            "[20816 19152 19883 23975 22464 24213 17856 15002 32733 15356 16690 17304\n",
            " 15177 11482] 5736\n",
            "[19152 19883 23975 22464 24213 17856 15002 32733 15356 16690 17304 15177\n",
            " 11482  5736] 9113\n",
            "[24213 17856 15002 32733 15356 16690 17304 15177 11482  5736  9113 13823\n",
            " 14863 13236] 12427\n",
            "[17856 15002 32733 15356 16690 17304 15177 11482  5736  9113 13823 14863\n",
            " 13236 12427] 9176\n",
            "[15002 32733 15356 16690 17304 15177 11482  5736  9113 13823 14863 13236\n",
            " 12427  9176] 4421\n",
            "[32733 15356 16690 17304 15177 11482  5736  9113 13823 14863 13236 12427\n",
            "  9176  4421] 8310\n",
            "[15356 16690 17304 15177 11482  5736  9113 13823 14863 13236 12427  9176\n",
            "  4421  8310] 12166\n",
            "[17304 15177 11482  5736  9113 13823 14863 13236 12427  9176  4421  8310\n",
            " 12166 13750] 13105\n",
            "[15177 11482  5736  9113 13823 14863 13236 12427  9176  4421  8310 12166\n",
            " 13750 13105] 11499\n",
            "[11482  5736  9113 13823 14863 13236 12427  9176  4421  8310 12166 13750\n",
            " 13105 11499] 8976\n",
            "[ 9113 13823 14863 13236 12427  9176  4421  8310 12166 13750 13105 11499\n",
            "  8976  4896] 6874\n",
            "[13823 14863 13236 12427  9176  4421  8310 12166 13750 13105 11499  8976\n",
            "  4896  6874] 12455\n",
            "[14863 13236 12427  9176  4421  8310 12166 13750 13105 11499  8976  4896\n",
            "  6874 12455] 11953\n",
            "[13236 12427  9176  4421  8310 12166 13750 13105 11499  8976  4896  6874\n",
            " 12455 11953] 11010\n",
            "[12427  9176  4421  8310 12166 13750 13105 11499  8976  4896  6874 12455\n",
            " 11953 11010] 11246\n",
            "[ 9176  4421  8310 12166 13750 13105 11499  8976  4896  6874 12455 11953\n",
            " 11010 11246] 8590\n",
            "[ 4421  8310 12166 13750 13105 11499  8976  4896  6874 12455 11953 11010\n",
            " 11246  8590] 4633\n",
            "[ 8310 12166 13750 13105 11499  8976  4896  6874 12455 11953 11010 11246\n",
            "  8590  4633] 7192\n",
            "[13750 13105 11499  8976  4896  6874 12455 11953 11010 11246  8590  4633\n",
            "  7192 12358] 13115\n",
            "[13105 11499  8976  4896  6874 12455 11953 11010 11246  8590  4633  7192\n",
            " 12358 13115] 9081\n",
            "[ 8976  4896  6874 12455 11953 11010 11246  8590  4633  7192 12358 13115\n",
            "  9081  4878] 3842\n",
            "[ 4896  6874 12455 11953 11010 11246  8590  4633  7192 12358 13115  9081\n",
            "  4878  3842] 3211\n",
            "[11010 11246  8590  4633  7192 12358 13115  9081  4878  3842  3211  7624\n",
            " 12780 13464] 10896\n",
            "[ 8590  4633  7192 12358 13115  9081  4878  3842  3211  7624 12780 13464\n",
            " 10896  7006] 5782\n",
            "[ 4633  7192 12358 13115  9081  4878  3842  3211  7624 12780 13464 10896\n",
            "  7006  5782] 4385\n",
            "[ 7192 12358 13115  9081  4878  3842  3211  7624 12780 13464 10896  7006\n",
            "  5782  4385] 7596\n",
            "[12358 13115  9081  4878  3842  3211  7624 12780 13464 10896  7006  5782\n",
            "  4385  7596] 14220\n",
            "[13115  9081  4878  3842  3211  7624 12780 13464 10896  7006  5782  4385\n",
            "  7596 14220] 12119\n",
            "[ 9081  4878  3842  3211  7624 12780 13464 10896  7006  5782  4385  7596\n",
            " 14220 12119] 8763\n",
            "[ 3211  7624 12780 13464 10896  7006  5782  4385  7596 14220 12119  8763\n",
            " 10744  9133] 4863\n",
            "[ 7624 12780 13464 10896  7006  5782  4385  7596 14220 12119  8763 10744\n",
            "  9133  4863] 5394\n",
            "[13464 10896  7006  5782  4385  7596 14220 12119  8763 10744  9133  4863\n",
            "  5394  9126] 9436\n",
            "[ 7006  5782  4385  7596 14220 12119  8763 10744  9133  4863  5394  9126\n",
            "  9436  7979] 7292\n",
            "[ 5782  4385  7596 14220 12119  8763 10744  9133  4863  5394  9126  9436\n",
            "  7979  7292] 5970\n",
            "[ 4385  7596 14220 12119  8763 10744  9133  4863  5394  9126  9436  7979\n",
            "  7292  5970] 3332\n",
            "[ 7596 14220 12119  8763 10744  9133  4863  5394  9126  9436  7979  7292\n",
            "  5970  3332] 4890\n",
            "[14220 12119  8763 10744  9133  4863  5394  9126  9436  7979  7292  5970\n",
            "  3332  4890] 6943\n",
            "[12119  8763 10744  9133  4863  5394  9126  9436  7979  7292  5970  3332\n",
            "  4890  6943] 7008\n",
            "[ 8763 10744  9133  4863  5394  9126  9436  7979  7292  5970  3332  4890\n",
            "  6943  7008] 6693\n",
            "[10744  9133  4863  5394  9126  9436  7979  7292  5970  3332  4890  6943\n",
            "  7008  6693] 6304\n",
            "[4863 5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566] 2674\n",
            "[5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674] 4603\n",
            "[9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790] 7153\n",
            "[7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153] 6145\n",
            "[7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145] 5864\n",
            "[4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504] 4326\n",
            "[6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326] 6801\n",
            "[7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801] 6495\n",
            "[6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495] 6053\n",
            "[6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053] 5966\n",
            "[4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966] 4725\n",
            "[2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725] 2431\n",
            "[4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431] 3999\n",
            "[6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999] 6960\n",
            "[6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013] 6378\n",
            "[5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378] 6585\n",
            "[6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176] 8699\n",
            "[6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699] 9074\n",
            "[6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074] 8772\n",
            "[4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509] 7040\n",
            "[2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040] 3891\n",
            "[3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040 3891] 6304\n",
            "[6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040 3891 6304] 12147\n",
            "[ 7013  6378  6585  5334  2542  5176  8699  9074  8772  8509  7040  3891\n",
            "  6304 12147] 12143\n",
            "[ 6378  6585  5334  2542  5176  8699  9074  8772  8509  7040  3891  6304\n",
            " 12147 12143] 11536\n",
            "[ 6585  5334  2542  5176  8699  9074  8772  8509  7040  3891  6304 12147\n",
            " 12143 11536] 12097\n",
            "[ 5334  2542  5176  8699  9074  8772  8509  7040  3891  6304 12147 12143\n",
            " 11536 12097] 10101\n",
            "[ 5176  8699  9074  8772  8509  7040  3891  6304 12147 12143 11536 12097\n",
            " 10101  4786] 7936\n",
            "[ 8699  9074  8772  8509  7040  3891  6304 12147 12143 11536 12097 10101\n",
            "  4786  7936] 15698\n",
            "[ 9074  8772  8509  7040  3891  6304 12147 12143 11536 12097 10101  4786\n",
            "  7936 15698] 15253\n",
            "[ 8509  7040  3891  6304 12147 12143 11536 12097 10101  4786  7936 15698\n",
            " 15253 15831] 14855\n",
            "[ 7040  3891  6304 12147 12143 11536 12097 10101  4786  7936 15698 15253\n",
            " 15831 14855] 13569\n",
            "[ 3891  6304 12147 12143 11536 12097 10101  4786  7936 15698 15253 15831\n",
            " 14855 13569] 6169\n",
            "[ 6304 12147 12143 11536 12097 10101  4786  7936 15698 15253 15831 14855\n",
            " 13569  6169] 9953\n",
            "[12143 11536 12097 10101  4786  7936 15698 15253 15831 14855 13569  6169\n",
            "  9953 17277] 21111\n",
            "[11536 12097 10101  4786  7936 15698 15253 15831 14855 13569  6169  9953\n",
            " 17277 21111] 18873\n",
            "[12097 10101  4786  7936 15698 15253 15831 14855 13569  6169  9953 17277\n",
            " 21111 18873] 21063\n",
            "[10101  4786  7936 15698 15253 15831 14855 13569  6169  9953 17277 21111\n",
            " 18873 21063] 17272\n",
            "[15698 15253 15831 14855 13569  6169  9953 17277 21111 18873 21063 17272\n",
            " 10895 14394] 25053\n",
            "[15253 15831 14855 13569  6169  9953 17277 21111 18873 21063 17272 10895\n",
            " 14394 25053] 27274\n",
            "[15831 14855 13569  6169  9953 17277 21111 18873 21063 17272 10895 14394\n",
            " 25053 27274] 25996\n",
            "[14855 13569  6169  9953 17277 21111 18873 21063 17272 10895 14394 25053\n",
            " 27274 25996] 26456\n",
            "[13569  6169  9953 17277 21111 18873 21063 17272 10895 14394 25053 27274\n",
            " 25996 26456] 21850\n",
            "[ 9953 17277 21111 18873 21063 17272 10895 14394 25053 27274 25996 26456\n",
            " 21850 14579] 16740\n",
            "[17277 21111 18873 21063 17272 10895 14394 25053 27274 25996 26456 21850\n",
            " 14579 16740] 30802\n",
            "[21111 18873 21063 17272 10895 14394 25053 27274 25996 26456 21850 14579\n",
            " 16740 30802] 34150\n",
            "[18873 21063 17272 10895 14394 25053 27274 25996 26456 21850 14579 16740\n",
            " 30802 34150] 35145\n",
            "[21063 17272 10895 14394 25053 27274 25996 26456 21850 14579 16740 30802\n",
            " 34150 35145] 31759\n",
            "[17272 10895 14394 25053 27274 25996 26456 21850 14579 16740 30802 34150\n",
            " 35145 31759] 29266\n",
            "[10895 14394 25053 27274 25996 26456 21850 14579 16740 30802 34150 35145\n",
            " 31759 29266] 16973\n",
            "[14394 25053 27274 25996 26456 21850 14579 16740 30802 34150 35145 31759\n",
            " 29266 16973] 20862\n",
            "[25053 27274 25996 26456 21850 14579 16740 30802 34150 35145 31759 29266\n",
            " 16973 20862] 32891\n",
            "[27274 25996 26456 21850 14579 16740 30802 34150 35145 31759 29266 16973\n",
            " 20862 32891] 35253\n",
            "[25996 26456 21850 14579 16740 30802 34150 35145 31759 29266 16973 20862\n",
            " 32891 35253] 30541\n",
            "[26456 21850 14579 16740 30802 34150 35145 31759 29266 16973 20862 32891\n",
            " 35253 30541] 28073\n",
            "[21850 14579 16740 30802 34150 35145 31759 29266 16973 20862 32891 35253\n",
            " 30541 28073] 22958\n",
            "[14579 16740 30802 34150 35145 31759 29266 16973 20862 32891 35253 30541\n",
            " 28073 22958] 9921\n",
            "[16740 30802 34150 35145 31759 29266 16973 20862 32891 35253 30541 28073\n",
            " 22958  9921] 8246\n",
            "[34150 35145 31759 29266 16973 20862 32891 35253 30541 28073 22958  9921\n",
            "  8246 14908] 27890\n",
            "[29266 16973 20862 32891 35253 30541 28073 22958  9921  8246 14908 27890\n",
            " 28499 24892] 21733\n",
            "[16973 20862 32891 35253 30541 28073 22958  9921  8246 14908 27890 28499\n",
            " 24892 21733] 12016\n",
            "[20862 32891 35253 30541 28073 22958  9921  8246 14908 27890 28499 24892\n",
            " 21733 12016] 13203\n",
            "[32891 35253 30541 28073 22958  9921  8246 14908 27890 28499 24892 21733\n",
            " 12016 13203] 21266\n",
            "[35253 30541 28073 22958  9921  8246 14908 27890 28499 24892 21733 12016\n",
            " 13203 21266] 21126\n",
            "[28073 22958  9921  8246 14908 27890 28499 24892 21733 12016 13203 21266\n",
            " 21126 17846] 15786\n",
            "[22958  9921  8246 14908 27890 28499 24892 21733 12016 13203 21266 21126\n",
            " 17846 15786] 12151\n",
            "[ 9921  8246 14908 27890 28499 24892 21733 12016 13203 21266 21126 17846\n",
            " 15786 12151] 7302\n",
            "[ 8246 14908 27890 28499 24892 21733 12016 13203 21266 21126 17846 15786\n",
            " 12151  7302] 9244\n",
            "[14908 27890 28499 24892 21733 12016 13203 21266 21126 17846 15786 12151\n",
            "  7302  9244] 13922\n",
            "[27890 28499 24892 21733 12016 13203 21266 21126 17846 15786 12151  7302\n",
            "  9244 13922] 12763\n",
            "[28499 24892 21733 12016 13203 21266 21126 17846 15786 12151  7302  9244\n",
            " 13922 12763] 10866\n",
            "[24892 21733 12016 13203 21266 21126 17846 15786 12151  7302  9244 13922\n",
            " 12763 10866] 9510\n",
            "[12016 13203 21266 21126 17846 15786 12151  7302  9244 13922 12763 10866\n",
            "  9510  7224] 3467\n",
            "[13203 21266 21126 17846 15786 12151  7302  9244 13922 12763 10866  9510\n",
            "  7224  3467] 5711\n",
            "[21266 21126 17846 15786 12151  7302  9244 13922 12763 10866  9510  7224\n",
            "  3467  5711] 8893\n",
            "[21126 17846 15786 12151  7302  9244 13922 12763 10866  9510  7224  3467\n",
            "  5711  8893] 8426\n",
            "[17846 15786 12151  7302  9244 13922 12763 10866  9510  7224  3467  5711\n",
            "  8893  8426] 6789\n",
            "[15786 12151  7302  9244 13922 12763 10866  9510  7224  3467  5711  8893\n",
            "  8426  6789] 6475\n",
            "[12151  7302  9244 13922 12763 10866  9510  7224  3467  5711  8893  8426\n",
            "  6789  6475] 4616\n",
            "[ 7302  9244 13922 12763 10866  9510  7224  3467  5711  8893  8426  6789\n",
            "  6475  4616] 2523\n",
            "[ 9244 13922 12763 10866  9510  7224  3467  5711  8893  8426  6789  6475\n",
            "  4616  2523] 2296\n",
            "[13922 12763 10866  9510  7224  3467  5711  8893  8426  6789  6475  4616\n",
            "  2523  2296] 3899\n",
            "[12763 10866  9510  7224  3467  5711  8893  8426  6789  6475  4616  2523\n",
            "  2296  3899] 6427\n",
            "[9510 7224 3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047] 4771\n",
            "[3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856] 2031\n",
            "[5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031] 3097\n",
            "[8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097] 3948\n",
            "[8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948] 3694\n",
            "[6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694] 3289\n",
            "[6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289] 2897\n",
            "[2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169] 1111\n",
            "[2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111] 1727\n",
            "[3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727] 2348\n",
            "[6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348] 2087\n",
            "[6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087] 1678\n",
            "[4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678] 1517\n",
            "[2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075] 559\n",
            "[3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559] 1000\n",
            "[3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000] 1267\n",
            "[3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267] 1227\n",
            "[3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227] 946\n",
            "[2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946] 775\n",
            "[1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946  775  579] 333\n",
            "[2087 1678 1517 1075  559 1000 1267 1227  946  775  579  333  588  659] 572\n",
            "[1678 1517 1075  559 1000 1267 1227  946  775  579  333  588  659  572] 317\n",
            "[1517 1075  559 1000 1267 1227  946  775  579  333  588  659  572  317] 415\n",
            "[1075  559 1000 1267 1227  946  775  579  333  588  659  572  317  415] 310\n",
            "[ 559 1000 1267 1227  946  775  579  333  588  659  572  317  415  310] 195\n",
            "[1000 1267 1227  946  775  579  333  588  659  572  317  415  310  195] 532\n",
            "[1267 1227  946  775  579  333  588  659  572  317  415  310  195  532] 428\n",
            "[1227  946  775  579  333  588  659  572  317  415  310  195  532  428] 382\n",
            "[775 579 333 588 659 572 317 415 310 195 532 428 382 341] 238\n",
            "[579 333 588 659 572 317 415 310 195 532 428 382 341 238] 226\n",
            "[333 588 659 572 317 415 310 195 532 428 382 341 238 226] 140\n",
            "[659 572 317 415 310 195 532 428 382 341 238 226 140 215] 238\n",
            "[572 317 415 310 195 532 428 382 341 238 226 140 215 238] 218\n",
            "[317 415 310 195 532 428 382 341 238 226 140 215 238 218] 190\n",
            "[415 310 195 532 428 382 341 238 226 140 215 238 218 190] 168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0PLxD5xXyz"
      },
      "source": [
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "Validation_X = Validation_X.reshape((Validation_X.shape[0], Validation_X.shape[1], n_features))\n",
        "Y = Y.reshape((Y.shape[0], 1, n_features))\n",
        "Validation_Y = Validation_Y.reshape((Validation_Y.shape[0], 1, n_features))\n",
        "look_back = n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_-ZW77mxava",
        "outputId": "8a2268c1-0390-4694-f169-4d4ce49b2942"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(372, 14, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw8wRQf3BCKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d29c693-e4b1-4e75-a9f2-55dd8fa6839a"
      },
      "source": [
        "#creating the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    LSTM(50,\n",
        "        activation='relu',\n",
        "        input_shape=(look_back,1))\n",
        ")\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='RMSprop', loss='mae')\n",
        "\n",
        "num_epochs = 10000"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEeHxQe8xk84",
        "outputId": "e769a68a-9ab0-4d3c-e3f9-d306f096164c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kBvWEfHxn5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db67984-8d34-4f2b-9bcf-71e68f7cc5be"
      },
      "source": [
        "history = model.fit(X, Y, epochs=num_epochs, validation_data=(X,Y), verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n",
            "Epoch 7501/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 624.7082 - val_loss: 577.6144\n",
            "Epoch 7502/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 589.1257 - val_loss: 604.8022\n",
            "Epoch 7503/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 631.6767 - val_loss: 547.1340\n",
            "Epoch 7504/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 504.3245 - val_loss: 553.8243\n",
            "Epoch 7505/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 494.7115 - val_loss: 525.6287\n",
            "Epoch 7506/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 520.3600 - val_loss: 535.6426\n",
            "Epoch 7507/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 549.5137 - val_loss: 519.3140\n",
            "Epoch 7508/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 507.5603 - val_loss: 513.1385\n",
            "Epoch 7509/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 481.1718 - val_loss: 589.1080\n",
            "Epoch 7510/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 572.8796 - val_loss: 578.3731\n",
            "Epoch 7511/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 605.6428 - val_loss: 632.8751\n",
            "Epoch 7512/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 550.3976 - val_loss: 562.9824\n",
            "Epoch 7513/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 587.2107 - val_loss: 600.2010\n",
            "Epoch 7514/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 621.3127 - val_loss: 593.9349\n",
            "Epoch 7515/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 622.3434 - val_loss: 525.1311\n",
            "Epoch 7516/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 486.6035 - val_loss: 540.9916\n",
            "Epoch 7517/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 472.3900 - val_loss: 649.0707\n",
            "Epoch 7518/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 641.2120 - val_loss: 564.3408\n",
            "Epoch 7519/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 500.3588 - val_loss: 531.5767\n",
            "Epoch 7520/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 620.6547 - val_loss: 597.2588\n",
            "Epoch 7521/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 559.4667 - val_loss: 755.6416\n",
            "Epoch 7522/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 879.2229 - val_loss: 947.9054\n",
            "Epoch 7523/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1046.8315 - val_loss: 799.7715\n",
            "Epoch 7524/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 854.5811 - val_loss: 810.3990\n",
            "Epoch 7525/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 827.7837 - val_loss: 790.8962\n",
            "Epoch 7526/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 882.2897 - val_loss: 778.0159\n",
            "Epoch 7527/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 696.4400 - val_loss: 749.0175\n",
            "Epoch 7528/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 691.2719 - val_loss: 768.6853\n",
            "Epoch 7529/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 647.4444 - val_loss: 680.3194\n",
            "Epoch 7530/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 816.7636 - val_loss: 875.8973\n",
            "Epoch 7531/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1010.6150 - val_loss: 1013.5479\n",
            "Epoch 7532/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1003.3642 - val_loss: 844.1124\n",
            "Epoch 7533/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 850.5032 - val_loss: 853.5137\n",
            "Epoch 7534/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 762.2514 - val_loss: 894.9127\n",
            "Epoch 7535/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 953.6827 - val_loss: 905.1512\n",
            "Epoch 7536/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 880.1689 - val_loss: 869.3217\n",
            "Epoch 7537/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 933.9605 - val_loss: 1111.7546\n",
            "Epoch 7538/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1165.8966 - val_loss: 1115.0514\n",
            "Epoch 7539/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1046.2704 - val_loss: 1042.7845\n",
            "Epoch 7540/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1200.7257 - val_loss: 1160.0142\n",
            "Epoch 7541/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1076.2744 - val_loss: 971.6144\n",
            "Epoch 7542/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 887.6710 - val_loss: 927.2295\n",
            "Epoch 7543/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 906.1092 - val_loss: 1010.8570\n",
            "Epoch 7544/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 929.1121 - val_loss: 977.7687\n",
            "Epoch 7545/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 984.6042 - val_loss: 1032.0155\n",
            "Epoch 7546/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1052.5396 - val_loss: 1147.4796\n",
            "Epoch 7547/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 1014.6262 - val_loss: 948.3318\n",
            "Epoch 7548/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 843.7026 - val_loss: 1048.9023\n",
            "Epoch 7549/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 1130.8871 - val_loss: 1089.1864\n",
            "Epoch 7550/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 1135.1428 - val_loss: 1026.1453\n",
            "Epoch 7551/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 1065.9754 - val_loss: 1012.8181\n",
            "Epoch 7552/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 943.8010 - val_loss: 869.1902\n",
            "Epoch 7553/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 832.8767 - val_loss: 814.9456\n",
            "Epoch 7554/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 1006.4019 - val_loss: 839.8325\n",
            "Epoch 7555/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 730.5474 - val_loss: 777.5371\n",
            "Epoch 7556/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 794.1085 - val_loss: 824.0836\n",
            "Epoch 7557/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 800.5567 - val_loss: 927.7390\n",
            "Epoch 7558/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 937.9643 - val_loss: 864.5370\n",
            "Epoch 7559/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 896.2864 - val_loss: 767.8322\n",
            "Epoch 7560/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 764.9221 - val_loss: 818.8583\n",
            "Epoch 7561/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 884.4789 - val_loss: 783.6810\n",
            "Epoch 7562/10000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 820.4094 - val_loss: 819.1520\n",
            "Epoch 7563/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 974.3475 - val_loss: 762.6817\n",
            "Epoch 7564/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 809.5528 - val_loss: 802.2437\n",
            "Epoch 7565/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 796.3459 - val_loss: 972.7176\n",
            "Epoch 7566/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 987.7269 - val_loss: 1130.8322\n",
            "Epoch 7567/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1327.7624 - val_loss: 965.1879\n",
            "Epoch 7568/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 922.4820 - val_loss: 862.1077\n",
            "Epoch 7569/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 889.0020 - val_loss: 833.3633\n",
            "Epoch 7570/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 836.4461 - val_loss: 840.1967\n",
            "Epoch 7571/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 954.1876 - val_loss: 860.0543\n",
            "Epoch 7572/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 837.3651 - val_loss: 930.5578\n",
            "Epoch 7573/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 887.3003 - val_loss: 839.3188\n",
            "Epoch 7574/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 906.1404 - val_loss: 869.1497\n",
            "Epoch 7575/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 921.0338 - val_loss: 807.5948\n",
            "Epoch 7576/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 849.1365 - val_loss: 745.7159\n",
            "Epoch 7577/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 972.6947 - val_loss: 754.7700\n",
            "Epoch 7578/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 837.6975 - val_loss: 772.4845\n",
            "Epoch 7579/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 877.2920 - val_loss: 757.0775\n",
            "Epoch 7580/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 780.3281 - val_loss: 746.4710\n",
            "Epoch 7581/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 817.2624 - val_loss: 948.2332\n",
            "Epoch 7582/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 1015.8752 - val_loss: 922.5333\n",
            "Epoch 7583/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 801.2284 - val_loss: 879.9274\n",
            "Epoch 7584/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 873.0077 - val_loss: 1022.0634\n",
            "Epoch 7585/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 992.1522 - val_loss: 928.9489\n",
            "Epoch 7586/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 811.7864 - val_loss: 816.2245\n",
            "Epoch 7587/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 707.1169 - val_loss: 802.8691\n",
            "Epoch 7588/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 1020.3524 - val_loss: 1009.4398\n",
            "Epoch 7589/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 805.2089 - val_loss: 913.4283\n",
            "Epoch 7590/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 859.4178 - val_loss: 869.4802\n",
            "Epoch 7591/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 992.6993 - val_loss: 901.1988\n",
            "Epoch 7592/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 878.5101 - val_loss: 775.3554\n",
            "Epoch 7593/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 718.9364 - val_loss: 737.6396\n",
            "Epoch 7594/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 712.3935 - val_loss: 690.3608\n",
            "Epoch 7595/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 777.6651 - val_loss: 702.6373\n",
            "Epoch 7596/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 673.6695 - val_loss: 666.6522\n",
            "Epoch 7597/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 806.6077 - val_loss: 656.8723\n",
            "Epoch 7598/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 659.8843 - val_loss: 691.6027\n",
            "Epoch 7599/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 622.7836 - val_loss: 622.8011\n",
            "Epoch 7600/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 634.9222 - val_loss: 661.6165\n",
            "Epoch 7601/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 684.7708 - val_loss: 719.6789\n",
            "Epoch 7602/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 763.1111 - val_loss: 652.1639\n",
            "Epoch 7603/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 618.6306 - val_loss: 692.8991\n",
            "Epoch 7604/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 743.9555 - val_loss: 657.6256\n",
            "Epoch 7605/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 711.9762 - val_loss: 747.9211\n",
            "Epoch 7606/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 694.8970 - val_loss: 794.5249\n",
            "Epoch 7607/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 691.5928 - val_loss: 634.9359\n",
            "Epoch 7608/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 696.9925 - val_loss: 760.0018\n",
            "Epoch 7609/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 716.2502 - val_loss: 747.3937\n",
            "Epoch 7610/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 616.7045 - val_loss: 700.3486\n",
            "Epoch 7611/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 685.3350 - val_loss: 643.8214\n",
            "Epoch 7612/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 721.5365 - val_loss: 709.8995\n",
            "Epoch 7613/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 637.2366 - val_loss: 655.2593\n",
            "Epoch 7614/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 738.0731 - val_loss: 707.2352\n",
            "Epoch 7615/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 691.0137 - val_loss: 709.7839\n",
            "Epoch 7616/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 673.1232 - val_loss: 716.0117\n",
            "Epoch 7617/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 653.8699 - val_loss: 670.6908\n",
            "Epoch 7618/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 714.5847 - val_loss: 736.9008\n",
            "Epoch 7619/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 847.1446 - val_loss: 655.3345\n",
            "Epoch 7620/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 708.9847 - val_loss: 593.0279\n",
            "Epoch 7621/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 650.5270 - val_loss: 568.9597\n",
            "Epoch 7622/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 524.4126 - val_loss: 612.5663\n",
            "Epoch 7623/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 565.9728 - val_loss: 571.4871\n",
            "Epoch 7624/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 568.3048 - val_loss: 596.4774\n",
            "Epoch 7625/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 594.0701 - val_loss: 628.8281\n",
            "Epoch 7626/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 606.3950 - val_loss: 621.5237\n",
            "Epoch 7627/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 596.7820 - val_loss: 630.4114\n",
            "Epoch 7628/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 702.2650 - val_loss: 573.2895\n",
            "Epoch 7629/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 624.3831 - val_loss: 613.2406\n",
            "Epoch 7630/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 578.4588 - val_loss: 614.3757\n",
            "Epoch 7631/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 554.9404 - val_loss: 614.1284\n",
            "Epoch 7632/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 642.3597 - val_loss: 569.2457\n",
            "Epoch 7633/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 703.5153 - val_loss: 636.0357\n",
            "Epoch 7634/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 543.6880 - val_loss: 672.3799\n",
            "Epoch 7635/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 846.0802 - val_loss: 582.3235\n",
            "Epoch 7636/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 571.4457 - val_loss: 582.6730\n",
            "Epoch 7637/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 602.0611 - val_loss: 563.3558\n",
            "Epoch 7638/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 622.9286 - val_loss: 680.8893\n",
            "Epoch 7639/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 708.3664 - val_loss: 601.4630\n",
            "Epoch 7640/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 632.4992 - val_loss: 565.6857\n",
            "Epoch 7641/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 607.8650 - val_loss: 548.4686\n",
            "Epoch 7642/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 658.3392 - val_loss: 565.5652\n",
            "Epoch 7643/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 503.4183 - val_loss: 615.8980\n",
            "Epoch 7644/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 599.7875 - val_loss: 551.2211\n",
            "Epoch 7645/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 546.7764 - val_loss: 597.9619\n",
            "Epoch 7646/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 539.9567 - val_loss: 544.3439\n",
            "Epoch 7647/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 587.0904 - val_loss: 577.8228\n",
            "Epoch 7648/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 608.4638 - val_loss: 517.7276\n",
            "Epoch 7649/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 503.5927 - val_loss: 556.7088\n",
            "Epoch 7650/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 560.3842 - val_loss: 563.7773\n",
            "Epoch 7651/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 586.5893 - val_loss: 573.4573\n",
            "Epoch 7652/10000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 510.9430 - val_loss: 536.4814\n",
            "Epoch 7653/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 646.3534 - val_loss: 535.0518\n",
            "Epoch 7654/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 598.9739 - val_loss: 542.8234\n",
            "Epoch 7655/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 536.7352 - val_loss: 558.4205\n",
            "Epoch 7656/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 531.3694 - val_loss: 543.3242\n",
            "Epoch 7657/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 508.8716 - val_loss: 561.0065\n",
            "Epoch 7658/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 523.8538 - val_loss: 538.8645\n",
            "Epoch 7659/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 580.2088 - val_loss: 613.3613\n",
            "Epoch 7660/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 656.3390 - val_loss: 620.1081\n",
            "Epoch 7661/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 613.4736 - val_loss: 540.4719\n",
            "Epoch 7662/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 556.3231 - val_loss: 556.9940\n",
            "Epoch 7663/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 761.1898 - val_loss: 576.1194\n",
            "Epoch 7664/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 544.7353 - val_loss: 543.2467\n",
            "Epoch 7665/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 569.0886 - val_loss: 507.5694\n",
            "Epoch 7666/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 521.3331 - val_loss: 507.2787\n",
            "Epoch 7667/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 481.1006 - val_loss: 541.2815\n",
            "Epoch 7668/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 597.9806 - val_loss: 525.8846\n",
            "Epoch 7669/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 508.2498 - val_loss: 590.3592\n",
            "Epoch 7670/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 635.4374 - val_loss: 508.5926\n",
            "Epoch 7671/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 496.4584 - val_loss: 561.0781\n",
            "Epoch 7672/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 523.0467 - val_loss: 523.3740\n",
            "Epoch 7673/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 556.4239 - val_loss: 544.2136\n",
            "Epoch 7674/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 496.4260 - val_loss: 562.1342\n",
            "Epoch 7675/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 579.0001 - val_loss: 611.2053\n",
            "Epoch 7676/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 671.6673 - val_loss: 581.9268\n",
            "Epoch 7677/10000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 554.7836 - val_loss: 650.8906\n",
            "Epoch 7678/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 544.6608 - val_loss: 580.0886\n",
            "Epoch 7679/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 576.6153 - val_loss: 565.4491\n",
            "Epoch 7680/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 530.9985 - val_loss: 640.2863\n",
            "Epoch 7681/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 614.5364 - val_loss: 624.1594\n",
            "Epoch 7682/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 693.9005 - val_loss: 595.7258\n",
            "Epoch 7683/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 597.2328 - val_loss: 596.4547\n",
            "Epoch 7684/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 687.7023 - val_loss: 586.8973\n",
            "Epoch 7685/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 596.4152 - val_loss: 601.0869\n",
            "Epoch 7686/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 601.8771 - val_loss: 591.7855\n",
            "Epoch 7687/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 596.9420 - val_loss: 612.8281\n",
            "Epoch 7688/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 636.3105 - val_loss: 544.5703\n",
            "Epoch 7689/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 537.3491 - val_loss: 564.0677\n",
            "Epoch 7690/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 559.3996 - val_loss: 547.2107\n",
            "Epoch 7691/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 565.0968 - val_loss: 527.4993\n",
            "Epoch 7692/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 554.0629 - val_loss: 533.2390\n",
            "Epoch 7693/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 545.0995 - val_loss: 575.2665\n",
            "Epoch 7694/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 601.6610 - val_loss: 603.6398\n",
            "Epoch 7695/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 689.7623 - val_loss: 552.6700\n",
            "Epoch 7696/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 530.2448 - val_loss: 586.1738\n",
            "Epoch 7697/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 558.1214 - val_loss: 559.6165\n",
            "Epoch 7698/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 553.1042 - val_loss: 598.0344\n",
            "Epoch 7699/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 562.8364 - val_loss: 574.2323\n",
            "Epoch 7700/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 554.6035 - val_loss: 559.5011\n",
            "Epoch 7701/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 509.7436 - val_loss: 593.9857\n",
            "Epoch 7702/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 676.2574 - val_loss: 546.8979\n",
            "Epoch 7703/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 562.0897 - val_loss: 530.5146\n",
            "Epoch 7704/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 533.6459 - val_loss: 522.0542\n",
            "Epoch 7705/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 636.6951 - val_loss: 541.7607\n",
            "Epoch 7706/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 546.2868 - val_loss: 549.1897\n",
            "Epoch 7707/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 538.2481 - val_loss: 572.3498\n",
            "Epoch 7708/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 573.5636 - val_loss: 491.1974\n",
            "Epoch 7709/10000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 584.8223 - val_loss: 545.7914\n",
            "Epoch 7710/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 524.9744 - val_loss: 526.7173\n",
            "Epoch 7711/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 512.0762 - val_loss: 678.5438\n",
            "Epoch 7712/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 665.0283 - val_loss: 587.4246\n",
            "Epoch 7713/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 571.0251 - val_loss: 533.3096\n",
            "Epoch 7714/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 579.5567 - val_loss: 506.8888\n",
            "Epoch 7715/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 621.5104 - val_loss: 541.1260\n",
            "Epoch 7716/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 505.8709 - val_loss: 554.9504\n",
            "Epoch 7717/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 576.9518 - val_loss: 540.1176\n",
            "Epoch 7718/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 548.0324 - val_loss: 545.9196\n",
            "Epoch 7719/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 527.0079 - val_loss: 553.1805\n",
            "Epoch 7720/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 531.7295 - val_loss: 580.8978\n",
            "Epoch 7721/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 567.9631 - val_loss: 571.9562\n",
            "Epoch 7722/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 644.0944 - val_loss: 560.2696\n",
            "Epoch 7723/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 566.9123 - val_loss: 568.0919\n",
            "Epoch 7724/10000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 589.8936 - val_loss: 591.6353\n",
            "Epoch 7725/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 673.9821 - val_loss: 630.9139\n",
            "Epoch 7726/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 589.8453 - val_loss: 580.8206\n",
            "Epoch 7727/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 589.1261 - val_loss: 579.4874\n",
            "Epoch 7728/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 514.5496 - val_loss: 588.7413\n",
            "Epoch 7729/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 586.4960 - val_loss: 595.5923\n",
            "Epoch 7730/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 621.3473 - val_loss: 649.6263\n",
            "Epoch 7731/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 773.0464 - val_loss: 916.3024\n",
            "Epoch 7732/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 750.5378 - val_loss: 747.9506\n",
            "Epoch 7733/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 774.5110 - val_loss: 939.6710\n",
            "Epoch 7734/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 967.2612 - val_loss: 863.6546\n",
            "Epoch 7735/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 841.3348 - val_loss: 945.8824\n",
            "Epoch 7736/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 989.6976 - val_loss: 924.2379\n",
            "Epoch 7737/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 846.3113 - val_loss: 804.0341\n",
            "Epoch 7738/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 800.9161 - val_loss: 726.5614\n",
            "Epoch 7739/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 673.8873 - val_loss: 766.2491\n",
            "Epoch 7740/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 633.1104 - val_loss: 790.1437\n",
            "Epoch 7741/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 816.8922 - val_loss: 737.0493\n",
            "Epoch 7742/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 834.4040 - val_loss: 953.0648\n",
            "Epoch 7743/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 788.0812 - val_loss: 685.6098\n",
            "Epoch 7744/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 623.9390 - val_loss: 569.6205\n",
            "Epoch 7745/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 493.8082 - val_loss: 604.3910\n",
            "Epoch 7746/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 523.7311 - val_loss: 589.0620\n",
            "Epoch 7747/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 573.7220 - val_loss: 598.5059\n",
            "Epoch 7748/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 545.7165 - val_loss: 596.1916\n",
            "Epoch 7749/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 649.0558 - val_loss: 650.1135\n",
            "Epoch 7750/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 690.3201 - val_loss: 679.9709\n",
            "Epoch 7751/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 626.6664 - val_loss: 639.9671\n",
            "Epoch 7752/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 667.1147 - val_loss: 589.8615\n",
            "Epoch 7753/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 592.1763 - val_loss: 559.1510\n",
            "Epoch 7754/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 550.7200 - val_loss: 594.4017\n",
            "Epoch 7755/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 701.4042 - val_loss: 660.9854\n",
            "Epoch 7756/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 686.0760 - val_loss: 641.5970\n",
            "Epoch 7757/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 649.5302 - val_loss: 548.6641\n",
            "Epoch 7758/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 532.8206 - val_loss: 596.7207\n",
            "Epoch 7759/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 691.2886 - val_loss: 733.4974\n",
            "Epoch 7760/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 698.2894 - val_loss: 678.0837\n",
            "Epoch 7761/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 739.1379 - val_loss: 753.5712\n",
            "Epoch 7762/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 796.8507 - val_loss: 833.9020\n",
            "Epoch 7763/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 847.0841 - val_loss: 697.8517\n",
            "Epoch 7764/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 672.3190 - val_loss: 733.6342\n",
            "Epoch 7765/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 697.1207 - val_loss: 734.9294\n",
            "Epoch 7766/10000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 664.1476 - val_loss: 577.5287\n",
            "Epoch 7767/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 633.6943 - val_loss: 583.0388\n",
            "Epoch 7768/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 606.8659 - val_loss: 598.1472\n",
            "Epoch 7769/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 677.1690 - val_loss: 669.0581\n",
            "Epoch 7770/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 620.7280 - val_loss: 558.8656\n",
            "Epoch 7771/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 568.8619 - val_loss: 555.0209\n",
            "Epoch 7772/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 537.0069 - val_loss: 681.8394\n",
            "Epoch 7773/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 687.4763 - val_loss: 667.1550\n",
            "Epoch 7774/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 717.9051 - val_loss: 600.0272\n",
            "Epoch 7775/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 573.3420 - val_loss: 647.0814\n",
            "Epoch 7776/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 602.3698 - val_loss: 627.7206\n",
            "Epoch 7777/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 537.7272 - val_loss: 581.8153\n",
            "Epoch 7778/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 595.8552 - val_loss: 652.3998\n",
            "Epoch 7779/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 673.7718 - val_loss: 649.8998\n",
            "Epoch 7780/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 711.1253 - val_loss: 622.2739\n",
            "Epoch 7781/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 635.6324 - val_loss: 588.2907\n",
            "Epoch 7782/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 591.4401 - val_loss: 571.6094\n",
            "Epoch 7783/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 592.4371 - val_loss: 601.0441\n",
            "Epoch 7784/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 657.2452 - val_loss: 564.4056\n",
            "Epoch 7785/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 656.0917 - val_loss: 648.1261\n",
            "Epoch 7786/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 655.1303 - val_loss: 573.2249\n",
            "Epoch 7787/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 541.9234 - val_loss: 659.9838\n",
            "Epoch 7788/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 714.6601 - val_loss: 565.3385\n",
            "Epoch 7789/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 564.2751 - val_loss: 608.4610\n",
            "Epoch 7790/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 638.6659 - val_loss: 553.8025\n",
            "Epoch 7791/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 490.1254 - val_loss: 532.7649\n",
            "Epoch 7792/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 603.0313 - val_loss: 538.3323\n",
            "Epoch 7793/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 565.8153 - val_loss: 617.7285\n",
            "Epoch 7794/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 546.5710 - val_loss: 623.8590\n",
            "Epoch 7795/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 577.1955 - val_loss: 606.3382\n",
            "Epoch 7796/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 684.4548 - val_loss: 592.3662\n",
            "Epoch 7797/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 546.1389 - val_loss: 553.0436\n",
            "Epoch 7798/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 585.3165 - val_loss: 681.0070\n",
            "Epoch 7799/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 734.1804 - val_loss: 606.5879\n",
            "Epoch 7800/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 668.6314 - val_loss: 601.5604\n",
            "Epoch 7801/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 626.4404 - val_loss: 633.7592\n",
            "Epoch 7802/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 501.5841 - val_loss: 578.3536\n",
            "Epoch 7803/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 603.9486 - val_loss: 569.2637\n",
            "Epoch 7804/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 603.6382 - val_loss: 586.1772\n",
            "Epoch 7805/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 542.2124 - val_loss: 688.5483\n",
            "Epoch 7806/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 659.1439 - val_loss: 638.5939\n",
            "Epoch 7807/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 604.9599 - val_loss: 609.1092\n",
            "Epoch 7808/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 628.7378 - val_loss: 619.4812\n",
            "Epoch 7809/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 623.1308 - val_loss: 612.6838\n",
            "Epoch 7810/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 608.9915 - val_loss: 597.1240\n",
            "Epoch 7811/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 535.0197 - val_loss: 575.3370\n",
            "Epoch 7812/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 622.6909 - val_loss: 575.1476\n",
            "Epoch 7813/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 572.8903 - val_loss: 568.5079\n",
            "Epoch 7814/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 548.0415 - val_loss: 584.1071\n",
            "Epoch 7815/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 590.5557 - val_loss: 642.6713\n",
            "Epoch 7816/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 681.2544 - val_loss: 581.6759\n",
            "Epoch 7817/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 667.8327 - val_loss: 550.6257\n",
            "Epoch 7818/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 597.3665 - val_loss: 601.7239\n",
            "Epoch 7819/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 675.1189 - val_loss: 601.5166\n",
            "Epoch 7820/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 562.7970 - val_loss: 699.5953\n",
            "Epoch 7821/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 703.1159 - val_loss: 646.7864\n",
            "Epoch 7822/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 604.0863 - val_loss: 566.3951\n",
            "Epoch 7823/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 662.7008 - val_loss: 620.2012\n",
            "Epoch 7824/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 560.2319 - val_loss: 590.5119\n",
            "Epoch 7825/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 664.3534 - val_loss: 586.5894\n",
            "Epoch 7826/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 633.9352 - val_loss: 578.8870\n",
            "Epoch 7827/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 594.3050 - val_loss: 607.5269\n",
            "Epoch 7828/10000\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 677.8653 - val_loss: 543.4833\n",
            "Epoch 7829/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 568.7420 - val_loss: 527.9514\n",
            "Epoch 7830/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 583.3232 - val_loss: 551.8795\n",
            "Epoch 7831/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 565.8161 - val_loss: 607.6592\n",
            "Epoch 7832/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 558.7751 - val_loss: 569.0167\n",
            "Epoch 7833/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 572.1013 - val_loss: 543.8781\n",
            "Epoch 7834/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 475.6690 - val_loss: 571.7271\n",
            "Epoch 7835/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 563.8416 - val_loss: 549.6695\n",
            "Epoch 7836/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 569.9298 - val_loss: 590.3290\n",
            "Epoch 7837/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 648.2284 - val_loss: 519.1038\n",
            "Epoch 7838/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 521.8611 - val_loss: 567.6124\n",
            "Epoch 7839/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 600.1240 - val_loss: 576.7275\n",
            "Epoch 7840/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 584.5383 - val_loss: 603.4890\n",
            "Epoch 7841/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 637.4493 - val_loss: 622.9238\n",
            "Epoch 7842/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 594.9089 - val_loss: 660.5866\n",
            "Epoch 7843/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 653.1096 - val_loss: 612.1366\n",
            "Epoch 7844/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 642.1553 - val_loss: 638.2465\n",
            "Epoch 7845/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 573.8700 - val_loss: 598.0139\n",
            "Epoch 7846/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 542.9683 - val_loss: 588.7108\n",
            "Epoch 7847/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 628.5566 - val_loss: 648.4506\n",
            "Epoch 7848/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 673.3815 - val_loss: 632.9776\n",
            "Epoch 7849/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 675.4851 - val_loss: 614.1942\n",
            "Epoch 7850/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 547.0334 - val_loss: 623.0218\n",
            "Epoch 7851/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 589.6080 - val_loss: 570.4506\n",
            "Epoch 7852/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 584.4933 - val_loss: 561.4473\n",
            "Epoch 7853/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 535.6875 - val_loss: 560.5383\n",
            "Epoch 7854/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 542.3812 - val_loss: 636.2416\n",
            "Epoch 7855/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 536.9678 - val_loss: 607.7929\n",
            "Epoch 7856/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 691.0916 - val_loss: 567.0475\n",
            "Epoch 7857/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 606.2996 - val_loss: 577.0502\n",
            "Epoch 7858/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 547.4674 - val_loss: 560.4801\n",
            "Epoch 7859/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 495.9466 - val_loss: 736.1439\n",
            "Epoch 7860/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 742.2340 - val_loss: 671.4899\n",
            "Epoch 7861/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 704.7045 - val_loss: 697.0243\n",
            "Epoch 7862/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 735.6185 - val_loss: 699.3223\n",
            "Epoch 7863/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 763.4916 - val_loss: 741.8380\n",
            "Epoch 7864/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 676.2447 - val_loss: 776.1941\n",
            "Epoch 7865/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 669.9208 - val_loss: 710.5758\n",
            "Epoch 7866/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 769.8808 - val_loss: 739.2440\n",
            "Epoch 7867/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 693.5656 - val_loss: 658.2382\n",
            "Epoch 7868/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 681.4208 - val_loss: 581.7474\n",
            "Epoch 7869/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 629.1906 - val_loss: 601.7605\n",
            "Epoch 7870/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 553.6890 - val_loss: 549.4157\n",
            "Epoch 7871/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 581.8940 - val_loss: 551.7712\n",
            "Epoch 7872/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 635.5489 - val_loss: 592.9613\n",
            "Epoch 7873/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 594.4750 - val_loss: 604.1291\n",
            "Epoch 7874/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 612.2803 - val_loss: 605.9061\n",
            "Epoch 7875/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 636.4986 - val_loss: 615.4941\n",
            "Epoch 7876/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 554.4548 - val_loss: 597.5161\n",
            "Epoch 7877/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 594.6628 - val_loss: 545.9082\n",
            "Epoch 7878/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 532.2303 - val_loss: 604.9424\n",
            "Epoch 7879/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 611.0690 - val_loss: 566.4767\n",
            "Epoch 7880/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 554.8792 - val_loss: 557.9994\n",
            "Epoch 7881/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 514.6675 - val_loss: 559.8486\n",
            "Epoch 7882/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 535.2927 - val_loss: 578.3170\n",
            "Epoch 7883/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 645.6733 - val_loss: 553.3545\n",
            "Epoch 7884/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 541.1783 - val_loss: 561.7695\n",
            "Epoch 7885/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 589.5850 - val_loss: 565.7684\n",
            "Epoch 7886/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 487.9141 - val_loss: 578.1958\n",
            "Epoch 7887/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 596.4794 - val_loss: 587.3369\n",
            "Epoch 7888/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 584.0453 - val_loss: 561.6219\n",
            "Epoch 7889/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 626.3796 - val_loss: 578.1594\n",
            "Epoch 7890/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 564.2765 - val_loss: 572.9771\n",
            "Epoch 7891/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 558.6877 - val_loss: 533.8334\n",
            "Epoch 7892/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 552.3233 - val_loss: 576.0296\n",
            "Epoch 7893/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 605.4803 - val_loss: 578.4355\n",
            "Epoch 7894/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 566.9751 - val_loss: 556.3397\n",
            "Epoch 7895/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 566.3008 - val_loss: 636.3935\n",
            "Epoch 7896/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 687.0839 - val_loss: 644.1707\n",
            "Epoch 7897/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 612.0782 - val_loss: 601.3369\n",
            "Epoch 7898/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 577.7532 - val_loss: 600.3107\n",
            "Epoch 7899/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 568.0321 - val_loss: 597.0936\n",
            "Epoch 7900/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 690.9896 - val_loss: 621.5266\n",
            "Epoch 7901/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 555.2651 - val_loss: 568.2405\n",
            "Epoch 7902/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 591.3685 - val_loss: 571.3791\n",
            "Epoch 7903/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 641.3454 - val_loss: 573.6469\n",
            "Epoch 7904/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 569.9222 - val_loss: 578.2420\n",
            "Epoch 7905/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 599.9468 - val_loss: 579.5674\n",
            "Epoch 7906/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 588.2109 - val_loss: 570.3534\n",
            "Epoch 7907/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 563.3098 - val_loss: 543.8858\n",
            "Epoch 7908/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 558.0603 - val_loss: 570.8622\n",
            "Epoch 7909/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 532.1877 - val_loss: 527.1870\n",
            "Epoch 7910/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 482.8277 - val_loss: 606.7629\n",
            "Epoch 7911/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 596.5770 - val_loss: 580.5064\n",
            "Epoch 7912/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 555.8840 - val_loss: 569.8404\n",
            "Epoch 7913/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 601.0707 - val_loss: 617.9442\n",
            "Epoch 7914/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 592.8773 - val_loss: 606.9498\n",
            "Epoch 7915/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 606.2689 - val_loss: 539.5256\n",
            "Epoch 7916/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 523.2692 - val_loss: 546.1013\n",
            "Epoch 7917/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 653.4899 - val_loss: 620.7062\n",
            "Epoch 7918/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 582.8807 - val_loss: 623.3015\n",
            "Epoch 7919/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 563.8265 - val_loss: 609.2264\n",
            "Epoch 7920/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 574.9568 - val_loss: 626.8795\n",
            "Epoch 7921/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 597.6333 - val_loss: 599.7251\n",
            "Epoch 7922/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 600.7940 - val_loss: 535.3773\n",
            "Epoch 7923/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 568.3946 - val_loss: 534.2095\n",
            "Epoch 7924/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 599.7911 - val_loss: 547.8258\n",
            "Epoch 7925/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 542.3392 - val_loss: 573.9577\n",
            "Epoch 7926/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 539.0156 - val_loss: 575.3488\n",
            "Epoch 7927/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 681.8408 - val_loss: 567.1097\n",
            "Epoch 7928/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 630.7793 - val_loss: 553.9977\n",
            "Epoch 7929/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 568.4435 - val_loss: 602.2007\n",
            "Epoch 7930/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 676.2483 - val_loss: 612.3031\n",
            "Epoch 7931/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 676.0237 - val_loss: 616.3192\n",
            "Epoch 7932/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 626.9128 - val_loss: 586.2983\n",
            "Epoch 7933/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 521.8703 - val_loss: 611.9443\n",
            "Epoch 7934/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 523.8546 - val_loss: 523.8139\n",
            "Epoch 7935/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 613.3833 - val_loss: 530.4105\n",
            "Epoch 7936/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 548.5999 - val_loss: 547.4834\n",
            "Epoch 7937/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 506.0903 - val_loss: 569.9329\n",
            "Epoch 7938/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 572.6247 - val_loss: 536.3495\n",
            "Epoch 7939/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 528.3514 - val_loss: 545.4717\n",
            "Epoch 7940/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 481.9135 - val_loss: 516.5983\n",
            "Epoch 7941/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 533.0842 - val_loss: 547.2784\n",
            "Epoch 7942/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 516.6898 - val_loss: 553.2971\n",
            "Epoch 7943/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 623.9510 - val_loss: 555.1890\n",
            "Epoch 7944/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 529.7261 - val_loss: 516.7076\n",
            "Epoch 7945/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 640.5534 - val_loss: 508.8669\n",
            "Epoch 7946/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 562.1792 - val_loss: 526.5525\n",
            "Epoch 7947/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 462.6722 - val_loss: 606.1609\n",
            "Epoch 7948/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 644.9015 - val_loss: 680.4550\n",
            "Epoch 7949/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 678.9200 - val_loss: 576.7096\n",
            "Epoch 7950/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 588.7984 - val_loss: 582.1317\n",
            "Epoch 7951/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 562.6569 - val_loss: 602.5405\n",
            "Epoch 7952/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 626.6389 - val_loss: 594.1074\n",
            "Epoch 7953/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 614.1360 - val_loss: 540.7300\n",
            "Epoch 7954/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 539.7028 - val_loss: 548.6791\n",
            "Epoch 7955/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 565.9525 - val_loss: 588.5710\n",
            "Epoch 7956/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 588.1093 - val_loss: 558.9308\n",
            "Epoch 7957/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 614.1164 - val_loss: 540.4687\n",
            "Epoch 7958/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 595.2456 - val_loss: 594.8132\n",
            "Epoch 7959/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 687.1130 - val_loss: 580.0366\n",
            "Epoch 7960/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 554.5518 - val_loss: 585.5148\n",
            "Epoch 7961/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 561.3542 - val_loss: 545.5957\n",
            "Epoch 7962/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 494.3251 - val_loss: 506.8278\n",
            "Epoch 7963/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 585.9213 - val_loss: 542.7090\n",
            "Epoch 7964/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 601.9862 - val_loss: 622.3295\n",
            "Epoch 7965/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 571.9815 - val_loss: 542.8847\n",
            "Epoch 7966/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 510.6776 - val_loss: 618.9746\n",
            "Epoch 7967/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 761.1578 - val_loss: 644.8516\n",
            "Epoch 7968/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 645.7732 - val_loss: 706.8100\n",
            "Epoch 7969/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 751.5579 - val_loss: 654.3355\n",
            "Epoch 7970/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 665.2139 - val_loss: 604.9421\n",
            "Epoch 7971/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 657.4478 - val_loss: 649.0066\n",
            "Epoch 7972/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 657.2835 - val_loss: 607.1052\n",
            "Epoch 7973/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 556.8537 - val_loss: 620.7378\n",
            "Epoch 7974/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 699.8087 - val_loss: 629.8971\n",
            "Epoch 7975/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 588.5584 - val_loss: 622.7657\n",
            "Epoch 7976/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 615.7772 - val_loss: 574.6694\n",
            "Epoch 7977/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 612.4185 - val_loss: 557.5538\n",
            "Epoch 7978/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 573.2774 - val_loss: 535.1599\n",
            "Epoch 7979/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 509.4151 - val_loss: 571.5558\n",
            "Epoch 7980/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 639.5513 - val_loss: 557.2048\n",
            "Epoch 7981/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 563.7494 - val_loss: 549.3616\n",
            "Epoch 7982/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 550.9321 - val_loss: 517.8352\n",
            "Epoch 7983/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 631.3575 - val_loss: 603.6079\n",
            "Epoch 7984/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 556.3325 - val_loss: 554.5120\n",
            "Epoch 7985/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 571.5388 - val_loss: 592.1294\n",
            "Epoch 7986/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 478.6330 - val_loss: 547.8847\n",
            "Epoch 7987/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 578.1638 - val_loss: 575.7463\n",
            "Epoch 7988/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 586.4325 - val_loss: 592.9724\n",
            "Epoch 7989/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 546.0183 - val_loss: 595.0798\n",
            "Epoch 7990/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 585.0702 - val_loss: 574.2802\n",
            "Epoch 7991/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 520.1551 - val_loss: 599.2755\n",
            "Epoch 7992/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 648.2468 - val_loss: 589.9919\n",
            "Epoch 7993/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 602.2717 - val_loss: 581.1630\n",
            "Epoch 7994/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 608.5723 - val_loss: 603.1078\n",
            "Epoch 7995/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 560.7285 - val_loss: 626.7776\n",
            "Epoch 7996/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 689.8583 - val_loss: 599.6760\n",
            "Epoch 7997/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 645.9848 - val_loss: 641.6171\n",
            "Epoch 7998/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 728.3921 - val_loss: 583.2451\n",
            "Epoch 7999/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 566.7393 - val_loss: 585.3556\n",
            "Epoch 8000/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 626.8720 - val_loss: 662.8264\n",
            "Epoch 8001/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 704.5605 - val_loss: 631.5813\n",
            "Epoch 8002/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 568.2342 - val_loss: 567.8101\n",
            "Epoch 8003/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 492.6016 - val_loss: 581.7275\n",
            "Epoch 8004/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 501.1834 - val_loss: 550.1482\n",
            "Epoch 8005/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 570.6291 - val_loss: 542.4636\n",
            "Epoch 8006/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 494.3904 - val_loss: 561.4973\n",
            "Epoch 8007/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 576.6339 - val_loss: 547.5317\n",
            "Epoch 8008/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 565.5603 - val_loss: 644.2020\n",
            "Epoch 8009/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 594.3619 - val_loss: 545.0369\n",
            "Epoch 8010/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 557.8446 - val_loss: 548.0502\n",
            "Epoch 8011/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 651.1276 - val_loss: 546.5624\n",
            "Epoch 8012/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 647.7301 - val_loss: 511.5246\n",
            "Epoch 8013/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 473.8828 - val_loss: 523.0454\n",
            "Epoch 8014/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 571.5826 - val_loss: 518.6584\n",
            "Epoch 8015/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 507.1339 - val_loss: 503.6360\n",
            "Epoch 8016/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 591.3847 - val_loss: 516.8124\n",
            "Epoch 8017/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 572.3580 - val_loss: 505.1031\n",
            "Epoch 8018/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 538.1481 - val_loss: 571.0914\n",
            "Epoch 8019/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 571.7016 - val_loss: 533.5887\n",
            "Epoch 8020/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 482.4183 - val_loss: 557.6323\n",
            "Epoch 8021/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 551.9108 - val_loss: 542.0554\n",
            "Epoch 8022/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 521.4349 - val_loss: 528.0605\n",
            "Epoch 8023/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 537.6328 - val_loss: 511.9217\n",
            "Epoch 8024/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 529.4356 - val_loss: 523.7615\n",
            "Epoch 8025/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 491.0947 - val_loss: 526.4290\n",
            "Epoch 8026/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 513.7720 - val_loss: 505.9571\n",
            "Epoch 8027/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 465.7694 - val_loss: 528.5340\n",
            "Epoch 8028/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 463.6963 - val_loss: 543.6781\n",
            "Epoch 8029/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 555.1531 - val_loss: 478.9512\n",
            "Epoch 8030/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 449.2351 - val_loss: 558.5209\n",
            "Epoch 8031/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 581.7844 - val_loss: 521.0403\n",
            "Epoch 8032/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 566.7528 - val_loss: 527.7847\n",
            "Epoch 8033/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 627.5209 - val_loss: 560.0739\n",
            "Epoch 8034/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 559.1014 - val_loss: 595.1555\n",
            "Epoch 8035/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 599.0403 - val_loss: 611.0151\n",
            "Epoch 8036/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 634.4819 - val_loss: 569.9238\n",
            "Epoch 8037/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 632.3151 - val_loss: 584.8953\n",
            "Epoch 8038/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 526.6761 - val_loss: 523.0677\n",
            "Epoch 8039/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 598.5761 - val_loss: 588.8421\n",
            "Epoch 8040/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 575.3882 - val_loss: 573.3543\n",
            "Epoch 8041/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 543.4615 - val_loss: 592.6931\n",
            "Epoch 8042/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 563.1686 - val_loss: 640.6189\n",
            "Epoch 8043/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 677.6291 - val_loss: 629.5172\n",
            "Epoch 8044/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 549.7679 - val_loss: 562.6005\n",
            "Epoch 8045/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 578.4831 - val_loss: 544.7734\n",
            "Epoch 8046/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 591.1939 - val_loss: 510.7331\n",
            "Epoch 8047/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 513.2550 - val_loss: 627.4160\n",
            "Epoch 8048/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 546.7180 - val_loss: 561.1984\n",
            "Epoch 8049/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 501.1555 - val_loss: 592.0232\n",
            "Epoch 8050/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 643.5455 - val_loss: 550.0461\n",
            "Epoch 8051/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 641.2035 - val_loss: 594.4822\n",
            "Epoch 8052/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 615.1534 - val_loss: 577.8021\n",
            "Epoch 8053/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 558.8058 - val_loss: 540.5296\n",
            "Epoch 8054/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 562.3846 - val_loss: 545.3007\n",
            "Epoch 8055/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 557.7653 - val_loss: 565.8610\n",
            "Epoch 8056/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 563.8970 - val_loss: 533.6562\n",
            "Epoch 8057/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 547.5516 - val_loss: 535.3792\n",
            "Epoch 8058/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 556.5088 - val_loss: 527.5640\n",
            "Epoch 8059/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 532.2111 - val_loss: 653.7166\n",
            "Epoch 8060/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 580.1508 - val_loss: 530.1784\n",
            "Epoch 8061/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 514.4974 - val_loss: 515.5901\n",
            "Epoch 8062/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 485.5947 - val_loss: 535.7184\n",
            "Epoch 8063/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 570.5968 - val_loss: 632.1322\n",
            "Epoch 8064/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 666.4895 - val_loss: 579.1934\n",
            "Epoch 8065/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 562.0556 - val_loss: 583.2706\n",
            "Epoch 8066/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 620.2803 - val_loss: 542.4598\n",
            "Epoch 8067/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 522.8194 - val_loss: 504.4547\n",
            "Epoch 8068/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 602.0537 - val_loss: 572.7087\n",
            "Epoch 8069/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 514.0671 - val_loss: 522.5656\n",
            "Epoch 8070/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 532.2485 - val_loss: 502.2319\n",
            "Epoch 8071/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 499.9420 - val_loss: 563.9678\n",
            "Epoch 8072/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 542.9587 - val_loss: 516.9880\n",
            "Epoch 8073/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 541.5506 - val_loss: 528.4366\n",
            "Epoch 8074/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 588.7522 - val_loss: 590.1151\n",
            "Epoch 8075/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 519.9761 - val_loss: 512.9517\n",
            "Epoch 8076/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 543.0705 - val_loss: 681.3807\n",
            "Epoch 8077/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 608.5061 - val_loss: 538.4642\n",
            "Epoch 8078/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 564.3017 - val_loss: 522.5795\n",
            "Epoch 8079/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 543.7918 - val_loss: 582.4289\n",
            "Epoch 8080/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 487.2991 - val_loss: 581.6115\n",
            "Epoch 8081/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 569.6067 - val_loss: 531.1390\n",
            "Epoch 8082/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 465.8002 - val_loss: 509.0689\n",
            "Epoch 8083/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 537.4430 - val_loss: 525.4190\n",
            "Epoch 8084/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 611.2422 - val_loss: 510.2755\n",
            "Epoch 8085/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 538.3828 - val_loss: 499.4055\n",
            "Epoch 8086/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 555.5688 - val_loss: 561.8911\n",
            "Epoch 8087/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 584.0754 - val_loss: 508.4801\n",
            "Epoch 8088/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 594.3444 - val_loss: 505.3467\n",
            "Epoch 8089/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 539.7805 - val_loss: 506.4934\n",
            "Epoch 8090/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 552.2437 - val_loss: 587.8085\n",
            "Epoch 8091/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 544.2209 - val_loss: 522.1677\n",
            "Epoch 8092/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 458.7203 - val_loss: 537.7167\n",
            "Epoch 8093/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 543.6284 - val_loss: 525.0998\n",
            "Epoch 8094/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 408.9153 - val_loss: 534.7087\n",
            "Epoch 8095/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 504.5191 - val_loss: 512.6462\n",
            "Epoch 8096/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 539.4210 - val_loss: 470.2968\n",
            "Epoch 8097/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 531.1721 - val_loss: 497.9780\n",
            "Epoch 8098/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 489.6685 - val_loss: 511.6735\n",
            "Epoch 8099/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 648.2462 - val_loss: 538.9921\n",
            "Epoch 8100/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 521.1648 - val_loss: 620.3365\n",
            "Epoch 8101/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 470.8214 - val_loss: 475.4381\n",
            "Epoch 8102/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 468.7726 - val_loss: 550.2892\n",
            "Epoch 8103/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 441.2382 - val_loss: 488.4650\n",
            "Epoch 8104/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 549.9383 - val_loss: 541.2952\n",
            "Epoch 8105/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 489.0610 - val_loss: 478.0443\n",
            "Epoch 8106/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 498.9062 - val_loss: 512.9760\n",
            "Epoch 8107/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 411.1568 - val_loss: 484.0867\n",
            "Epoch 8108/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 510.7319 - val_loss: 517.7917\n",
            "Epoch 8109/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 555.1443 - val_loss: 525.2933\n",
            "Epoch 8110/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 546.7410 - val_loss: 533.9985\n",
            "Epoch 8111/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 552.5364 - val_loss: 517.4335\n",
            "Epoch 8112/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 474.6476 - val_loss: 518.0289\n",
            "Epoch 8113/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 494.8956 - val_loss: 472.8031\n",
            "Epoch 8114/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 435.7440 - val_loss: 476.8290\n",
            "Epoch 8115/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 482.2823 - val_loss: 489.1129\n",
            "Epoch 8116/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 571.0056 - val_loss: 468.4437\n",
            "Epoch 8117/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 506.2855 - val_loss: 444.9611\n",
            "Epoch 8118/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 519.0931 - val_loss: 487.3481\n",
            "Epoch 8119/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 453.9857 - val_loss: 664.1741\n",
            "Epoch 8120/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 536.0039 - val_loss: 475.1138\n",
            "Epoch 8121/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 649.9850 - val_loss: 505.0143\n",
            "Epoch 8122/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 502.9786 - val_loss: 560.5500\n",
            "Epoch 8123/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 474.7266 - val_loss: 566.1674\n",
            "Epoch 8124/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 535.1646 - val_loss: 463.0535\n",
            "Epoch 8125/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 565.6355 - val_loss: 591.3115\n",
            "Epoch 8126/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 462.7209 - val_loss: 485.3282\n",
            "Epoch 8127/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 512.3606 - val_loss: 512.7406\n",
            "Epoch 8128/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 585.7861 - val_loss: 510.5622\n",
            "Epoch 8129/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 510.1197 - val_loss: 499.4018\n",
            "Epoch 8130/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 539.7635 - val_loss: 545.0656\n",
            "Epoch 8131/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 579.2744 - val_loss: 496.3555\n",
            "Epoch 8132/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 422.2670 - val_loss: 475.2607\n",
            "Epoch 8133/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 444.0825 - val_loss: 497.0107\n",
            "Epoch 8134/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 510.1532 - val_loss: 501.6276\n",
            "Epoch 8135/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 492.3823 - val_loss: 469.0051\n",
            "Epoch 8136/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 512.7066 - val_loss: 483.4864\n",
            "Epoch 8137/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 451.3019 - val_loss: 477.4893\n",
            "Epoch 8138/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 461.0493 - val_loss: 506.4257\n",
            "Epoch 8139/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 515.6585 - val_loss: 460.9555\n",
            "Epoch 8140/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 446.8872 - val_loss: 620.7689\n",
            "Epoch 8141/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 649.8563 - val_loss: 534.6171\n",
            "Epoch 8142/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 529.2215 - val_loss: 492.5505\n",
            "Epoch 8143/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 568.8316 - val_loss: 500.2212\n",
            "Epoch 8144/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 494.9110 - val_loss: 465.5057\n",
            "Epoch 8145/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 518.3351 - val_loss: 464.1718\n",
            "Epoch 8146/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 438.1845 - val_loss: 468.6556\n",
            "Epoch 8147/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 503.6751 - val_loss: 477.7372\n",
            "Epoch 8148/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 455.9813 - val_loss: 462.3934\n",
            "Epoch 8149/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 464.1413 - val_loss: 500.5851\n",
            "Epoch 8150/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 560.1128 - val_loss: 477.3711\n",
            "Epoch 8151/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 466.7887 - val_loss: 478.6373\n",
            "Epoch 8152/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 521.2409 - val_loss: 530.4842\n",
            "Epoch 8153/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 539.2536 - val_loss: 523.9622\n",
            "Epoch 8154/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 596.1329 - val_loss: 504.8654\n",
            "Epoch 8155/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 534.9656 - val_loss: 507.7992\n",
            "Epoch 8156/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 499.4580 - val_loss: 558.5568\n",
            "Epoch 8157/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 601.6651 - val_loss: 516.3817\n",
            "Epoch 8158/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 545.8806 - val_loss: 519.1646\n",
            "Epoch 8159/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 478.9833 - val_loss: 503.5916\n",
            "Epoch 8160/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 529.5972 - val_loss: 481.2686\n",
            "Epoch 8161/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 573.3352 - val_loss: 512.8769\n",
            "Epoch 8162/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 539.2235 - val_loss: 525.0858\n",
            "Epoch 8163/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 485.1903 - val_loss: 557.4946\n",
            "Epoch 8164/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 518.7941 - val_loss: 540.0204\n",
            "Epoch 8165/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 582.9022 - val_loss: 548.6071\n",
            "Epoch 8166/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 607.0550 - val_loss: 591.6962\n",
            "Epoch 8167/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 547.7609 - val_loss: 515.2900\n",
            "Epoch 8168/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 583.0408 - val_loss: 550.1083\n",
            "Epoch 8169/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 569.0031 - val_loss: 527.2186\n",
            "Epoch 8170/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 509.5422 - val_loss: 597.7462\n",
            "Epoch 8171/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 530.8605 - val_loss: 493.8776\n",
            "Epoch 8172/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 467.3883 - val_loss: 488.0952\n",
            "Epoch 8173/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 582.3991 - val_loss: 489.4898\n",
            "Epoch 8174/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 478.5614 - val_loss: 493.5102\n",
            "Epoch 8175/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 482.8166 - val_loss: 482.9302\n",
            "Epoch 8176/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 483.8152 - val_loss: 531.8927\n",
            "Epoch 8177/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 458.5239 - val_loss: 526.4122\n",
            "Epoch 8178/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 533.2315 - val_loss: 560.1047\n",
            "Epoch 8179/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 514.9998 - val_loss: 466.4565\n",
            "Epoch 8180/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 457.8282 - val_loss: 573.4605\n",
            "Epoch 8181/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 554.7713 - val_loss: 571.9979\n",
            "Epoch 8182/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 573.5534 - val_loss: 577.0591\n",
            "Epoch 8183/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 558.0541 - val_loss: 533.2499\n",
            "Epoch 8184/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 645.4388 - val_loss: 517.1942\n",
            "Epoch 8185/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 512.9101 - val_loss: 519.6168\n",
            "Epoch 8186/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 548.3689 - val_loss: 507.6942\n",
            "Epoch 8187/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 512.7313 - val_loss: 505.2412\n",
            "Epoch 8188/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 514.1763 - val_loss: 480.9885\n",
            "Epoch 8189/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 521.3098 - val_loss: 572.2000\n",
            "Epoch 8190/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 643.2056 - val_loss: 541.7491\n",
            "Epoch 8191/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 570.4070 - val_loss: 513.5246\n",
            "Epoch 8192/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 568.7900 - val_loss: 527.1452\n",
            "Epoch 8193/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 514.1360 - val_loss: 558.8806\n",
            "Epoch 8194/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 561.5447 - val_loss: 576.5011\n",
            "Epoch 8195/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 518.6857 - val_loss: 540.4667\n",
            "Epoch 8196/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 633.3403 - val_loss: 573.0315\n",
            "Epoch 8197/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 616.5826 - val_loss: 543.4313\n",
            "Epoch 8198/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 593.3883 - val_loss: 535.2279\n",
            "Epoch 8199/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 524.1926 - val_loss: 573.8382\n",
            "Epoch 8200/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 603.9563 - val_loss: 524.5584\n",
            "Epoch 8201/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 495.6861 - val_loss: 625.0973\n",
            "Epoch 8202/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 731.6710 - val_loss: 598.0607\n",
            "Epoch 8203/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 691.6488 - val_loss: 577.1625\n",
            "Epoch 8204/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 593.7088 - val_loss: 529.1011\n",
            "Epoch 8205/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 482.2005 - val_loss: 615.7638\n",
            "Epoch 8206/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 616.8544 - val_loss: 544.3103\n",
            "Epoch 8207/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 532.5672 - val_loss: 559.7424\n",
            "Epoch 8208/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 679.3924 - val_loss: 561.2362\n",
            "Epoch 8209/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 598.7094 - val_loss: 562.9398\n",
            "Epoch 8210/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 597.1015 - val_loss: 549.0071\n",
            "Epoch 8211/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 567.4935 - val_loss: 606.8548\n",
            "Epoch 8212/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 509.9477 - val_loss: 526.1075\n",
            "Epoch 8213/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 593.7536 - val_loss: 665.2233\n",
            "Epoch 8214/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 583.4788 - val_loss: 588.7654\n",
            "Epoch 8215/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 597.1347 - val_loss: 534.7267\n",
            "Epoch 8216/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 585.7754 - val_loss: 568.8330\n",
            "Epoch 8217/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 554.1877 - val_loss: 634.9471\n",
            "Epoch 8218/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 581.1990 - val_loss: 516.4801\n",
            "Epoch 8219/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 533.6440 - val_loss: 520.7878\n",
            "Epoch 8220/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 513.4470 - val_loss: 600.7005\n",
            "Epoch 8221/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 652.2720 - val_loss: 694.1608\n",
            "Epoch 8222/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 719.2225 - val_loss: 662.1761\n",
            "Epoch 8223/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 617.9715 - val_loss: 640.2155\n",
            "Epoch 8224/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 631.9704 - val_loss: 723.2098\n",
            "Epoch 8225/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 614.3308 - val_loss: 603.8601\n",
            "Epoch 8226/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 709.7631 - val_loss: 642.2083\n",
            "Epoch 8227/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 611.2993 - val_loss: 672.8171\n",
            "Epoch 8228/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 692.0937 - val_loss: 680.4862\n",
            "Epoch 8229/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 689.0288 - val_loss: 667.9473\n",
            "Epoch 8230/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 642.6008 - val_loss: 640.2214\n",
            "Epoch 8231/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 607.6905 - val_loss: 634.1646\n",
            "Epoch 8232/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 648.1202 - val_loss: 629.2220\n",
            "Epoch 8233/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 642.0421 - val_loss: 650.1636\n",
            "Epoch 8234/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 802.2189 - val_loss: 679.1021\n",
            "Epoch 8235/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 633.4768 - val_loss: 674.4539\n",
            "Epoch 8236/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 661.2156 - val_loss: 649.1848\n",
            "Epoch 8237/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 609.0464 - val_loss: 591.6313\n",
            "Epoch 8238/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 618.2427 - val_loss: 576.0001\n",
            "Epoch 8239/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 656.2115 - val_loss: 645.3333\n",
            "Epoch 8240/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 848.9949 - val_loss: 830.5395\n",
            "Epoch 8241/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 788.7148 - val_loss: 770.9405\n",
            "Epoch 8242/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 828.6580 - val_loss: 895.7824\n",
            "Epoch 8243/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 934.2991 - val_loss: 828.2253\n",
            "Epoch 8244/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 921.5177 - val_loss: 845.9398\n",
            "Epoch 8245/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 824.2098 - val_loss: 807.5760\n",
            "Epoch 8246/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 733.2604 - val_loss: 676.6281\n",
            "Epoch 8247/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 654.8417 - val_loss: 695.1316\n",
            "Epoch 8248/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 666.2640 - val_loss: 660.6318\n",
            "Epoch 8249/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 647.3733 - val_loss: 625.8920\n",
            "Epoch 8250/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 714.2295 - val_loss: 608.6219\n",
            "Epoch 8251/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 675.0215 - val_loss: 770.4783\n",
            "Epoch 8252/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 817.6890 - val_loss: 635.8795\n",
            "Epoch 8253/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 560.6761 - val_loss: 620.2321\n",
            "Epoch 8254/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 675.6195 - val_loss: 639.1727\n",
            "Epoch 8255/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 596.6709 - val_loss: 657.7251\n",
            "Epoch 8256/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 679.7219 - val_loss: 643.8336\n",
            "Epoch 8257/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 651.6229 - val_loss: 696.3906\n",
            "Epoch 8258/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 681.7567 - val_loss: 724.3354\n",
            "Epoch 8259/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 630.3763 - val_loss: 666.1418\n",
            "Epoch 8260/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 760.3458 - val_loss: 652.0137\n",
            "Epoch 8261/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 675.1324 - val_loss: 696.9565\n",
            "Epoch 8262/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 688.3965 - val_loss: 614.0938\n",
            "Epoch 8263/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 700.7144 - val_loss: 672.8419\n",
            "Epoch 8264/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 666.9528 - val_loss: 650.5458\n",
            "Epoch 8265/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 625.2284 - val_loss: 644.7474\n",
            "Epoch 8266/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 644.5272 - val_loss: 626.8138\n",
            "Epoch 8267/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 602.0847 - val_loss: 637.7020\n",
            "Epoch 8268/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 586.4642 - val_loss: 650.2639\n",
            "Epoch 8269/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 566.1424 - val_loss: 698.4379\n",
            "Epoch 8270/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 665.5967 - val_loss: 637.1080\n",
            "Epoch 8271/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 606.7479 - val_loss: 619.7229\n",
            "Epoch 8272/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 726.2233 - val_loss: 711.5622\n",
            "Epoch 8273/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 705.2598 - val_loss: 708.3593\n",
            "Epoch 8274/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 729.7670 - val_loss: 575.6384\n",
            "Epoch 8275/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 592.1132 - val_loss: 573.5928\n",
            "Epoch 8276/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 590.0667 - val_loss: 642.2819\n",
            "Epoch 8277/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 609.6102 - val_loss: 789.0607\n",
            "Epoch 8278/10000\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 853.1725 - val_loss: 625.0233\n",
            "Epoch 8279/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 657.7259 - val_loss: 575.2552\n",
            "Epoch 8280/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 611.8767 - val_loss: 719.2994\n",
            "Epoch 8281/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 601.2219 - val_loss: 632.1003\n",
            "Epoch 8282/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 719.9776 - val_loss: 714.7595\n",
            "Epoch 8283/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 824.9322 - val_loss: 730.8677\n",
            "Epoch 8284/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 768.3223 - val_loss: 685.2881\n",
            "Epoch 8285/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 674.4861 - val_loss: 626.3103\n",
            "Epoch 8286/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 660.3263 - val_loss: 592.2832\n",
            "Epoch 8287/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 647.2030 - val_loss: 544.5391\n",
            "Epoch 8288/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 579.1546 - val_loss: 630.9485\n",
            "Epoch 8289/10000\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 614.5856 - val_loss: 631.9055\n",
            "Epoch 8290/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 587.7508 - val_loss: 593.0427\n",
            "Epoch 8291/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 631.2225 - val_loss: 617.0942\n",
            "Epoch 8292/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 585.8024 - val_loss: 594.7314\n",
            "Epoch 8293/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 581.3463 - val_loss: 521.3127\n",
            "Epoch 8294/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 599.0198 - val_loss: 626.6575\n",
            "Epoch 8295/10000\n",
            "12/12 [==============================] - 1s 77ms/step - loss: 598.4183 - val_loss: 635.6591\n",
            "Epoch 8296/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 645.3210 - val_loss: 627.5165\n",
            "Epoch 8297/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 613.2815 - val_loss: 583.6960\n",
            "Epoch 8298/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 567.7109 - val_loss: 545.1017\n",
            "Epoch 8299/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 636.5447 - val_loss: 525.6053\n",
            "Epoch 8300/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 608.0695 - val_loss: 709.1885\n",
            "Epoch 8301/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 726.9967 - val_loss: 621.2547\n",
            "Epoch 8302/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 611.6308 - val_loss: 509.8825\n",
            "Epoch 8303/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 521.3162 - val_loss: 595.8701\n",
            "Epoch 8304/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 568.5981 - val_loss: 564.5413\n",
            "Epoch 8305/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 492.4165 - val_loss: 642.3257\n",
            "Epoch 8306/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 606.3497 - val_loss: 634.4825\n",
            "Epoch 8307/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 582.7418 - val_loss: 521.4572\n",
            "Epoch 8308/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 522.6506 - val_loss: 477.6649\n",
            "Epoch 8309/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 492.0669 - val_loss: 487.0878\n",
            "Epoch 8310/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 516.5311 - val_loss: 592.9548\n",
            "Epoch 8311/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 583.3830 - val_loss: 540.1475\n",
            "Epoch 8312/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 594.5165 - val_loss: 603.2892\n",
            "Epoch 8313/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 537.0661 - val_loss: 556.3187\n",
            "Epoch 8314/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 618.5059 - val_loss: 541.1729\n",
            "Epoch 8315/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 516.1531 - val_loss: 523.0135\n",
            "Epoch 8316/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 524.0423 - val_loss: 493.4182\n",
            "Epoch 8317/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 543.0467 - val_loss: 522.0026\n",
            "Epoch 8318/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 534.5119 - val_loss: 563.4453\n",
            "Epoch 8319/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 567.9163 - val_loss: 636.4111\n",
            "Epoch 8320/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 731.0902 - val_loss: 583.8680\n",
            "Epoch 8321/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 648.0672 - val_loss: 603.2094\n",
            "Epoch 8322/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 675.2503 - val_loss: 644.9923\n",
            "Epoch 8323/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 549.2035 - val_loss: 631.6473\n",
            "Epoch 8324/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 614.5372 - val_loss: 621.5926\n",
            "Epoch 8325/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 570.5474 - val_loss: 566.4662\n",
            "Epoch 8326/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 611.6765 - val_loss: 614.6684\n",
            "Epoch 8327/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 582.0496 - val_loss: 655.4492\n",
            "Epoch 8328/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 640.7809 - val_loss: 601.9453\n",
            "Epoch 8329/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 577.7090 - val_loss: 533.5560\n",
            "Epoch 8330/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 545.1100 - val_loss: 538.2509\n",
            "Epoch 8331/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 530.8058 - val_loss: 515.6901\n",
            "Epoch 8332/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 560.3384 - val_loss: 529.5945\n",
            "Epoch 8333/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 517.3345 - val_loss: 591.3240\n",
            "Epoch 8334/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 630.0863 - val_loss: 562.9825\n",
            "Epoch 8335/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 599.1643 - val_loss: 563.1708\n",
            "Epoch 8336/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 501.1384 - val_loss: 558.8062\n",
            "Epoch 8337/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 561.7897 - val_loss: 538.8290\n",
            "Epoch 8338/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 491.4649 - val_loss: 571.2173\n",
            "Epoch 8339/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 589.8140 - val_loss: 530.5231\n",
            "Epoch 8340/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 569.6577 - val_loss: 658.7165\n",
            "Epoch 8341/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 857.9304 - val_loss: 657.3415\n",
            "Epoch 8342/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 704.5562 - val_loss: 726.6309\n",
            "Epoch 8343/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 669.5296 - val_loss: 718.6852\n",
            "Epoch 8344/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 644.3456 - val_loss: 726.9899\n",
            "Epoch 8345/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 719.9050 - val_loss: 631.5200\n",
            "Epoch 8346/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 622.7890 - val_loss: 685.5423\n",
            "Epoch 8347/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 674.5640 - val_loss: 569.9389\n",
            "Epoch 8348/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 675.8435 - val_loss: 506.1611\n",
            "Epoch 8349/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 471.1944 - val_loss: 560.4243\n",
            "Epoch 8350/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 612.8569 - val_loss: 591.0660\n",
            "Epoch 8351/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 518.5801 - val_loss: 545.7640\n",
            "Epoch 8352/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 605.5706 - val_loss: 552.2123\n",
            "Epoch 8353/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 523.9220 - val_loss: 583.6070\n",
            "Epoch 8354/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 533.9018 - val_loss: 570.3268\n",
            "Epoch 8355/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 583.7050 - val_loss: 606.1885\n",
            "Epoch 8356/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 686.9026 - val_loss: 659.2391\n",
            "Epoch 8357/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 599.5348 - val_loss: 652.4018\n",
            "Epoch 8358/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 677.4947 - val_loss: 620.3351\n",
            "Epoch 8359/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 703.5633 - val_loss: 574.5008\n",
            "Epoch 8360/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 553.3396 - val_loss: 596.3094\n",
            "Epoch 8361/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 609.4116 - val_loss: 624.1057\n",
            "Epoch 8362/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 624.1767 - val_loss: 626.3485\n",
            "Epoch 8363/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 666.8329 - val_loss: 657.3803\n",
            "Epoch 8364/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 645.1677 - val_loss: 603.3889\n",
            "Epoch 8365/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 540.8789 - val_loss: 595.2205\n",
            "Epoch 8366/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 540.8522 - val_loss: 546.0937\n",
            "Epoch 8367/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 550.4629 - val_loss: 631.5339\n",
            "Epoch 8368/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 630.4868 - val_loss: 715.7643\n",
            "Epoch 8369/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 695.2705 - val_loss: 673.6696\n",
            "Epoch 8370/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 681.2005 - val_loss: 691.1027\n",
            "Epoch 8371/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 691.2124 - val_loss: 647.6248\n",
            "Epoch 8372/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 646.0829 - val_loss: 648.9354\n",
            "Epoch 8373/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 584.9987 - val_loss: 620.7715\n",
            "Epoch 8374/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 627.2198 - val_loss: 624.6653\n",
            "Epoch 8375/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 538.0915 - val_loss: 619.1732\n",
            "Epoch 8376/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 579.5198 - val_loss: 626.6954\n",
            "Epoch 8377/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 658.4004 - val_loss: 566.0724\n",
            "Epoch 8378/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 590.5946 - val_loss: 575.5867\n",
            "Epoch 8379/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 604.1676 - val_loss: 566.4479\n",
            "Epoch 8380/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 567.8101 - val_loss: 555.1691\n",
            "Epoch 8381/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 627.2492 - val_loss: 534.1052\n",
            "Epoch 8382/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 502.9644 - val_loss: 564.2955\n",
            "Epoch 8383/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 545.0426 - val_loss: 537.7401\n",
            "Epoch 8384/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 523.9401 - val_loss: 567.2461\n",
            "Epoch 8385/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 508.7512 - val_loss: 514.9692\n",
            "Epoch 8386/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 490.1137 - val_loss: 541.4527\n",
            "Epoch 8387/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 556.3567 - val_loss: 521.4441\n",
            "Epoch 8388/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 497.8309 - val_loss: 561.6725\n",
            "Epoch 8389/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 502.0688 - val_loss: 534.8088\n",
            "Epoch 8390/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 481.1880 - val_loss: 500.0428\n",
            "Epoch 8391/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 495.5511 - val_loss: 525.5333\n",
            "Epoch 8392/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 558.4887 - val_loss: 547.7728\n",
            "Epoch 8393/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 676.7586 - val_loss: 497.9423\n",
            "Epoch 8394/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 511.9555 - val_loss: 548.3741\n",
            "Epoch 8395/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 464.1565 - val_loss: 590.3196\n",
            "Epoch 8396/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 540.4745 - val_loss: 485.8288\n",
            "Epoch 8397/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 497.1331 - val_loss: 547.9309\n",
            "Epoch 8398/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 497.3572 - val_loss: 533.9249\n",
            "Epoch 8399/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 577.9495 - val_loss: 566.4513\n",
            "Epoch 8400/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 566.1754 - val_loss: 498.0002\n",
            "Epoch 8401/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 517.8720 - val_loss: 573.7350\n",
            "Epoch 8402/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 533.6557 - val_loss: 552.7757\n",
            "Epoch 8403/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 552.8259 - val_loss: 610.3066\n",
            "Epoch 8404/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 650.2303 - val_loss: 512.4121\n",
            "Epoch 8405/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 537.8603 - val_loss: 475.4680\n",
            "Epoch 8406/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 567.0453 - val_loss: 487.1889\n",
            "Epoch 8407/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 515.5138 - val_loss: 474.8587\n",
            "Epoch 8408/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 489.3343 - val_loss: 474.0700\n",
            "Epoch 8409/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 485.4226 - val_loss: 482.5406\n",
            "Epoch 8410/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 524.0830 - val_loss: 596.0457\n",
            "Epoch 8411/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 476.7719 - val_loss: 497.9690\n",
            "Epoch 8412/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 505.4646 - val_loss: 459.8864\n",
            "Epoch 8413/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 463.7988 - val_loss: 504.8679\n",
            "Epoch 8414/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 536.6075 - val_loss: 524.4124\n",
            "Epoch 8415/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 554.0634 - val_loss: 522.2645\n",
            "Epoch 8416/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 513.1983 - val_loss: 588.2814\n",
            "Epoch 8417/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 564.3062 - val_loss: 487.7088\n",
            "Epoch 8418/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 550.5995 - val_loss: 482.2582\n",
            "Epoch 8419/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 502.8624 - val_loss: 509.4333\n",
            "Epoch 8420/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 515.8652 - val_loss: 505.0676\n",
            "Epoch 8421/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 516.7290 - val_loss: 535.1790\n",
            "Epoch 8422/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 606.8265 - val_loss: 500.7028\n",
            "Epoch 8423/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 482.3760 - val_loss: 532.1123\n",
            "Epoch 8424/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 550.1101 - val_loss: 533.2375\n",
            "Epoch 8425/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 535.2643 - val_loss: 494.9874\n",
            "Epoch 8426/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 548.9598 - val_loss: 491.8002\n",
            "Epoch 8427/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 605.1633 - val_loss: 544.1548\n",
            "Epoch 8428/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 558.1587 - val_loss: 560.0444\n",
            "Epoch 8429/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 542.0757 - val_loss: 528.6431\n",
            "Epoch 8430/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 435.5077 - val_loss: 493.6815\n",
            "Epoch 8431/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 546.8084 - val_loss: 471.4530\n",
            "Epoch 8432/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 552.7043 - val_loss: 547.6533\n",
            "Epoch 8433/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 555.2877 - val_loss: 503.6506\n",
            "Epoch 8434/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 495.3554 - val_loss: 542.6833\n",
            "Epoch 8435/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 562.6858 - val_loss: 442.8886\n",
            "Epoch 8436/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 442.8359 - val_loss: 470.3140\n",
            "Epoch 8437/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 424.9617 - val_loss: 450.8953\n",
            "Epoch 8438/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 414.0788 - val_loss: 478.9913\n",
            "Epoch 8439/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 441.0720 - val_loss: 510.0576\n",
            "Epoch 8440/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 418.0468 - val_loss: 473.6266\n",
            "Epoch 8441/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 503.6827 - val_loss: 482.6388\n",
            "Epoch 8442/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 483.7061 - val_loss: 488.3531\n",
            "Epoch 8443/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 475.6017 - val_loss: 472.9803\n",
            "Epoch 8444/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 514.5541 - val_loss: 471.1176\n",
            "Epoch 8445/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 475.6639 - val_loss: 440.0615\n",
            "Epoch 8446/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 460.2445 - val_loss: 443.6656\n",
            "Epoch 8447/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 461.8520 - val_loss: 447.1801\n",
            "Epoch 8448/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 399.4032 - val_loss: 472.4695\n",
            "Epoch 8449/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 475.7013 - val_loss: 556.5413\n",
            "Epoch 8450/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 487.4368 - val_loss: 538.2853\n",
            "Epoch 8451/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 546.5353 - val_loss: 475.8578\n",
            "Epoch 8452/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 472.1193 - val_loss: 496.9341\n",
            "Epoch 8453/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 469.1061 - val_loss: 507.4801\n",
            "Epoch 8454/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 503.4108 - val_loss: 641.9068\n",
            "Epoch 8455/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 522.0486 - val_loss: 477.8387\n",
            "Epoch 8456/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 540.4029 - val_loss: 479.4811\n",
            "Epoch 8457/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 468.4130 - val_loss: 442.5424\n",
            "Epoch 8458/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 503.7081 - val_loss: 467.2526\n",
            "Epoch 8459/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 468.1033 - val_loss: 460.0623\n",
            "Epoch 8460/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 456.2909 - val_loss: 477.9550\n",
            "Epoch 8461/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 476.3199 - val_loss: 513.7996\n",
            "Epoch 8462/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 524.0742 - val_loss: 439.3903\n",
            "Epoch 8463/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 535.4177 - val_loss: 466.0659\n",
            "Epoch 8464/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 445.2694 - val_loss: 456.9689\n",
            "Epoch 8465/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 460.4954 - val_loss: 485.2700\n",
            "Epoch 8466/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 434.7126 - val_loss: 438.8802\n",
            "Epoch 8467/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 455.1187 - val_loss: 432.0197\n",
            "Epoch 8468/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 450.5273 - val_loss: 512.8265\n",
            "Epoch 8469/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 571.2983 - val_loss: 478.2350\n",
            "Epoch 8470/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 532.7925 - val_loss: 498.1143\n",
            "Epoch 8471/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 435.0188 - val_loss: 457.9839\n",
            "Epoch 8472/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 493.8546 - val_loss: 471.6012\n",
            "Epoch 8473/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 478.4990 - val_loss: 443.6326\n",
            "Epoch 8474/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 456.5225 - val_loss: 425.1653\n",
            "Epoch 8475/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 443.4110 - val_loss: 447.6625\n",
            "Epoch 8476/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 403.0641 - val_loss: 438.0038\n",
            "Epoch 8477/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 460.7434 - val_loss: 433.0612\n",
            "Epoch 8478/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 444.9043 - val_loss: 484.1943\n",
            "Epoch 8479/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 476.2246 - val_loss: 446.3197\n",
            "Epoch 8480/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 436.5040 - val_loss: 483.1295\n",
            "Epoch 8481/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 407.7841 - val_loss: 465.1991\n",
            "Epoch 8482/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 481.7507 - val_loss: 432.3744\n",
            "Epoch 8483/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 427.9608 - val_loss: 457.3288\n",
            "Epoch 8484/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 416.5232 - val_loss: 511.4156\n",
            "Epoch 8485/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 498.4554 - val_loss: 497.8115\n",
            "Epoch 8486/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 473.9951 - val_loss: 494.6379\n",
            "Epoch 8487/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 514.5191 - val_loss: 467.4870\n",
            "Epoch 8488/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 524.7293 - val_loss: 496.1377\n",
            "Epoch 8489/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 492.3025 - val_loss: 476.5101\n",
            "Epoch 8490/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 511.8318 - val_loss: 484.5578\n",
            "Epoch 8491/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 445.0981 - val_loss: 532.9653\n",
            "Epoch 8492/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 567.4683 - val_loss: 666.8447\n",
            "Epoch 8493/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 561.6637 - val_loss: 528.6688\n",
            "Epoch 8494/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 490.5839 - val_loss: 450.4504\n",
            "Epoch 8495/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 484.6627 - val_loss: 477.8674\n",
            "Epoch 8496/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 454.4848 - val_loss: 431.2969\n",
            "Epoch 8497/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 446.2121 - val_loss: 433.8323\n",
            "Epoch 8498/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 433.2820 - val_loss: 499.9560\n",
            "Epoch 8499/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 521.4415 - val_loss: 460.8394\n",
            "Epoch 8500/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 502.6698 - val_loss: 471.6075\n",
            "Epoch 8501/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 528.5238 - val_loss: 508.9409\n",
            "Epoch 8502/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 533.7241 - val_loss: 507.7179\n",
            "Epoch 8503/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 471.2493 - val_loss: 637.9164\n",
            "Epoch 8504/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 686.8517 - val_loss: 718.7664\n",
            "Epoch 8505/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 727.6821 - val_loss: 580.1954\n",
            "Epoch 8506/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 587.3778 - val_loss: 591.2143\n",
            "Epoch 8507/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 583.2851 - val_loss: 509.3862\n",
            "Epoch 8508/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 587.6630 - val_loss: 652.3615\n",
            "Epoch 8509/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 638.2202 - val_loss: 741.2050\n",
            "Epoch 8510/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 814.8675 - val_loss: 624.5409\n",
            "Epoch 8511/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 714.3932 - val_loss: 708.7542\n",
            "Epoch 8512/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 753.4075 - val_loss: 700.2133\n",
            "Epoch 8513/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 574.1062 - val_loss: 564.6421\n",
            "Epoch 8514/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 622.6529 - val_loss: 521.4995\n",
            "Epoch 8515/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 540.7260 - val_loss: 487.0842\n",
            "Epoch 8516/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 560.6790 - val_loss: 624.8688\n",
            "Epoch 8517/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 622.6473 - val_loss: 617.3748\n",
            "Epoch 8518/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 682.6051 - val_loss: 751.1909\n",
            "Epoch 8519/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 672.0971 - val_loss: 600.1181\n",
            "Epoch 8520/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 573.7218 - val_loss: 689.0895\n",
            "Epoch 8521/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 622.7406 - val_loss: 570.1531\n",
            "Epoch 8522/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 598.6264 - val_loss: 542.7943\n",
            "Epoch 8523/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 501.6991 - val_loss: 556.7351\n",
            "Epoch 8524/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 668.8273 - val_loss: 534.3557\n",
            "Epoch 8525/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 556.1143 - val_loss: 568.9152\n",
            "Epoch 8526/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 503.1288 - val_loss: 523.9743\n",
            "Epoch 8527/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 611.6592 - val_loss: 553.2383\n",
            "Epoch 8528/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 558.2489 - val_loss: 566.5751\n",
            "Epoch 8529/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 626.9847 - val_loss: 577.8493\n",
            "Epoch 8530/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 550.3045 - val_loss: 545.8049\n",
            "Epoch 8531/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 653.7576 - val_loss: 551.1973\n",
            "Epoch 8532/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 554.3431 - val_loss: 769.5569\n",
            "Epoch 8533/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 700.3176 - val_loss: 603.1450\n",
            "Epoch 8534/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 582.7233 - val_loss: 577.6309\n",
            "Epoch 8535/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 549.3928 - val_loss: 579.0337\n",
            "Epoch 8536/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 553.1573 - val_loss: 535.4442\n",
            "Epoch 8537/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 582.2728 - val_loss: 555.2499\n",
            "Epoch 8538/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 514.0911 - val_loss: 582.8256\n",
            "Epoch 8539/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 564.8529 - val_loss: 547.3036\n",
            "Epoch 8540/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 546.1210 - val_loss: 488.5832\n",
            "Epoch 8541/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 533.8861 - val_loss: 484.5098\n",
            "Epoch 8542/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 533.8558 - val_loss: 551.9962\n",
            "Epoch 8543/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 630.7392 - val_loss: 493.4044\n",
            "Epoch 8544/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 544.7140 - val_loss: 596.4387\n",
            "Epoch 8545/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 613.5564 - val_loss: 566.9199\n",
            "Epoch 8546/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 496.2506 - val_loss: 571.1713\n",
            "Epoch 8547/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 553.5870 - val_loss: 519.8748\n",
            "Epoch 8548/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 540.4256 - val_loss: 543.2955\n",
            "Epoch 8549/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 562.9475 - val_loss: 578.8912\n",
            "Epoch 8550/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 524.3087 - val_loss: 523.6604\n",
            "Epoch 8551/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 552.4576 - val_loss: 505.4943\n",
            "Epoch 8552/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 450.3874 - val_loss: 529.4735\n",
            "Epoch 8553/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 515.4886 - val_loss: 598.4702\n",
            "Epoch 8554/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 628.7398 - val_loss: 535.3276\n",
            "Epoch 8555/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 471.4704 - val_loss: 506.8138\n",
            "Epoch 8556/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 505.7486 - val_loss: 616.6085\n",
            "Epoch 8557/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 564.9415 - val_loss: 647.1277\n",
            "Epoch 8558/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 659.9212 - val_loss: 581.7272\n",
            "Epoch 8559/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 493.7945 - val_loss: 537.0635\n",
            "Epoch 8560/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 568.9628 - val_loss: 643.6987\n",
            "Epoch 8561/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 591.1103 - val_loss: 512.6041\n",
            "Epoch 8562/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 558.2851 - val_loss: 533.4232\n",
            "Epoch 8563/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 456.9357 - val_loss: 531.1063\n",
            "Epoch 8564/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 568.0005 - val_loss: 518.3580\n",
            "Epoch 8565/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 474.6451 - val_loss: 630.9293\n",
            "Epoch 8566/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 549.9593 - val_loss: 514.5273\n",
            "Epoch 8567/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 565.5250 - val_loss: 556.0834\n",
            "Epoch 8568/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 621.4819 - val_loss: 537.1336\n",
            "Epoch 8569/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 625.8333 - val_loss: 504.7413\n",
            "Epoch 8570/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 586.4902 - val_loss: 509.4666\n",
            "Epoch 8571/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 553.1294 - val_loss: 469.4051\n",
            "Epoch 8572/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 526.9235 - val_loss: 471.6288\n",
            "Epoch 8573/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 498.4317 - val_loss: 508.9234\n",
            "Epoch 8574/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 460.5390 - val_loss: 516.9692\n",
            "Epoch 8575/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 578.7231 - val_loss: 505.7304\n",
            "Epoch 8576/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 576.8246 - val_loss: 538.2186\n",
            "Epoch 8577/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 543.4304 - val_loss: 490.0368\n",
            "Epoch 8578/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 478.3245 - val_loss: 511.9894\n",
            "Epoch 8579/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 474.3596 - val_loss: 492.0957\n",
            "Epoch 8580/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 505.6323 - val_loss: 554.5031\n",
            "Epoch 8581/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 494.3985 - val_loss: 526.7634\n",
            "Epoch 8582/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 530.3072 - val_loss: 482.9230\n",
            "Epoch 8583/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 435.4960 - val_loss: 514.4033\n",
            "Epoch 8584/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 536.7218 - val_loss: 576.7497\n",
            "Epoch 8585/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 602.2336 - val_loss: 603.7698\n",
            "Epoch 8586/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 621.7875 - val_loss: 573.7172\n",
            "Epoch 8587/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 573.1472 - val_loss: 507.8472\n",
            "Epoch 8588/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 476.0534 - val_loss: 486.3042\n",
            "Epoch 8589/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 542.8186 - val_loss: 499.2532\n",
            "Epoch 8590/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 458.0921 - val_loss: 516.8845\n",
            "Epoch 8591/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 506.9683 - val_loss: 479.3853\n",
            "Epoch 8592/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 496.1145 - val_loss: 583.7639\n",
            "Epoch 8593/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 494.2746 - val_loss: 501.3020\n",
            "Epoch 8594/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 469.7570 - val_loss: 453.3898\n",
            "Epoch 8595/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 451.9147 - val_loss: 503.7615\n",
            "Epoch 8596/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 479.1638 - val_loss: 520.4300\n",
            "Epoch 8597/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 453.6691 - val_loss: 492.1276\n",
            "Epoch 8598/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 430.0642 - val_loss: 496.8212\n",
            "Epoch 8599/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 448.3630 - val_loss: 568.8207\n",
            "Epoch 8600/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 578.2931 - val_loss: 567.2997\n",
            "Epoch 8601/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 508.3523 - val_loss: 524.2892\n",
            "Epoch 8602/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 466.4571 - val_loss: 523.4603\n",
            "Epoch 8603/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 485.5766 - val_loss: 536.2106\n",
            "Epoch 8604/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 618.6284 - val_loss: 524.7371\n",
            "Epoch 8605/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 525.1773 - val_loss: 482.6333\n",
            "Epoch 8606/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 460.8733 - val_loss: 485.8005\n",
            "Epoch 8607/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 475.6602 - val_loss: 494.5230\n",
            "Epoch 8608/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 480.9607 - val_loss: 568.0737\n",
            "Epoch 8609/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 517.0981 - val_loss: 567.4178\n",
            "Epoch 8610/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 484.3462 - val_loss: 521.6141\n",
            "Epoch 8611/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 550.9387 - val_loss: 491.1291\n",
            "Epoch 8612/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 464.4665 - val_loss: 519.9011\n",
            "Epoch 8613/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 483.0454 - val_loss: 458.2454\n",
            "Epoch 8614/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 471.2390 - val_loss: 543.4061\n",
            "Epoch 8615/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 479.6626 - val_loss: 581.6244\n",
            "Epoch 8616/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 622.2466 - val_loss: 700.3920\n",
            "Epoch 8617/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 592.1291 - val_loss: 540.1509\n",
            "Epoch 8618/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 552.8541 - val_loss: 509.3865\n",
            "Epoch 8619/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 530.0838 - val_loss: 500.8947\n",
            "Epoch 8620/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 484.0983 - val_loss: 489.6399\n",
            "Epoch 8621/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 465.3471 - val_loss: 498.5844\n",
            "Epoch 8622/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 526.6186 - val_loss: 579.8834\n",
            "Epoch 8623/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 636.9338 - val_loss: 616.4172\n",
            "Epoch 8624/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 673.7364 - val_loss: 600.0142\n",
            "Epoch 8625/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 503.0399 - val_loss: 513.6710\n",
            "Epoch 8626/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 510.6399 - val_loss: 567.3241\n",
            "Epoch 8627/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 550.1176 - val_loss: 509.4478\n",
            "Epoch 8628/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 511.2798 - val_loss: 532.1789\n",
            "Epoch 8629/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 569.8876 - val_loss: 575.2202\n",
            "Epoch 8630/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 701.0131 - val_loss: 607.2574\n",
            "Epoch 8631/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 520.1503 - val_loss: 611.4662\n",
            "Epoch 8632/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 597.9778 - val_loss: 541.6840\n",
            "Epoch 8633/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 497.5749 - val_loss: 533.4258\n",
            "Epoch 8634/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 593.5955 - val_loss: 561.4401\n",
            "Epoch 8635/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 487.2262 - val_loss: 520.2409\n",
            "Epoch 8636/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 593.6258 - val_loss: 509.9140\n",
            "Epoch 8637/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 513.2831 - val_loss: 526.0531\n",
            "Epoch 8638/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 573.9377 - val_loss: 529.3230\n",
            "Epoch 8639/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 530.0524 - val_loss: 492.3492\n",
            "Epoch 8640/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 499.6191 - val_loss: 494.2235\n",
            "Epoch 8641/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 453.0926 - val_loss: 496.5268\n",
            "Epoch 8642/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 438.3303 - val_loss: 497.4341\n",
            "Epoch 8643/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 537.6527 - val_loss: 478.4751\n",
            "Epoch 8644/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 531.7134 - val_loss: 477.0726\n",
            "Epoch 8645/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 502.6411 - val_loss: 517.8550\n",
            "Epoch 8646/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 515.1494 - val_loss: 534.0961\n",
            "Epoch 8647/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 557.2204 - val_loss: 503.4659\n",
            "Epoch 8648/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 485.0607 - val_loss: 531.2452\n",
            "Epoch 8649/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 518.4622 - val_loss: 465.7277\n",
            "Epoch 8650/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 476.0818 - val_loss: 505.7390\n",
            "Epoch 8651/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 560.7366 - val_loss: 615.9529\n",
            "Epoch 8652/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 648.4433 - val_loss: 527.4076\n",
            "Epoch 8653/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 1309.5337 - val_loss: 1388.5586\n",
            "Epoch 8654/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 1332.6385 - val_loss: 1122.0627\n",
            "Epoch 8655/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 1084.1879 - val_loss: 699.3052\n",
            "Epoch 8656/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 724.0764 - val_loss: 725.9987\n",
            "Epoch 8657/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 735.6649 - val_loss: 643.9407\n",
            "Epoch 8658/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 757.3232 - val_loss: 1060.8861\n",
            "Epoch 8659/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 908.4384 - val_loss: 831.2763\n",
            "Epoch 8660/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 984.6856 - val_loss: 725.1071\n",
            "Epoch 8661/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 817.3823 - val_loss: 632.7311\n",
            "Epoch 8662/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 603.9541 - val_loss: 654.5394\n",
            "Epoch 8663/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 541.9241 - val_loss: 564.4911\n",
            "Epoch 8664/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 539.1496 - val_loss: 518.2486\n",
            "Epoch 8665/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 647.1002 - val_loss: 670.2635\n",
            "Epoch 8666/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 500.7158 - val_loss: 646.7510\n",
            "Epoch 8667/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 770.1278 - val_loss: 786.8190\n",
            "Epoch 8668/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 941.1486 - val_loss: 1343.7734\n",
            "Epoch 8669/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 1060.7958 - val_loss: 1137.9448\n",
            "Epoch 8670/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 1212.4780 - val_loss: 836.6605\n",
            "Epoch 8671/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 1017.9007 - val_loss: 1177.9203\n",
            "Epoch 8672/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 1128.0123 - val_loss: 1035.2634\n",
            "Epoch 8673/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 1465.8632 - val_loss: 1676.2220\n",
            "Epoch 8674/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 1543.8930 - val_loss: 1024.6200\n",
            "Epoch 8675/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1027.1653 - val_loss: 932.7742\n",
            "Epoch 8676/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 726.0891 - val_loss: 619.7625\n",
            "Epoch 8677/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 593.3830 - val_loss: 526.1001\n",
            "Epoch 8678/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 474.6003 - val_loss: 575.2172\n",
            "Epoch 8679/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 689.1609 - val_loss: 645.8371\n",
            "Epoch 8680/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 561.0578 - val_loss: 525.5015\n",
            "Epoch 8681/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 584.4501 - val_loss: 531.4431\n",
            "Epoch 8682/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 542.3071 - val_loss: 532.1263\n",
            "Epoch 8683/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 534.3779 - val_loss: 506.4196\n",
            "Epoch 8684/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 517.8546 - val_loss: 544.9185\n",
            "Epoch 8685/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 613.3344 - val_loss: 566.8418\n",
            "Epoch 8686/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 589.2403 - val_loss: 530.6696\n",
            "Epoch 8687/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 492.7846 - val_loss: 580.5294\n",
            "Epoch 8688/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 545.5639 - val_loss: 546.0386\n",
            "Epoch 8689/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 517.7169 - val_loss: 485.1834\n",
            "Epoch 8690/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 530.1017 - val_loss: 498.4912\n",
            "Epoch 8691/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 504.6142 - val_loss: 519.7191\n",
            "Epoch 8692/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 648.3334 - val_loss: 477.0950\n",
            "Epoch 8693/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 512.9422 - val_loss: 617.7399\n",
            "Epoch 8694/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 621.5536 - val_loss: 588.0119\n",
            "Epoch 8695/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 557.8371 - val_loss: 626.9437\n",
            "Epoch 8696/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 625.9573 - val_loss: 449.1886\n",
            "Epoch 8697/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 486.4044 - val_loss: 554.6655\n",
            "Epoch 8698/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 504.6254 - val_loss: 478.2875\n",
            "Epoch 8699/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 496.9494 - val_loss: 602.8839\n",
            "Epoch 8700/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 530.3463 - val_loss: 543.6541\n",
            "Epoch 8701/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 504.6789 - val_loss: 482.2337\n",
            "Epoch 8702/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 456.3081 - val_loss: 460.4436\n",
            "Epoch 8703/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 525.8169 - val_loss: 468.6552\n",
            "Epoch 8704/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 487.9020 - val_loss: 507.3855\n",
            "Epoch 8705/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 545.1825 - val_loss: 494.3934\n",
            "Epoch 8706/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 509.2759 - val_loss: 462.3012\n",
            "Epoch 8707/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 514.7003 - val_loss: 517.3991\n",
            "Epoch 8708/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 523.2395 - val_loss: 531.9585\n",
            "Epoch 8709/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 484.0664 - val_loss: 574.6208\n",
            "Epoch 8710/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 589.0325 - val_loss: 634.7966\n",
            "Epoch 8711/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 547.2130 - val_loss: 574.7158\n",
            "Epoch 8712/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 579.4714 - val_loss: 605.6667\n",
            "Epoch 8713/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 537.7858 - val_loss: 570.6484\n",
            "Epoch 8714/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 550.9324 - val_loss: 481.9586\n",
            "Epoch 8715/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 606.7541 - val_loss: 528.7020\n",
            "Epoch 8716/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 505.7599 - val_loss: 532.9377\n",
            "Epoch 8717/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 599.2559 - val_loss: 601.2851\n",
            "Epoch 8718/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 603.6823 - val_loss: 527.8306\n",
            "Epoch 8719/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 579.6726 - val_loss: 582.7551\n",
            "Epoch 8720/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 496.5260 - val_loss: 495.9648\n",
            "Epoch 8721/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 557.1288 - val_loss: 524.7578\n",
            "Epoch 8722/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 477.2487 - val_loss: 492.4982\n",
            "Epoch 8723/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 526.9212 - val_loss: 471.2750\n",
            "Epoch 8724/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 541.0546 - val_loss: 504.6644\n",
            "Epoch 8725/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 529.6701 - val_loss: 633.5504\n",
            "Epoch 8726/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 684.1709 - val_loss: 639.5132\n",
            "Epoch 8727/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 617.1873 - val_loss: 622.5582\n",
            "Epoch 8728/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 574.9054 - val_loss: 596.1350\n",
            "Epoch 8729/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 480.7436 - val_loss: 553.2383\n",
            "Epoch 8730/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 588.4434 - val_loss: 511.6387\n",
            "Epoch 8731/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 505.0295 - val_loss: 494.1103\n",
            "Epoch 8732/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 540.3639 - val_loss: 476.4727\n",
            "Epoch 8733/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 537.2584 - val_loss: 507.6517\n",
            "Epoch 8734/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 546.4425 - val_loss: 464.0041\n",
            "Epoch 8735/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 466.6305 - val_loss: 460.0622\n",
            "Epoch 8736/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 499.1907 - val_loss: 470.9142\n",
            "Epoch 8737/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 590.6826 - val_loss: 509.9592\n",
            "Epoch 8738/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 481.6616 - val_loss: 551.8694\n",
            "Epoch 8739/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 568.2760 - val_loss: 535.0399\n",
            "Epoch 8740/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 524.0570 - val_loss: 509.3055\n",
            "Epoch 8741/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 488.3106 - val_loss: 492.7851\n",
            "Epoch 8742/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 528.8958 - val_loss: 531.8547\n",
            "Epoch 8743/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 568.9280 - val_loss: 540.2054\n",
            "Epoch 8744/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 543.2066 - val_loss: 575.7812\n",
            "Epoch 8745/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 530.0872 - val_loss: 499.7084\n",
            "Epoch 8746/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 459.3934 - val_loss: 526.8663\n",
            "Epoch 8747/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 547.9806 - val_loss: 616.3944\n",
            "Epoch 8748/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 703.7098 - val_loss: 584.4082\n",
            "Epoch 8749/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 515.3647 - val_loss: 597.9973\n",
            "Epoch 8750/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 591.4973 - val_loss: 616.8488\n",
            "Epoch 8751/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 632.1206 - val_loss: 609.5676\n",
            "Epoch 8752/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 629.4048 - val_loss: 672.3757\n",
            "Epoch 8753/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 700.0880 - val_loss: 698.6967\n",
            "Epoch 8754/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 825.1362 - val_loss: 1024.2924\n",
            "Epoch 8755/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 973.8565 - val_loss: 1221.2311\n",
            "Epoch 8756/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1141.9820 - val_loss: 895.8978\n",
            "Epoch 8757/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 739.9333 - val_loss: 846.0330\n",
            "Epoch 8758/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 793.2607 - val_loss: 859.1157\n",
            "Epoch 8759/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 752.7865 - val_loss: 858.4309\n",
            "Epoch 8760/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 888.8622 - val_loss: 710.0638\n",
            "Epoch 8761/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 674.8530 - val_loss: 769.5262\n",
            "Epoch 8762/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 729.5206 - val_loss: 730.1798\n",
            "Epoch 8763/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 671.7132 - val_loss: 569.3512\n",
            "Epoch 8764/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 622.2721 - val_loss: 567.3662\n",
            "Epoch 8765/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 518.1213 - val_loss: 526.1629\n",
            "Epoch 8766/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 548.2037 - val_loss: 565.8003\n",
            "Epoch 8767/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 553.1898 - val_loss: 529.1817\n",
            "Epoch 8768/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 611.7015 - val_loss: 644.8449\n",
            "Epoch 8769/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 674.1293 - val_loss: 536.9214\n",
            "Epoch 8770/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 541.3889 - val_loss: 503.2595\n",
            "Epoch 8771/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 495.4324 - val_loss: 550.8843\n",
            "Epoch 8772/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 550.2680 - val_loss: 550.5054\n",
            "Epoch 8773/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 586.9241 - val_loss: 583.7258\n",
            "Epoch 8774/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 613.7608 - val_loss: 668.3258\n",
            "Epoch 8775/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 601.8998 - val_loss: 570.3942\n",
            "Epoch 8776/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 571.0762 - val_loss: 600.3294\n",
            "Epoch 8777/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 624.3613 - val_loss: 538.9283\n",
            "Epoch 8778/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 510.0847 - val_loss: 605.9418\n",
            "Epoch 8779/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 603.7575 - val_loss: 531.9627\n",
            "Epoch 8780/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 465.6474 - val_loss: 507.1176\n",
            "Epoch 8781/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 501.4435 - val_loss: 515.4235\n",
            "Epoch 8782/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 526.8929 - val_loss: 547.8287\n",
            "Epoch 8783/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 584.0015 - val_loss: 534.3112\n",
            "Epoch 8784/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 631.7596 - val_loss: 542.1130\n",
            "Epoch 8785/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 556.4302 - val_loss: 506.1918\n",
            "Epoch 8786/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 483.2735 - val_loss: 525.8346\n",
            "Epoch 8787/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 527.4314 - val_loss: 560.2798\n",
            "Epoch 8788/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 514.4626 - val_loss: 512.7097\n",
            "Epoch 8789/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 540.9830 - val_loss: 523.1490\n",
            "Epoch 8790/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 562.1390 - val_loss: 631.3787\n",
            "Epoch 8791/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 565.2911 - val_loss: 684.7625\n",
            "Epoch 8792/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 560.5442 - val_loss: 587.8842\n",
            "Epoch 8793/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 763.9764 - val_loss: 732.2421\n",
            "Epoch 8794/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 667.2369 - val_loss: 771.2477\n",
            "Epoch 8795/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 824.5777 - val_loss: 911.2753\n",
            "Epoch 8796/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 877.6862 - val_loss: 471.0883\n",
            "Epoch 8797/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 474.1400 - val_loss: 526.3095\n",
            "Epoch 8798/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 486.3361 - val_loss: 531.0883\n",
            "Epoch 8799/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 523.7215 - val_loss: 482.3773\n",
            "Epoch 8800/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 531.8388 - val_loss: 475.8893\n",
            "Epoch 8801/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 555.0660 - val_loss: 467.6565\n",
            "Epoch 8802/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 427.3119 - val_loss: 472.1874\n",
            "Epoch 8803/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 546.4966 - val_loss: 482.0831\n",
            "Epoch 8804/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 521.1518 - val_loss: 586.5037\n",
            "Epoch 8805/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 606.6171 - val_loss: 500.2141\n",
            "Epoch 8806/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 569.4291 - val_loss: 489.1745\n",
            "Epoch 8807/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 522.9722 - val_loss: 485.0772\n",
            "Epoch 8808/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 484.1506 - val_loss: 552.0781\n",
            "Epoch 8809/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 696.6424 - val_loss: 746.9666\n",
            "Epoch 8810/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 768.3599 - val_loss: 568.5082\n",
            "Epoch 8811/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 581.7015 - val_loss: 575.4603\n",
            "Epoch 8812/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 618.5935 - val_loss: 537.4438\n",
            "Epoch 8813/10000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 606.8160 - val_loss: 524.3439\n",
            "Epoch 8814/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 539.7898 - val_loss: 495.9829\n",
            "Epoch 8815/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 529.5310 - val_loss: 584.3055\n",
            "Epoch 8816/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 643.5605 - val_loss: 545.6615\n",
            "Epoch 8817/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 562.6895 - val_loss: 545.4082\n",
            "Epoch 8818/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 524.1457 - val_loss: 540.8613\n",
            "Epoch 8819/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 583.1328 - val_loss: 541.3202\n",
            "Epoch 8820/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 467.4522 - val_loss: 537.6478\n",
            "Epoch 8821/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 556.3798 - val_loss: 622.6144\n",
            "Epoch 8822/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 662.0241 - val_loss: 680.9962\n",
            "Epoch 8823/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 653.7101 - val_loss: 611.5656\n",
            "Epoch 8824/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 663.5244 - val_loss: 582.1713\n",
            "Epoch 8825/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 562.1922 - val_loss: 561.1824\n",
            "Epoch 8826/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 594.3388 - val_loss: 592.6207\n",
            "Epoch 8827/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 608.0557 - val_loss: 723.3069\n",
            "Epoch 8828/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 661.2153 - val_loss: 595.1570\n",
            "Epoch 8829/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 582.6227 - val_loss: 591.1749\n",
            "Epoch 8830/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 635.8433 - val_loss: 634.8643\n",
            "Epoch 8831/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 616.7636 - val_loss: 538.0712\n",
            "Epoch 8832/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 496.8032 - val_loss: 558.3533\n",
            "Epoch 8833/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 507.5936 - val_loss: 509.0295\n",
            "Epoch 8834/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 456.3269 - val_loss: 533.6630\n",
            "Epoch 8835/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 524.0681 - val_loss: 522.0589\n",
            "Epoch 8836/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 557.1757 - val_loss: 588.0760\n",
            "Epoch 8837/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 549.7151 - val_loss: 529.7520\n",
            "Epoch 8838/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 490.6185 - val_loss: 489.4594\n",
            "Epoch 8839/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 538.8828 - val_loss: 510.2390\n",
            "Epoch 8840/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 424.8357 - val_loss: 546.6344\n",
            "Epoch 8841/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 505.4249 - val_loss: 656.1519\n",
            "Epoch 8842/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 640.7252 - val_loss: 493.2245\n",
            "Epoch 8843/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 506.6136 - val_loss: 527.9204\n",
            "Epoch 8844/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 515.5632 - val_loss: 515.6737\n",
            "Epoch 8845/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 515.5225 - val_loss: 559.7690\n",
            "Epoch 8846/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 522.3546 - val_loss: 489.2593\n",
            "Epoch 8847/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 482.0052 - val_loss: 483.4235\n",
            "Epoch 8848/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 474.4869 - val_loss: 542.4686\n",
            "Epoch 8849/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 468.7764 - val_loss: 543.5089\n",
            "Epoch 8850/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 487.0545 - val_loss: 461.6711\n",
            "Epoch 8851/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 468.5065 - val_loss: 489.7022\n",
            "Epoch 8852/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 457.3110 - val_loss: 494.4628\n",
            "Epoch 8853/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 472.9452 - val_loss: 499.7178\n",
            "Epoch 8854/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 516.0852 - val_loss: 468.9968\n",
            "Epoch 8855/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 505.1585 - val_loss: 465.8923\n",
            "Epoch 8856/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 486.7752 - val_loss: 465.8138\n",
            "Epoch 8857/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 419.2637 - val_loss: 551.8738\n",
            "Epoch 8858/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 507.6031 - val_loss: 550.9516\n",
            "Epoch 8859/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 584.5884 - val_loss: 514.5967\n",
            "Epoch 8860/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 563.6443 - val_loss: 502.1472\n",
            "Epoch 8861/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 496.9193 - val_loss: 583.8887\n",
            "Epoch 8862/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 607.3631 - val_loss: 554.8326\n",
            "Epoch 8863/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 523.9949 - val_loss: 620.5370\n",
            "Epoch 8864/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 657.9185 - val_loss: 593.1066\n",
            "Epoch 8865/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 610.7906 - val_loss: 568.3017\n",
            "Epoch 8866/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 589.0783 - val_loss: 573.0818\n",
            "Epoch 8867/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 519.8530 - val_loss: 555.3605\n",
            "Epoch 8868/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 578.9407 - val_loss: 673.3043\n",
            "Epoch 8869/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 700.4751 - val_loss: 695.1373\n",
            "Epoch 8870/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 655.7629 - val_loss: 686.8423\n",
            "Epoch 8871/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 762.0066 - val_loss: 760.0110\n",
            "Epoch 8872/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 694.6998 - val_loss: 907.9229\n",
            "Epoch 8873/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 789.9316 - val_loss: 750.2678\n",
            "Epoch 8874/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 770.3305 - val_loss: 769.2651\n",
            "Epoch 8875/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 679.2095 - val_loss: 734.6219\n",
            "Epoch 8876/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 742.4003 - val_loss: 730.1626\n",
            "Epoch 8877/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 701.5304 - val_loss: 719.8416\n",
            "Epoch 8878/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 632.2782 - val_loss: 727.7632\n",
            "Epoch 8879/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 722.0698 - val_loss: 663.7287\n",
            "Epoch 8880/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 631.7752 - val_loss: 719.4842\n",
            "Epoch 8881/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 741.2878 - val_loss: 681.8692\n",
            "Epoch 8882/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 611.4176 - val_loss: 566.3026\n",
            "Epoch 8883/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 539.0498 - val_loss: 619.6760\n",
            "Epoch 8884/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 605.8111 - val_loss: 580.0817\n",
            "Epoch 8885/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 525.5516 - val_loss: 528.1108\n",
            "Epoch 8886/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 529.3064 - val_loss: 525.1227\n",
            "Epoch 8887/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 562.4822 - val_loss: 518.5748\n",
            "Epoch 8888/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 510.2808 - val_loss: 507.5834\n",
            "Epoch 8889/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 509.3971 - val_loss: 589.4661\n",
            "Epoch 8890/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 620.3952 - val_loss: 583.8035\n",
            "Epoch 8891/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 602.1438 - val_loss: 657.0612\n",
            "Epoch 8892/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 610.3698 - val_loss: 565.9832\n",
            "Epoch 8893/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 461.8438 - val_loss: 498.7019\n",
            "Epoch 8894/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 523.7305 - val_loss: 526.4608\n",
            "Epoch 8895/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 453.2539 - val_loss: 485.1404\n",
            "Epoch 8896/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 441.0682 - val_loss: 483.9490\n",
            "Epoch 8897/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 548.5081 - val_loss: 480.5714\n",
            "Epoch 8898/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 539.7434 - val_loss: 504.2329\n",
            "Epoch 8899/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 520.7420 - val_loss: 518.2469\n",
            "Epoch 8900/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 504.2047 - val_loss: 470.6826\n",
            "Epoch 8901/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 457.2052 - val_loss: 523.9672\n",
            "Epoch 8902/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 532.5166 - val_loss: 462.1032\n",
            "Epoch 8903/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 493.7499 - val_loss: 463.8605\n",
            "Epoch 8904/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 512.6279 - val_loss: 478.8721\n",
            "Epoch 8905/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 534.6028 - val_loss: 538.9913\n",
            "Epoch 8906/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 471.7731 - val_loss: 507.3174\n",
            "Epoch 8907/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 539.9755 - val_loss: 490.0663\n",
            "Epoch 8908/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 474.7513 - val_loss: 649.3599\n",
            "Epoch 8909/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 513.8804 - val_loss: 468.5090\n",
            "Epoch 8910/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 456.2115 - val_loss: 494.2740\n",
            "Epoch 8911/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 542.5039 - val_loss: 473.0295\n",
            "Epoch 8912/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 461.2012 - val_loss: 511.5928\n",
            "Epoch 8913/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 514.0385 - val_loss: 512.9902\n",
            "Epoch 8914/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 549.3801 - val_loss: 447.6281\n",
            "Epoch 8915/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 457.4694 - val_loss: 467.8583\n",
            "Epoch 8916/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 459.7049 - val_loss: 454.5486\n",
            "Epoch 8917/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 471.3917 - val_loss: 503.6131\n",
            "Epoch 8918/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 479.6370 - val_loss: 448.8593\n",
            "Epoch 8919/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 459.2571 - val_loss: 471.9233\n",
            "Epoch 8920/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 478.2388 - val_loss: 490.9269\n",
            "Epoch 8921/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 512.0127 - val_loss: 515.3343\n",
            "Epoch 8922/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 447.6187 - val_loss: 553.6333\n",
            "Epoch 8923/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 436.0844 - val_loss: 483.7501\n",
            "Epoch 8924/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 496.8603 - val_loss: 504.5290\n",
            "Epoch 8925/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 439.4127 - val_loss: 520.8098\n",
            "Epoch 8926/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 517.4773 - val_loss: 461.6971\n",
            "Epoch 8927/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 552.3038 - val_loss: 430.8708\n",
            "Epoch 8928/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 472.1459 - val_loss: 509.3931\n",
            "Epoch 8929/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 478.2232 - val_loss: 472.9076\n",
            "Epoch 8930/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 474.4803 - val_loss: 444.8241\n",
            "Epoch 8931/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 417.1545 - val_loss: 524.3752\n",
            "Epoch 8932/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 465.3839 - val_loss: 449.8750\n",
            "Epoch 8933/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 489.2820 - val_loss: 472.2701\n",
            "Epoch 8934/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 472.6199 - val_loss: 497.1962\n",
            "Epoch 8935/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 480.6534 - val_loss: 451.3057\n",
            "Epoch 8936/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 469.0032 - val_loss: 461.6441\n",
            "Epoch 8937/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 406.5969 - val_loss: 517.3940\n",
            "Epoch 8938/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 517.3642 - val_loss: 486.4828\n",
            "Epoch 8939/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 563.5287 - val_loss: 535.9357\n",
            "Epoch 8940/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 552.1035 - val_loss: 506.4370\n",
            "Epoch 8941/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 477.0197 - val_loss: 493.6353\n",
            "Epoch 8942/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 481.3689 - val_loss: 492.6785\n",
            "Epoch 8943/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 569.8468 - val_loss: 449.6852\n",
            "Epoch 8944/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 462.9537 - val_loss: 523.4956\n",
            "Epoch 8945/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 520.4893 - val_loss: 463.4844\n",
            "Epoch 8946/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 490.1097 - val_loss: 494.2914\n",
            "Epoch 8947/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 425.6874 - val_loss: 521.3688\n",
            "Epoch 8948/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 469.9833 - val_loss: 525.8576\n",
            "Epoch 8949/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 531.4946 - val_loss: 573.2711\n",
            "Epoch 8950/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 529.5226 - val_loss: 457.5326\n",
            "Epoch 8951/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 434.7196 - val_loss: 523.7065\n",
            "Epoch 8952/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 519.9202 - val_loss: 506.3833\n",
            "Epoch 8953/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 538.2440 - val_loss: 473.6773\n",
            "Epoch 8954/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 462.3191 - val_loss: 434.4274\n",
            "Epoch 8955/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 455.8788 - val_loss: 439.7886\n",
            "Epoch 8956/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 513.8020 - val_loss: 499.1425\n",
            "Epoch 8957/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 418.2674 - val_loss: 436.9539\n",
            "Epoch 8958/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 450.3352 - val_loss: 444.8842\n",
            "Epoch 8959/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 453.8230 - val_loss: 440.7073\n",
            "Epoch 8960/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 513.5526 - val_loss: 507.6875\n",
            "Epoch 8961/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 502.6338 - val_loss: 507.1572\n",
            "Epoch 8962/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 556.0850 - val_loss: 438.9666\n",
            "Epoch 8963/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 478.3545 - val_loss: 528.1306\n",
            "Epoch 8964/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 480.2242 - val_loss: 456.6868\n",
            "Epoch 8965/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 495.0697 - val_loss: 462.1280\n",
            "Epoch 8966/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 518.6825 - val_loss: 456.8980\n",
            "Epoch 8967/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 471.9868 - val_loss: 458.5858\n",
            "Epoch 8968/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 467.7212 - val_loss: 465.3834\n",
            "Epoch 8969/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 514.9264 - val_loss: 442.4166\n",
            "Epoch 8970/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 450.4209 - val_loss: 441.3546\n",
            "Epoch 8971/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 485.7372 - val_loss: 471.6936\n",
            "Epoch 8972/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 538.4552 - val_loss: 467.8897\n",
            "Epoch 8973/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 546.6856 - val_loss: 551.2566\n",
            "Epoch 8974/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 536.6956 - val_loss: 477.4888\n",
            "Epoch 8975/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 532.3605 - val_loss: 470.6802\n",
            "Epoch 8976/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 543.0860 - val_loss: 479.2419\n",
            "Epoch 8977/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 514.1494 - val_loss: 444.4421\n",
            "Epoch 8978/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 493.7591 - val_loss: 591.6446\n",
            "Epoch 8979/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 564.5520 - val_loss: 482.3874\n",
            "Epoch 8980/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 439.9654 - val_loss: 478.1340\n",
            "Epoch 8981/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 469.3020 - val_loss: 527.8727\n",
            "Epoch 8982/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 556.0181 - val_loss: 498.5990\n",
            "Epoch 8983/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 492.4050 - val_loss: 452.1746\n",
            "Epoch 8984/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 480.0618 - val_loss: 487.9922\n",
            "Epoch 8985/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 501.6689 - val_loss: 451.6439\n",
            "Epoch 8986/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 422.0670 - val_loss: 454.2039\n",
            "Epoch 8987/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 436.7337 - val_loss: 417.2754\n",
            "Epoch 8988/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 485.0412 - val_loss: 438.8417\n",
            "Epoch 8989/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 385.1645 - val_loss: 535.1344\n",
            "Epoch 8990/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 507.6794 - val_loss: 439.3865\n",
            "Epoch 8991/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 439.8063 - val_loss: 448.5148\n",
            "Epoch 8992/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 450.9604 - val_loss: 451.6591\n",
            "Epoch 8993/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 471.9955 - val_loss: 542.0769\n",
            "Epoch 8994/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 432.4702 - val_loss: 420.2582\n",
            "Epoch 8995/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 407.9711 - val_loss: 562.6966\n",
            "Epoch 8996/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 441.6363 - val_loss: 477.0954\n",
            "Epoch 8997/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 568.8116 - val_loss: 505.6578\n",
            "Epoch 8998/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 433.8761 - val_loss: 466.6311\n",
            "Epoch 8999/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 476.5355 - val_loss: 429.4499\n",
            "Epoch 9000/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 436.4809 - val_loss: 468.2229\n",
            "Epoch 9001/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 481.9408 - val_loss: 564.7172\n",
            "Epoch 9002/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 615.0409 - val_loss: 508.2849\n",
            "Epoch 9003/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 465.4718 - val_loss: 448.2513\n",
            "Epoch 9004/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 527.8526 - val_loss: 500.3485\n",
            "Epoch 9005/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 489.7085 - val_loss: 439.5050\n",
            "Epoch 9006/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 422.5432 - val_loss: 440.1964\n",
            "Epoch 9007/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 411.4127 - val_loss: 434.7959\n",
            "Epoch 9008/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 496.6706 - val_loss: 485.6433\n",
            "Epoch 9009/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 462.9314 - val_loss: 475.6890\n",
            "Epoch 9010/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 454.5563 - val_loss: 428.3738\n",
            "Epoch 9011/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 412.9431 - val_loss: 444.0322\n",
            "Epoch 9012/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 414.8843 - val_loss: 422.2950\n",
            "Epoch 9013/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 438.8817 - val_loss: 435.3664\n",
            "Epoch 9014/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 458.1155 - val_loss: 434.1125\n",
            "Epoch 9015/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 434.0838 - val_loss: 426.5139\n",
            "Epoch 9016/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 462.1735 - val_loss: 430.1770\n",
            "Epoch 9017/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 427.2918 - val_loss: 439.7224\n",
            "Epoch 9018/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 433.0254 - val_loss: 439.4052\n",
            "Epoch 9019/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 486.2602 - val_loss: 419.3996\n",
            "Epoch 9020/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 429.5982 - val_loss: 392.9377\n",
            "Epoch 9021/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 382.6300 - val_loss: 415.3788\n",
            "Epoch 9022/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 428.4595 - val_loss: 438.6018\n",
            "Epoch 9023/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 440.8931 - val_loss: 463.2970\n",
            "Epoch 9024/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 438.6296 - val_loss: 451.5220\n",
            "Epoch 9025/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 534.2192 - val_loss: 468.1001\n",
            "Epoch 9026/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 472.3528 - val_loss: 428.9318\n",
            "Epoch 9027/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 431.9558 - val_loss: 413.3132\n",
            "Epoch 9028/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 372.9828 - val_loss: 409.8379\n",
            "Epoch 9029/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 433.7883 - val_loss: 470.7500\n",
            "Epoch 9030/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 431.0188 - val_loss: 415.6895\n",
            "Epoch 9031/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 500.6629 - val_loss: 437.0689\n",
            "Epoch 9032/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 469.8305 - val_loss: 471.9247\n",
            "Epoch 9033/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 514.3567 - val_loss: 499.9280\n",
            "Epoch 9034/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 541.7873 - val_loss: 411.2903\n",
            "Epoch 9035/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 541.2409 - val_loss: 531.0732\n",
            "Epoch 9036/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 616.9506 - val_loss: 714.8134\n",
            "Epoch 9037/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 713.4606 - val_loss: 858.3111\n",
            "Epoch 9038/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 686.8083 - val_loss: 688.0206\n",
            "Epoch 9039/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 679.7910 - val_loss: 616.7166\n",
            "Epoch 9040/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 660.7438 - val_loss: 624.6219\n",
            "Epoch 9041/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 665.0242 - val_loss: 592.5798\n",
            "Epoch 9042/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 522.1355 - val_loss: 650.4025\n",
            "Epoch 9043/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 610.1300 - val_loss: 630.9044\n",
            "Epoch 9044/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 629.1902 - val_loss: 611.1666\n",
            "Epoch 9045/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 671.2320 - val_loss: 619.6861\n",
            "Epoch 9046/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 640.7018 - val_loss: 623.2325\n",
            "Epoch 9047/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 646.0322 - val_loss: 612.0499\n",
            "Epoch 9048/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 665.0454 - val_loss: 577.9387\n",
            "Epoch 9049/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 607.8992 - val_loss: 552.8383\n",
            "Epoch 9050/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 647.9830 - val_loss: 536.3848\n",
            "Epoch 9051/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 609.7708 - val_loss: 523.8428\n",
            "Epoch 9052/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 560.4616 - val_loss: 537.2395\n",
            "Epoch 9053/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 540.6163 - val_loss: 609.6765\n",
            "Epoch 9054/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 600.3622 - val_loss: 499.7711\n",
            "Epoch 9055/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 565.1921 - val_loss: 528.6499\n",
            "Epoch 9056/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 458.4917 - val_loss: 503.6008\n",
            "Epoch 9057/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 586.1401 - val_loss: 560.1660\n",
            "Epoch 9058/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 575.4133 - val_loss: 535.1412\n",
            "Epoch 9059/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 498.8804 - val_loss: 541.9993\n",
            "Epoch 9060/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 588.8842 - val_loss: 555.0648\n",
            "Epoch 9061/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 509.2953 - val_loss: 569.8348\n",
            "Epoch 9062/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 518.2689 - val_loss: 559.1379\n",
            "Epoch 9063/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 531.4277 - val_loss: 548.2050\n",
            "Epoch 9064/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 531.3173 - val_loss: 548.5043\n",
            "Epoch 9065/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 549.9674 - val_loss: 536.0919\n",
            "Epoch 9066/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 514.2809 - val_loss: 525.0220\n",
            "Epoch 9067/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 479.3684 - val_loss: 505.9687\n",
            "Epoch 9068/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 476.8550 - val_loss: 483.8712\n",
            "Epoch 9069/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 489.0393 - val_loss: 521.8210\n",
            "Epoch 9070/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 511.9996 - val_loss: 536.2644\n",
            "Epoch 9071/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 563.1075 - val_loss: 535.2379\n",
            "Epoch 9072/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 505.0553 - val_loss: 538.6722\n",
            "Epoch 9073/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 532.1494 - val_loss: 526.0078\n",
            "Epoch 9074/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 493.1888 - val_loss: 534.8059\n",
            "Epoch 9075/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 569.3247 - val_loss: 590.4747\n",
            "Epoch 9076/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 600.4880 - val_loss: 552.5182\n",
            "Epoch 9077/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 535.4387 - val_loss: 530.5125\n",
            "Epoch 9078/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 532.7559 - val_loss: 537.7767\n",
            "Epoch 9079/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 507.6711 - val_loss: 495.4692\n",
            "Epoch 9080/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 502.5354 - val_loss: 533.9546\n",
            "Epoch 9081/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 515.6125 - val_loss: 560.2295\n",
            "Epoch 9082/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 587.7378 - val_loss: 592.2584\n",
            "Epoch 9083/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 537.5876 - val_loss: 503.5899\n",
            "Epoch 9084/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 571.7569 - val_loss: 569.1621\n",
            "Epoch 9085/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 546.3455 - val_loss: 588.4935\n",
            "Epoch 9086/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 614.5580 - val_loss: 604.5987\n",
            "Epoch 9087/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 588.8881 - val_loss: 570.6277\n",
            "Epoch 9088/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 578.0564 - val_loss: 501.4949\n",
            "Epoch 9089/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 578.8271 - val_loss: 501.6984\n",
            "Epoch 9090/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 479.2494 - val_loss: 480.2303\n",
            "Epoch 9091/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 496.7768 - val_loss: 552.6851\n",
            "Epoch 9092/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 521.1704 - val_loss: 503.5406\n",
            "Epoch 9093/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 477.2936 - val_loss: 521.6450\n",
            "Epoch 9094/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 557.5911 - val_loss: 523.2777\n",
            "Epoch 9095/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 503.7968 - val_loss: 465.8795\n",
            "Epoch 9096/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 510.7546 - val_loss: 457.9885\n",
            "Epoch 9097/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 530.0117 - val_loss: 541.2550\n",
            "Epoch 9098/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 432.7891 - val_loss: 524.5659\n",
            "Epoch 9099/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 543.9043 - val_loss: 551.6771\n",
            "Epoch 9100/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 531.2022 - val_loss: 541.6851\n",
            "Epoch 9101/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 628.5975 - val_loss: 540.4262\n",
            "Epoch 9102/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 542.2019 - val_loss: 504.4518\n",
            "Epoch 9103/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 495.2310 - val_loss: 512.3991\n",
            "Epoch 9104/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 543.0846 - val_loss: 541.5715\n",
            "Epoch 9105/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 529.7953 - val_loss: 539.3200\n",
            "Epoch 9106/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 512.2830 - val_loss: 494.6366\n",
            "Epoch 9107/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 465.3800 - val_loss: 516.3610\n",
            "Epoch 9108/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 560.9559 - val_loss: 487.1179\n",
            "Epoch 9109/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 503.8015 - val_loss: 489.4084\n",
            "Epoch 9110/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 530.4585 - val_loss: 574.9079\n",
            "Epoch 9111/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 543.5449 - val_loss: 525.0659\n",
            "Epoch 9112/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 579.9944 - val_loss: 541.9716\n",
            "Epoch 9113/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 611.3187 - val_loss: 516.0356\n",
            "Epoch 9114/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 529.7684 - val_loss: 571.3792\n",
            "Epoch 9115/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 503.9222 - val_loss: 513.0061\n",
            "Epoch 9116/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 513.4382 - val_loss: 531.9774\n",
            "Epoch 9117/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 519.3286 - val_loss: 559.0547\n",
            "Epoch 9118/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 547.3920 - val_loss: 613.1370\n",
            "Epoch 9119/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 645.3486 - val_loss: 623.2014\n",
            "Epoch 9120/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 606.6877 - val_loss: 558.2244\n",
            "Epoch 9121/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 589.1850 - val_loss: 542.3737\n",
            "Epoch 9122/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 543.5640 - val_loss: 574.8620\n",
            "Epoch 9123/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 546.7268 - val_loss: 597.2041\n",
            "Epoch 9124/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 592.6900 - val_loss: 538.3503\n",
            "Epoch 9125/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 662.4536 - val_loss: 541.4793\n",
            "Epoch 9126/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 553.7863 - val_loss: 580.6651\n",
            "Epoch 9127/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 641.8836 - val_loss: 577.9943\n",
            "Epoch 9128/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 623.1453 - val_loss: 558.3542\n",
            "Epoch 9129/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 529.5855 - val_loss: 559.7339\n",
            "Epoch 9130/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 543.4104 - val_loss: 555.8572\n",
            "Epoch 9131/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 566.7675 - val_loss: 548.0197\n",
            "Epoch 9132/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 584.0244 - val_loss: 697.0643\n",
            "Epoch 9133/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 553.0345 - val_loss: 524.3593\n",
            "Epoch 9134/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 522.0207 - val_loss: 576.1248\n",
            "Epoch 9135/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 517.1740 - val_loss: 573.0460\n",
            "Epoch 9136/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 575.3206 - val_loss: 515.8087\n",
            "Epoch 9137/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 472.6972 - val_loss: 567.1341\n",
            "Epoch 9138/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 573.2133 - val_loss: 547.1765\n",
            "Epoch 9139/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 607.9705 - val_loss: 593.0579\n",
            "Epoch 9140/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 587.9502 - val_loss: 515.8128\n",
            "Epoch 9141/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 556.1482 - val_loss: 532.4263\n",
            "Epoch 9142/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 489.5674 - val_loss: 602.9074\n",
            "Epoch 9143/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 532.3283 - val_loss: 508.3675\n",
            "Epoch 9144/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 584.0762 - val_loss: 553.0749\n",
            "Epoch 9145/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 562.7488 - val_loss: 508.0854\n",
            "Epoch 9146/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 601.1391 - val_loss: 468.3019\n",
            "Epoch 9147/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 480.2769 - val_loss: 440.0075\n",
            "Epoch 9148/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 420.6070 - val_loss: 592.9860\n",
            "Epoch 9149/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 438.9048 - val_loss: 554.7276\n",
            "Epoch 9150/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 476.3537 - val_loss: 486.2031\n",
            "Epoch 9151/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 501.8896 - val_loss: 470.1927\n",
            "Epoch 9152/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 482.6167 - val_loss: 521.5463\n",
            "Epoch 9153/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 519.3192 - val_loss: 505.5928\n",
            "Epoch 9154/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 514.2437 - val_loss: 453.2892\n",
            "Epoch 9155/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 463.8956 - val_loss: 462.1071\n",
            "Epoch 9156/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 474.5784 - val_loss: 457.0515\n",
            "Epoch 9157/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 445.0785 - val_loss: 506.9623\n",
            "Epoch 9158/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 555.4442 - val_loss: 452.8688\n",
            "Epoch 9159/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 463.4792 - val_loss: 530.6501\n",
            "Epoch 9160/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 491.8511 - val_loss: 470.9737\n",
            "Epoch 9161/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 485.1291 - val_loss: 479.5136\n",
            "Epoch 9162/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 474.8481 - val_loss: 461.1352\n",
            "Epoch 9163/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 498.5859 - val_loss: 461.9518\n",
            "Epoch 9164/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 474.2352 - val_loss: 479.9635\n",
            "Epoch 9165/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 486.0120 - val_loss: 478.8467\n",
            "Epoch 9166/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 462.9561 - val_loss: 477.6041\n",
            "Epoch 9167/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 489.5244 - val_loss: 463.2173\n",
            "Epoch 9168/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 427.8778 - val_loss: 608.5712\n",
            "Epoch 9169/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 540.9682 - val_loss: 448.4393\n",
            "Epoch 9170/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 463.8978 - val_loss: 495.1235\n",
            "Epoch 9171/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 465.4777 - val_loss: 515.6238\n",
            "Epoch 9172/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 598.4933 - val_loss: 463.1413\n",
            "Epoch 9173/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 416.6468 - val_loss: 493.4482\n",
            "Epoch 9174/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 451.7749 - val_loss: 441.1711\n",
            "Epoch 9175/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 459.8629 - val_loss: 522.1585\n",
            "Epoch 9176/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 479.5862 - val_loss: 427.4566\n",
            "Epoch 9177/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 470.4563 - val_loss: 483.3636\n",
            "Epoch 9178/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 477.7071 - val_loss: 478.6817\n",
            "Epoch 9179/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 522.6267 - val_loss: 469.5237\n",
            "Epoch 9180/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 533.9351 - val_loss: 476.6483\n",
            "Epoch 9181/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 471.0539 - val_loss: 479.8205\n",
            "Epoch 9182/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 482.9777 - val_loss: 449.7933\n",
            "Epoch 9183/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 462.1884 - val_loss: 462.1942\n",
            "Epoch 9184/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 500.9281 - val_loss: 423.0612\n",
            "Epoch 9185/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 494.1028 - val_loss: 456.1972\n",
            "Epoch 9186/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 486.9166 - val_loss: 536.8478\n",
            "Epoch 9187/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 540.4305 - val_loss: 475.0297\n",
            "Epoch 9188/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 451.3487 - val_loss: 442.4102\n",
            "Epoch 9189/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 456.1906 - val_loss: 479.1486\n",
            "Epoch 9190/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 483.4691 - val_loss: 521.7263\n",
            "Epoch 9191/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 440.6897 - val_loss: 465.4302\n",
            "Epoch 9192/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 440.0748 - val_loss: 488.6941\n",
            "Epoch 9193/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 517.6475 - val_loss: 494.4403\n",
            "Epoch 9194/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 462.4593 - val_loss: 454.7036\n",
            "Epoch 9195/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 423.8993 - val_loss: 460.6648\n",
            "Epoch 9196/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 439.9504 - val_loss: 514.7866\n",
            "Epoch 9197/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 506.3727 - val_loss: 495.9142\n",
            "Epoch 9198/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 462.0174 - val_loss: 416.8726\n",
            "Epoch 9199/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 430.7653 - val_loss: 412.4478\n",
            "Epoch 9200/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 460.1092 - val_loss: 550.0690\n",
            "Epoch 9201/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 463.0542 - val_loss: 468.0857\n",
            "Epoch 9202/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 383.0261 - val_loss: 476.0679\n",
            "Epoch 9203/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 571.7059 - val_loss: 445.9771\n",
            "Epoch 9204/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 435.5175 - val_loss: 550.3673\n",
            "Epoch 9205/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 537.2286 - val_loss: 488.2611\n",
            "Epoch 9206/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 518.3791 - val_loss: 512.9767\n",
            "Epoch 9207/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 545.4693 - val_loss: 562.8187\n",
            "Epoch 9208/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 621.9782 - val_loss: 561.4490\n",
            "Epoch 9209/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 569.6400 - val_loss: 560.8957\n",
            "Epoch 9210/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 506.8644 - val_loss: 544.1304\n",
            "Epoch 9211/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 556.1429 - val_loss: 476.0366\n",
            "Epoch 9212/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 429.9310 - val_loss: 478.4126\n",
            "Epoch 9213/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 425.0477 - val_loss: 449.2973\n",
            "Epoch 9214/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 458.5786 - val_loss: 459.5767\n",
            "Epoch 9215/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 425.8670 - val_loss: 467.0477\n",
            "Epoch 9216/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 487.4960 - val_loss: 426.8523\n",
            "Epoch 9217/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 415.3252 - val_loss: 421.6401\n",
            "Epoch 9218/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 479.8253 - val_loss: 499.2192\n",
            "Epoch 9219/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 543.3789 - val_loss: 466.5173\n",
            "Epoch 9220/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 426.4661 - val_loss: 531.4252\n",
            "Epoch 9221/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 561.9462 - val_loss: 508.3081\n",
            "Epoch 9222/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 484.6804 - val_loss: 523.1246\n",
            "Epoch 9223/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 505.7366 - val_loss: 515.1700\n",
            "Epoch 9224/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 532.3659 - val_loss: 499.6382\n",
            "Epoch 9225/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 488.2526 - val_loss: 448.7098\n",
            "Epoch 9226/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 490.1946 - val_loss: 595.2568\n",
            "Epoch 9227/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 581.3307 - val_loss: 503.1000\n",
            "Epoch 9228/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 507.9960 - val_loss: 486.2034\n",
            "Epoch 9229/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 457.8420 - val_loss: 614.4855\n",
            "Epoch 9230/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 589.0019 - val_loss: 482.5495\n",
            "Epoch 9231/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 536.0817 - val_loss: 546.6440\n",
            "Epoch 9232/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 508.7106 - val_loss: 503.8795\n",
            "Epoch 9233/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 541.5869 - val_loss: 499.9980\n",
            "Epoch 9234/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 513.4700 - val_loss: 509.3209\n",
            "Epoch 9235/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 483.9432 - val_loss: 499.9926\n",
            "Epoch 9236/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 499.5496 - val_loss: 517.4890\n",
            "Epoch 9237/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 473.8044 - val_loss: 587.0440\n",
            "Epoch 9238/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 609.4696 - val_loss: 552.2427\n",
            "Epoch 9239/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 617.0472 - val_loss: 595.5198\n",
            "Epoch 9240/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 518.4261 - val_loss: 545.2050\n",
            "Epoch 9241/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 558.8697 - val_loss: 560.7756\n",
            "Epoch 9242/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 554.6010 - val_loss: 600.9839\n",
            "Epoch 9243/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 530.4140 - val_loss: 582.6628\n",
            "Epoch 9244/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 510.2584 - val_loss: 490.6896\n",
            "Epoch 9245/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 514.9737 - val_loss: 538.8084\n",
            "Epoch 9246/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 532.8622 - val_loss: 461.4967\n",
            "Epoch 9247/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 498.6433 - val_loss: 533.1652\n",
            "Epoch 9248/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 580.8771 - val_loss: 544.9642\n",
            "Epoch 9249/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 594.6115 - val_loss: 539.5980\n",
            "Epoch 9250/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 613.5045 - val_loss: 532.7335\n",
            "Epoch 9251/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 555.0300 - val_loss: 508.6702\n",
            "Epoch 9252/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 479.1239 - val_loss: 509.1877\n",
            "Epoch 9253/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 507.5710 - val_loss: 558.0487\n",
            "Epoch 9254/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 574.4682 - val_loss: 582.1365\n",
            "Epoch 9255/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 544.0942 - val_loss: 585.0592\n",
            "Epoch 9256/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 567.8839 - val_loss: 523.3098\n",
            "Epoch 9257/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 545.3492 - val_loss: 555.0367\n",
            "Epoch 9258/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 580.1188 - val_loss: 595.2296\n",
            "Epoch 9259/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 607.1039 - val_loss: 494.0592\n",
            "Epoch 9260/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 488.3996 - val_loss: 514.9178\n",
            "Epoch 9261/10000\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 506.7247 - val_loss: 695.7144\n",
            "Epoch 9262/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 599.0746 - val_loss: 601.9221\n",
            "Epoch 9263/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 567.3509 - val_loss: 601.3086\n",
            "Epoch 9264/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 533.4453 - val_loss: 580.0029\n",
            "Epoch 9265/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 634.0290 - val_loss: 577.1458\n",
            "Epoch 9266/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 586.4068 - val_loss: 687.6207\n",
            "Epoch 9267/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 561.4674 - val_loss: 539.1821\n",
            "Epoch 9268/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 650.4822 - val_loss: 561.9906\n",
            "Epoch 9269/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 547.4670 - val_loss: 516.7806\n",
            "Epoch 9270/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 572.7083 - val_loss: 552.9454\n",
            "Epoch 9271/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 507.2919 - val_loss: 495.2019\n",
            "Epoch 9272/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 515.7871 - val_loss: 507.4907\n",
            "Epoch 9273/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 485.2580 - val_loss: 540.5886\n",
            "Epoch 9274/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 526.4987 - val_loss: 497.2423\n",
            "Epoch 9275/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 506.7925 - val_loss: 499.1553\n",
            "Epoch 9276/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 497.2369 - val_loss: 520.4974\n",
            "Epoch 9277/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 507.3135 - val_loss: 527.0831\n",
            "Epoch 9278/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 545.0831 - val_loss: 580.0341\n",
            "Epoch 9279/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 603.5109 - val_loss: 531.8356\n",
            "Epoch 9280/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 541.1853 - val_loss: 641.5957\n",
            "Epoch 9281/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 586.0023 - val_loss: 569.3007\n",
            "Epoch 9282/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 519.2742 - val_loss: 571.9497\n",
            "Epoch 9283/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 543.7382 - val_loss: 512.0709\n",
            "Epoch 9284/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 496.6784 - val_loss: 573.2825\n",
            "Epoch 9285/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 519.5927 - val_loss: 618.2659\n",
            "Epoch 9286/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 609.6722 - val_loss: 595.0743\n",
            "Epoch 9287/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 547.2754 - val_loss: 583.7678\n",
            "Epoch 9288/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 521.0728 - val_loss: 551.6081\n",
            "Epoch 9289/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 581.2031 - val_loss: 524.8818\n",
            "Epoch 9290/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 519.2917 - val_loss: 535.0071\n",
            "Epoch 9291/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 556.3961 - val_loss: 544.5861\n",
            "Epoch 9292/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 582.9581 - val_loss: 498.0931\n",
            "Epoch 9293/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 448.8258 - val_loss: 748.0071\n",
            "Epoch 9294/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 728.4895 - val_loss: 757.5062\n",
            "Epoch 9295/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 753.4722 - val_loss: 911.2197\n",
            "Epoch 9296/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 888.9545 - val_loss: 784.5250\n",
            "Epoch 9297/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 862.5958 - val_loss: 858.6147\n",
            "Epoch 9298/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 761.5047 - val_loss: 806.4465\n",
            "Epoch 9299/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 643.7553 - val_loss: 653.2956\n",
            "Epoch 9300/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 511.0669 - val_loss: 607.8927\n",
            "Epoch 9301/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 637.0792 - val_loss: 748.0003\n",
            "Epoch 9302/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 709.3566 - val_loss: 639.6321\n",
            "Epoch 9303/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 702.2127 - val_loss: 590.4072\n",
            "Epoch 9304/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 564.2631 - val_loss: 576.4299\n",
            "Epoch 9305/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 548.2450 - val_loss: 603.6271\n",
            "Epoch 9306/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 638.3320 - val_loss: 519.8007\n",
            "Epoch 9307/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 558.6515 - val_loss: 486.8183\n",
            "Epoch 9308/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 521.3013 - val_loss: 519.7883\n",
            "Epoch 9309/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 541.1623 - val_loss: 491.1688\n",
            "Epoch 9310/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 448.9217 - val_loss: 488.1857\n",
            "Epoch 9311/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 472.8426 - val_loss: 499.1951\n",
            "Epoch 9312/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 560.5184 - val_loss: 531.5808\n",
            "Epoch 9313/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 538.0093 - val_loss: 562.6871\n",
            "Epoch 9314/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 470.7771 - val_loss: 545.3199\n",
            "Epoch 9315/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 549.5594 - val_loss: 527.8418\n",
            "Epoch 9316/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 534.1502 - val_loss: 531.2776\n",
            "Epoch 9317/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 561.2239 - val_loss: 640.9238\n",
            "Epoch 9318/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 661.9783 - val_loss: 660.7878\n",
            "Epoch 9319/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 730.4039 - val_loss: 705.1379\n",
            "Epoch 9320/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 710.4834 - val_loss: 685.9057\n",
            "Epoch 9321/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 785.7170 - val_loss: 705.8673\n",
            "Epoch 9322/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 761.2092 - val_loss: 684.4694\n",
            "Epoch 9323/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 621.1523 - val_loss: 581.9537\n",
            "Epoch 9324/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 615.6095 - val_loss: 633.7062\n",
            "Epoch 9325/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 647.4742 - val_loss: 726.8703\n",
            "Epoch 9326/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 667.2792 - val_loss: 660.4072\n",
            "Epoch 9327/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 647.6530 - val_loss: 700.1306\n",
            "Epoch 9328/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 637.6645 - val_loss: 754.2540\n",
            "Epoch 9329/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 776.6707 - val_loss: 711.5613\n",
            "Epoch 9330/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 778.7953 - val_loss: 613.7192\n",
            "Epoch 9331/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 560.9522 - val_loss: 632.4294\n",
            "Epoch 9332/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 622.5082 - val_loss: 578.2276\n",
            "Epoch 9333/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 678.2329 - val_loss: 669.9344\n",
            "Epoch 9334/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 592.2059 - val_loss: 584.5563\n",
            "Epoch 9335/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 642.0122 - val_loss: 547.0138\n",
            "Epoch 9336/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 596.0941 - val_loss: 526.6762\n",
            "Epoch 9337/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 655.2040 - val_loss: 519.2902\n",
            "Epoch 9338/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 587.2400 - val_loss: 500.2366\n",
            "Epoch 9339/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 512.3125 - val_loss: 546.9828\n",
            "Epoch 9340/10000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 552.3403 - val_loss: 662.8235\n",
            "Epoch 9341/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 625.4685 - val_loss: 554.9913\n",
            "Epoch 9342/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 517.5483 - val_loss: 708.3859\n",
            "Epoch 9343/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 724.8081 - val_loss: 707.0471\n",
            "Epoch 9344/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 796.0367 - val_loss: 708.2306\n",
            "Epoch 9345/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 737.8266 - val_loss: 689.6918\n",
            "Epoch 9346/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 617.3329 - val_loss: 587.2166\n",
            "Epoch 9347/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 673.0187 - val_loss: 607.8958\n",
            "Epoch 9348/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 569.1884 - val_loss: 525.6329\n",
            "Epoch 9349/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 542.3830 - val_loss: 538.3792\n",
            "Epoch 9350/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 612.5079 - val_loss: 525.4748\n",
            "Epoch 9351/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 533.1636 - val_loss: 524.9857\n",
            "Epoch 9352/10000\n",
            "12/12 [==============================] - 1s 75ms/step - loss: 531.1426 - val_loss: 490.0468\n",
            "Epoch 9353/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 509.4431 - val_loss: 530.6694\n",
            "Epoch 9354/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 463.6272 - val_loss: 484.3599\n",
            "Epoch 9355/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 542.0236 - val_loss: 487.7933\n",
            "Epoch 9356/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 535.8914 - val_loss: 499.0765\n",
            "Epoch 9357/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 596.7391 - val_loss: 516.9918\n",
            "Epoch 9358/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 552.3709 - val_loss: 479.0852\n",
            "Epoch 9359/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 537.0248 - val_loss: 527.5769\n",
            "Epoch 9360/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 533.5055 - val_loss: 493.1077\n",
            "Epoch 9361/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 530.0018 - val_loss: 529.5569\n",
            "Epoch 9362/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 499.6256 - val_loss: 482.0725\n",
            "Epoch 9363/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 508.4347 - val_loss: 488.6160\n",
            "Epoch 9364/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 525.8047 - val_loss: 513.6494\n",
            "Epoch 9365/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 458.6784 - val_loss: 517.5812\n",
            "Epoch 9366/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 518.6146 - val_loss: 471.8880\n",
            "Epoch 9367/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 591.4985 - val_loss: 561.0807\n",
            "Epoch 9368/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 585.2450 - val_loss: 472.3557\n",
            "Epoch 9369/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 479.5147 - val_loss: 468.0850\n",
            "Epoch 9370/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 536.1640 - val_loss: 501.6474\n",
            "Epoch 9371/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 501.0076 - val_loss: 477.2842\n",
            "Epoch 9372/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 426.9967 - val_loss: 481.5680\n",
            "Epoch 9373/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 488.9110 - val_loss: 466.1386\n",
            "Epoch 9374/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 447.6504 - val_loss: 471.2376\n",
            "Epoch 9375/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 486.8731 - val_loss: 567.3234\n",
            "Epoch 9376/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 471.8107 - val_loss: 474.4138\n",
            "Epoch 9377/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 476.2702 - val_loss: 468.8979\n",
            "Epoch 9378/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 462.8826 - val_loss: 484.3265\n",
            "Epoch 9379/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 590.3499 - val_loss: 456.5302\n",
            "Epoch 9380/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 407.1488 - val_loss: 482.5232\n",
            "Epoch 9381/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 436.1959 - val_loss: 480.5390\n",
            "Epoch 9382/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 399.7001 - val_loss: 473.1392\n",
            "Epoch 9383/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 512.7489 - val_loss: 458.3523\n",
            "Epoch 9384/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 458.2689 - val_loss: 448.9777\n",
            "Epoch 9385/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 495.2431 - val_loss: 447.0362\n",
            "Epoch 9386/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 490.6838 - val_loss: 473.5829\n",
            "Epoch 9387/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 509.8998 - val_loss: 493.0248\n",
            "Epoch 9388/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 533.4172 - val_loss: 435.8435\n",
            "Epoch 9389/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 420.9510 - val_loss: 516.7389\n",
            "Epoch 9390/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 546.3480 - val_loss: 495.2850\n",
            "Epoch 9391/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 475.4150 - val_loss: 531.2606\n",
            "Epoch 9392/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 456.4215 - val_loss: 632.8704\n",
            "Epoch 9393/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 632.5831 - val_loss: 530.2996\n",
            "Epoch 9394/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 495.3448 - val_loss: 478.5000\n",
            "Epoch 9395/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 477.0230 - val_loss: 515.0950\n",
            "Epoch 9396/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 546.7672 - val_loss: 605.2430\n",
            "Epoch 9397/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 605.7814 - val_loss: 669.6535\n",
            "Epoch 9398/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 671.1391 - val_loss: 647.4342\n",
            "Epoch 9399/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 688.7303 - val_loss: 610.2750\n",
            "Epoch 9400/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 610.4576 - val_loss: 542.0293\n",
            "Epoch 9401/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 548.6332 - val_loss: 521.0040\n",
            "Epoch 9402/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 448.6419 - val_loss: 694.2208\n",
            "Epoch 9403/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 549.9327 - val_loss: 497.1078\n",
            "Epoch 9404/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 583.4167 - val_loss: 468.4338\n",
            "Epoch 9405/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 516.7982 - val_loss: 478.2426\n",
            "Epoch 9406/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 526.3508 - val_loss: 567.3931\n",
            "Epoch 9407/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 544.1224 - val_loss: 494.8161\n",
            "Epoch 9408/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 547.0931 - val_loss: 528.6227\n",
            "Epoch 9409/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 467.8581 - val_loss: 529.5591\n",
            "Epoch 9410/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 569.4120 - val_loss: 476.3480\n",
            "Epoch 9411/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 525.6268 - val_loss: 485.6706\n",
            "Epoch 9412/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 517.0447 - val_loss: 485.8667\n",
            "Epoch 9413/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 476.5703 - val_loss: 649.6932\n",
            "Epoch 9414/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 496.4597 - val_loss: 528.2542\n",
            "Epoch 9415/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 572.9890 - val_loss: 495.8586\n",
            "Epoch 9416/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 510.2432 - val_loss: 477.8793\n",
            "Epoch 9417/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 542.3318 - val_loss: 517.1445\n",
            "Epoch 9418/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 510.6482 - val_loss: 478.4432\n",
            "Epoch 9419/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 443.7204 - val_loss: 543.0103\n",
            "Epoch 9420/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 579.4754 - val_loss: 600.1425\n",
            "Epoch 9421/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 504.9976 - val_loss: 526.3889\n",
            "Epoch 9422/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 585.2661 - val_loss: 540.5870\n",
            "Epoch 9423/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 571.2648 - val_loss: 492.7561\n",
            "Epoch 9424/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 530.2462 - val_loss: 544.0967\n",
            "Epoch 9425/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 507.1464 - val_loss: 463.6114\n",
            "Epoch 9426/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 587.6767 - val_loss: 448.8371\n",
            "Epoch 9427/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 502.6534 - val_loss: 441.5364\n",
            "Epoch 9428/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 420.1242 - val_loss: 510.5899\n",
            "Epoch 9429/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 508.6954 - val_loss: 493.4638\n",
            "Epoch 9430/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 547.8285 - val_loss: 467.7554\n",
            "Epoch 9431/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 434.2427 - val_loss: 488.4620\n",
            "Epoch 9432/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 606.9203 - val_loss: 648.2267\n",
            "Epoch 9433/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 451.7906 - val_loss: 464.0333\n",
            "Epoch 9434/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 458.2536 - val_loss: 477.4144\n",
            "Epoch 9435/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 472.5336 - val_loss: 450.0209\n",
            "Epoch 9436/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 484.4922 - val_loss: 422.2018\n",
            "Epoch 9437/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 420.9541 - val_loss: 454.5385\n",
            "Epoch 9438/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 472.5512 - val_loss: 474.9502\n",
            "Epoch 9439/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 458.1466 - val_loss: 512.5856\n",
            "Epoch 9440/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 408.5112 - val_loss: 431.8663\n",
            "Epoch 9441/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 474.7163 - val_loss: 508.9539\n",
            "Epoch 9442/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 483.8040 - val_loss: 588.0242\n",
            "Epoch 9443/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 552.4898 - val_loss: 444.5353\n",
            "Epoch 9444/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 411.0161 - val_loss: 502.6351\n",
            "Epoch 9445/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 463.7893 - val_loss: 497.3033\n",
            "Epoch 9446/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 449.3120 - val_loss: 444.6728\n",
            "Epoch 9447/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 464.1121 - val_loss: 437.9044\n",
            "Epoch 9448/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 477.5202 - val_loss: 426.4171\n",
            "Epoch 9449/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 460.8939 - val_loss: 409.8887\n",
            "Epoch 9450/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 459.6244 - val_loss: 411.1860\n",
            "Epoch 9451/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 449.3176 - val_loss: 415.8619\n",
            "Epoch 9452/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 387.7142 - val_loss: 449.5941\n",
            "Epoch 9453/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 499.4142 - val_loss: 465.3972\n",
            "Epoch 9454/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 476.0958 - val_loss: 419.8441\n",
            "Epoch 9455/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 435.6117 - val_loss: 402.0264\n",
            "Epoch 9456/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 455.4697 - val_loss: 459.5337\n",
            "Epoch 9457/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 406.9707 - val_loss: 420.3534\n",
            "Epoch 9458/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 380.3781 - val_loss: 486.6584\n",
            "Epoch 9459/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 487.3543 - val_loss: 418.7877\n",
            "Epoch 9460/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 408.6001 - val_loss: 405.4641\n",
            "Epoch 9461/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 399.4186 - val_loss: 486.2296\n",
            "Epoch 9462/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 396.5636 - val_loss: 491.1491\n",
            "Epoch 9463/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 464.5980 - val_loss: 426.6823\n",
            "Epoch 9464/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 409.6167 - val_loss: 418.2000\n",
            "Epoch 9465/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 490.8731 - val_loss: 435.4582\n",
            "Epoch 9466/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 402.2951 - val_loss: 412.9992\n",
            "Epoch 9467/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 494.1132 - val_loss: 409.5312\n",
            "Epoch 9468/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 399.4980 - val_loss: 456.2510\n",
            "Epoch 9469/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 435.4075 - val_loss: 424.3626\n",
            "Epoch 9470/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 397.0166 - val_loss: 421.3266\n",
            "Epoch 9471/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 473.6481 - val_loss: 608.6873\n",
            "Epoch 9472/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 485.5154 - val_loss: 409.5894\n",
            "Epoch 9473/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 406.8027 - val_loss: 441.3474\n",
            "Epoch 9474/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 440.8587 - val_loss: 392.0211\n",
            "Epoch 9475/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 446.6909 - val_loss: 487.4755\n",
            "Epoch 9476/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 418.8346 - val_loss: 401.5291\n",
            "Epoch 9477/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 416.0714 - val_loss: 416.4121\n",
            "Epoch 9478/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 428.7545 - val_loss: 441.0891\n",
            "Epoch 9479/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 428.6251 - val_loss: 433.0434\n",
            "Epoch 9480/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 408.1890 - val_loss: 425.9731\n",
            "Epoch 9481/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 470.8008 - val_loss: 516.0765\n",
            "Epoch 9482/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 538.4868 - val_loss: 463.8467\n",
            "Epoch 9483/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 444.6189 - val_loss: 461.9699\n",
            "Epoch 9484/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 481.0525 - val_loss: 457.9401\n",
            "Epoch 9485/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 497.7300 - val_loss: 517.9077\n",
            "Epoch 9486/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 432.9533 - val_loss: 422.3786\n",
            "Epoch 9487/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 430.0112 - val_loss: 390.1976\n",
            "Epoch 9488/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 420.8886 - val_loss: 438.3189\n",
            "Epoch 9489/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 418.6840 - val_loss: 434.3449\n",
            "Epoch 9490/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 470.7460 - val_loss: 523.9214\n",
            "Epoch 9491/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 433.7698 - val_loss: 437.8615\n",
            "Epoch 9492/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 422.1775 - val_loss: 505.3621\n",
            "Epoch 9493/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 495.3504 - val_loss: 484.3234\n",
            "Epoch 9494/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 429.0317 - val_loss: 422.9710\n",
            "Epoch 9495/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 432.2899 - val_loss: 413.2021\n",
            "Epoch 9496/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 413.5061 - val_loss: 458.4736\n",
            "Epoch 9497/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 450.6137 - val_loss: 398.0551\n",
            "Epoch 9498/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 400.3289 - val_loss: 492.8607\n",
            "Epoch 9499/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 446.9650 - val_loss: 454.1517\n",
            "Epoch 9500/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 391.8559 - val_loss: 436.5838\n",
            "Epoch 9501/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 451.4769 - val_loss: 427.4331\n",
            "Epoch 9502/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 459.8589 - val_loss: 451.7937\n",
            "Epoch 9503/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 438.4141 - val_loss: 494.3068\n",
            "Epoch 9504/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 473.2768 - val_loss: 512.4538\n",
            "Epoch 9505/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 418.1830 - val_loss: 491.2265\n",
            "Epoch 9506/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 499.7678 - val_loss: 533.9379\n",
            "Epoch 9507/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 497.4158 - val_loss: 467.3525\n",
            "Epoch 9508/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 439.7572 - val_loss: 463.0152\n",
            "Epoch 9509/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 438.2029 - val_loss: 483.2579\n",
            "Epoch 9510/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 537.8510 - val_loss: 425.5131\n",
            "Epoch 9511/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 445.6221 - val_loss: 487.9034\n",
            "Epoch 9512/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 485.9880 - val_loss: 449.9272\n",
            "Epoch 9513/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 464.1940 - val_loss: 520.1013\n",
            "Epoch 9514/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 494.8627 - val_loss: 491.2165\n",
            "Epoch 9515/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 481.9648 - val_loss: 432.7607\n",
            "Epoch 9516/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 405.7681 - val_loss: 552.5151\n",
            "Epoch 9517/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 478.7963 - val_loss: 459.0614\n",
            "Epoch 9518/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 457.5887 - val_loss: 475.3684\n",
            "Epoch 9519/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 463.0149 - val_loss: 465.9903\n",
            "Epoch 9520/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 479.0533 - val_loss: 531.6788\n",
            "Epoch 9521/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 484.6983 - val_loss: 535.4542\n",
            "Epoch 9522/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 449.9341 - val_loss: 503.8507\n",
            "Epoch 9523/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 495.0256 - val_loss: 473.0992\n",
            "Epoch 9524/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 478.3822 - val_loss: 500.2174\n",
            "Epoch 9525/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 470.6882 - val_loss: 487.0353\n",
            "Epoch 9526/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 513.6527 - val_loss: 483.8484\n",
            "Epoch 9527/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 459.3344 - val_loss: 557.2851\n",
            "Epoch 9528/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 522.4551 - val_loss: 500.8548\n",
            "Epoch 9529/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 486.4105 - val_loss: 528.4753\n",
            "Epoch 9530/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 482.0184 - val_loss: 445.0940\n",
            "Epoch 9531/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 476.4177 - val_loss: 431.5669\n",
            "Epoch 9532/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 420.4061 - val_loss: 463.0857\n",
            "Epoch 9533/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 483.9748 - val_loss: 428.1291\n",
            "Epoch 9534/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 471.3186 - val_loss: 496.9229\n",
            "Epoch 9535/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 423.9658 - val_loss: 507.2476\n",
            "Epoch 9536/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 492.3200 - val_loss: 456.2540\n",
            "Epoch 9537/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 463.6671 - val_loss: 500.1873\n",
            "Epoch 9538/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 454.6234 - val_loss: 464.5821\n",
            "Epoch 9539/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 515.4451 - val_loss: 495.4208\n",
            "Epoch 9540/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 463.6535 - val_loss: 509.3554\n",
            "Epoch 9541/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 452.8118 - val_loss: 440.7402\n",
            "Epoch 9542/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 454.8159 - val_loss: 466.9192\n",
            "Epoch 9543/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 482.7405 - val_loss: 428.7068\n",
            "Epoch 9544/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 389.0343 - val_loss: 450.6881\n",
            "Epoch 9545/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 468.3628 - val_loss: 478.2083\n",
            "Epoch 9546/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 499.7728 - val_loss: 557.0023\n",
            "Epoch 9547/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 510.7605 - val_loss: 431.6380\n",
            "Epoch 9548/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 427.9193 - val_loss: 597.4406\n",
            "Epoch 9549/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 676.5648 - val_loss: 570.3546\n",
            "Epoch 9550/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 601.6045 - val_loss: 811.5501\n",
            "Epoch 9551/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 888.7416 - val_loss: 921.6006\n",
            "Epoch 9552/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 889.9930 - val_loss: 1044.0905\n",
            "Epoch 9553/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 1175.4829 - val_loss: 1102.5588\n",
            "Epoch 9554/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 999.5433 - val_loss: 1038.2544\n",
            "Epoch 9555/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 1010.2195 - val_loss: 841.3390\n",
            "Epoch 9556/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 869.0425 - val_loss: 697.6490\n",
            "Epoch 9557/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 665.3815 - val_loss: 892.7694\n",
            "Epoch 9558/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 702.7848 - val_loss: 691.7261\n",
            "Epoch 9559/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 664.7313 - val_loss: 684.1035\n",
            "Epoch 9560/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 687.6219 - val_loss: 677.0564\n",
            "Epoch 9561/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 744.2212 - val_loss: 578.3766\n",
            "Epoch 9562/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 721.7782 - val_loss: 625.8791\n",
            "Epoch 9563/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 745.5845 - val_loss: 635.9330\n",
            "Epoch 9564/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 623.5634 - val_loss: 598.3304\n",
            "Epoch 9565/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 595.9087 - val_loss: 687.8390\n",
            "Epoch 9566/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 643.1113 - val_loss: 566.5402\n",
            "Epoch 9567/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 637.0590 - val_loss: 611.9337\n",
            "Epoch 9568/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 651.4811 - val_loss: 591.5500\n",
            "Epoch 9569/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 533.8213 - val_loss: 629.8073\n",
            "Epoch 9570/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 541.4614 - val_loss: 599.5556\n",
            "Epoch 9571/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 723.3356 - val_loss: 566.8217\n",
            "Epoch 9572/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 610.6659 - val_loss: 545.7720\n",
            "Epoch 9573/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 548.8133 - val_loss: 494.3297\n",
            "Epoch 9574/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 517.8299 - val_loss: 544.8964\n",
            "Epoch 9575/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 510.0384 - val_loss: 483.5043\n",
            "Epoch 9576/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 411.6229 - val_loss: 496.2447\n",
            "Epoch 9577/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 496.7720 - val_loss: 612.6441\n",
            "Epoch 9578/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 663.7403 - val_loss: 513.6770\n",
            "Epoch 9579/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 539.2506 - val_loss: 537.5425\n",
            "Epoch 9580/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 513.8255 - val_loss: 481.5950\n",
            "Epoch 9581/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 516.9717 - val_loss: 472.3379\n",
            "Epoch 9582/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 553.4876 - val_loss: 531.2871\n",
            "Epoch 9583/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 483.4536 - val_loss: 463.6134\n",
            "Epoch 9584/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 402.9432 - val_loss: 536.2693\n",
            "Epoch 9585/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 469.8856 - val_loss: 462.6679\n",
            "Epoch 9586/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 441.0632 - val_loss: 496.5605\n",
            "Epoch 9587/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 492.2705 - val_loss: 436.4990\n",
            "Epoch 9588/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 409.3656 - val_loss: 458.7321\n",
            "Epoch 9589/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 414.3405 - val_loss: 493.1971\n",
            "Epoch 9590/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 437.6287 - val_loss: 428.2537\n",
            "Epoch 9591/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 452.6478 - val_loss: 434.6291\n",
            "Epoch 9592/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 466.8880 - val_loss: 446.1439\n",
            "Epoch 9593/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 409.5895 - val_loss: 447.2771\n",
            "Epoch 9594/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 534.2177 - val_loss: 428.0292\n",
            "Epoch 9595/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 461.4567 - val_loss: 461.7713\n",
            "Epoch 9596/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 587.7521 - val_loss: 508.3021\n",
            "Epoch 9597/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 468.7610 - val_loss: 538.1674\n",
            "Epoch 9598/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 434.7806 - val_loss: 422.0540\n",
            "Epoch 9599/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 439.8341 - val_loss: 514.4590\n",
            "Epoch 9600/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 456.2366 - val_loss: 448.4835\n",
            "Epoch 9601/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 441.4340 - val_loss: 431.6186\n",
            "Epoch 9602/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 417.7317 - val_loss: 442.2768\n",
            "Epoch 9603/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 509.8099 - val_loss: 531.2238\n",
            "Epoch 9604/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 423.5675 - val_loss: 491.4837\n",
            "Epoch 9605/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 453.6478 - val_loss: 430.2556\n",
            "Epoch 9606/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 476.7447 - val_loss: 469.9158\n",
            "Epoch 9607/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 503.1581 - val_loss: 455.0702\n",
            "Epoch 9608/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 481.8783 - val_loss: 553.9407\n",
            "Epoch 9609/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 427.1499 - val_loss: 442.0987\n",
            "Epoch 9610/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 404.9805 - val_loss: 413.5473\n",
            "Epoch 9611/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 448.8267 - val_loss: 467.2651\n",
            "Epoch 9612/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 386.2243 - val_loss: 430.3686\n",
            "Epoch 9613/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 398.4200 - val_loss: 495.7475\n",
            "Epoch 9614/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 446.7811 - val_loss: 485.0635\n",
            "Epoch 9615/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 521.3532 - val_loss: 445.5836\n",
            "Epoch 9616/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 382.2877 - val_loss: 407.2483\n",
            "Epoch 9617/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 398.0174 - val_loss: 404.0773\n",
            "Epoch 9618/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 450.7390 - val_loss: 380.9517\n",
            "Epoch 9619/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 362.4681 - val_loss: 421.8946\n",
            "Epoch 9620/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 472.4577 - val_loss: 490.3482\n",
            "Epoch 9621/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 391.2316 - val_loss: 417.7614\n",
            "Epoch 9622/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 414.8071 - val_loss: 451.7788\n",
            "Epoch 9623/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 484.3048 - val_loss: 536.4776\n",
            "Epoch 9624/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 449.0967 - val_loss: 444.6552\n",
            "Epoch 9625/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 446.9351 - val_loss: 416.4040\n",
            "Epoch 9626/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 421.4691 - val_loss: 495.2607\n",
            "Epoch 9627/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 522.3623 - val_loss: 428.0131\n",
            "Epoch 9628/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 498.0351 - val_loss: 495.6235\n",
            "Epoch 9629/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 553.8584 - val_loss: 419.8420\n",
            "Epoch 9630/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 399.3909 - val_loss: 395.8054\n",
            "Epoch 9631/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 394.1857 - val_loss: 445.1328\n",
            "Epoch 9632/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 472.7120 - val_loss: 424.9929\n",
            "Epoch 9633/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 482.3829 - val_loss: 466.0415\n",
            "Epoch 9634/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 444.0706 - val_loss: 477.6707\n",
            "Epoch 9635/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 450.8393 - val_loss: 429.6486\n",
            "Epoch 9636/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 407.8316 - val_loss: 403.0091\n",
            "Epoch 9637/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 438.5185 - val_loss: 411.8673\n",
            "Epoch 9638/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 485.5842 - val_loss: 460.2740\n",
            "Epoch 9639/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 555.1003 - val_loss: 428.2741\n",
            "Epoch 9640/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 433.3784 - val_loss: 390.5140\n",
            "Epoch 9641/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 459.5731 - val_loss: 404.7068\n",
            "Epoch 9642/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 402.2902 - val_loss: 399.6074\n",
            "Epoch 9643/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 434.6831 - val_loss: 415.8441\n",
            "Epoch 9644/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 410.6817 - val_loss: 429.3528\n",
            "Epoch 9645/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 471.1469 - val_loss: 436.2456\n",
            "Epoch 9646/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 452.8370 - val_loss: 455.6558\n",
            "Epoch 9647/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 455.4536 - val_loss: 454.1607\n",
            "Epoch 9648/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 545.6936 - val_loss: 469.6250\n",
            "Epoch 9649/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 432.8878 - val_loss: 530.6842\n",
            "Epoch 9650/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 537.1631 - val_loss: 395.9255\n",
            "Epoch 9651/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 416.7666 - val_loss: 434.1757\n",
            "Epoch 9652/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 443.2640 - val_loss: 547.1507\n",
            "Epoch 9653/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 520.4675 - val_loss: 378.5100\n",
            "Epoch 9654/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 400.5877 - val_loss: 446.1027\n",
            "Epoch 9655/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 407.5908 - val_loss: 379.9340\n",
            "Epoch 9656/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 418.7918 - val_loss: 396.9925\n",
            "Epoch 9657/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 441.6517 - val_loss: 444.1704\n",
            "Epoch 9658/10000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 414.3834 - val_loss: 467.5746\n",
            "Epoch 9659/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 417.4221 - val_loss: 414.5427\n",
            "Epoch 9660/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 457.2794 - val_loss: 434.3066\n",
            "Epoch 9661/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 462.1159 - val_loss: 414.3319\n",
            "Epoch 9662/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 419.5082 - val_loss: 477.5865\n",
            "Epoch 9663/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 501.7581 - val_loss: 437.7292\n",
            "Epoch 9664/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 439.2644 - val_loss: 441.6507\n",
            "Epoch 9665/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 438.8110 - val_loss: 519.6274\n",
            "Epoch 9666/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 524.5585 - val_loss: 451.0731\n",
            "Epoch 9667/10000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 460.6355 - val_loss: 435.4712\n",
            "Epoch 9668/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 472.0742 - val_loss: 450.4495\n",
            "Epoch 9669/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 462.0460 - val_loss: 535.9402\n",
            "Epoch 9670/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 541.1159 - val_loss: 455.7179\n",
            "Epoch 9671/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 440.3280 - val_loss: 469.8031\n",
            "Epoch 9672/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 444.9838 - val_loss: 415.1891\n",
            "Epoch 9673/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 430.5482 - val_loss: 449.5677\n",
            "Epoch 9674/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 456.4142 - val_loss: 401.0135\n",
            "Epoch 9675/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 429.9603 - val_loss: 429.7717\n",
            "Epoch 9676/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 517.5006 - val_loss: 500.4949\n",
            "Epoch 9677/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 493.1256 - val_loss: 529.5130\n",
            "Epoch 9678/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 587.5140 - val_loss: 430.6980\n",
            "Epoch 9679/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 457.8759 - val_loss: 480.5725\n",
            "Epoch 9680/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 417.5619 - val_loss: 512.2805\n",
            "Epoch 9681/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 437.6883 - val_loss: 426.2806\n",
            "Epoch 9682/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 468.3686 - val_loss: 441.9656\n",
            "Epoch 9683/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 478.0204 - val_loss: 496.1603\n",
            "Epoch 9684/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 529.2960 - val_loss: 474.5144\n",
            "Epoch 9685/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 491.3918 - val_loss: 503.3047\n",
            "Epoch 9686/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 540.2093 - val_loss: 635.2656\n",
            "Epoch 9687/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 601.1725 - val_loss: 727.9247\n",
            "Epoch 9688/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 558.8929 - val_loss: 503.3356\n",
            "Epoch 9689/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 459.8038 - val_loss: 515.5109\n",
            "Epoch 9690/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 530.5952 - val_loss: 563.1219\n",
            "Epoch 9691/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 621.1074 - val_loss: 525.1880\n",
            "Epoch 9692/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 559.6141 - val_loss: 518.8413\n",
            "Epoch 9693/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 548.5095 - val_loss: 486.2202\n",
            "Epoch 9694/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 505.4702 - val_loss: 496.5124\n",
            "Epoch 9695/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 453.7096 - val_loss: 473.6704\n",
            "Epoch 9696/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 499.9811 - val_loss: 443.5167\n",
            "Epoch 9697/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 446.2822 - val_loss: 458.9631\n",
            "Epoch 9698/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 440.4502 - val_loss: 475.5633\n",
            "Epoch 9699/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 429.0853 - val_loss: 516.1115\n",
            "Epoch 9700/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 585.6997 - val_loss: 462.5209\n",
            "Epoch 9701/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 488.4004 - val_loss: 497.4692\n",
            "Epoch 9702/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 454.6693 - val_loss: 675.8745\n",
            "Epoch 9703/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 556.3927 - val_loss: 477.5226\n",
            "Epoch 9704/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 469.9606 - val_loss: 602.5244\n",
            "Epoch 9705/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 492.5889 - val_loss: 719.2366\n",
            "Epoch 9706/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 694.4734 - val_loss: 632.3097\n",
            "Epoch 9707/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 644.3777 - val_loss: 602.4627\n",
            "Epoch 9708/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 714.8150 - val_loss: 542.5096\n",
            "Epoch 9709/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 561.8167 - val_loss: 450.7473\n",
            "Epoch 9710/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 448.1049 - val_loss: 555.0536\n",
            "Epoch 9711/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 469.0213 - val_loss: 429.0315\n",
            "Epoch 9712/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 432.6782 - val_loss: 589.1631\n",
            "Epoch 9713/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 515.2223 - val_loss: 548.5328\n",
            "Epoch 9714/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 489.1628 - val_loss: 624.3394\n",
            "Epoch 9715/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 717.7008 - val_loss: 559.1025\n",
            "Epoch 9716/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 599.1225 - val_loss: 557.1008\n",
            "Epoch 9717/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 477.8721 - val_loss: 445.8641\n",
            "Epoch 9718/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 543.7678 - val_loss: 542.4918\n",
            "Epoch 9719/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 411.5516 - val_loss: 510.4936\n",
            "Epoch 9720/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 561.2688 - val_loss: 467.5699\n",
            "Epoch 9721/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 397.4728 - val_loss: 411.1041\n",
            "Epoch 9722/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 363.7747 - val_loss: 432.2957\n",
            "Epoch 9723/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 515.0140 - val_loss: 461.1975\n",
            "Epoch 9724/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 452.7255 - val_loss: 432.4218\n",
            "Epoch 9725/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 451.6594 - val_loss: 419.5239\n",
            "Epoch 9726/10000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 427.0248 - val_loss: 437.9052\n",
            "Epoch 9727/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 425.7976 - val_loss: 438.1121\n",
            "Epoch 9728/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 421.8374 - val_loss: 454.1274\n",
            "Epoch 9729/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 457.2866 - val_loss: 437.1484\n",
            "Epoch 9730/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 463.2553 - val_loss: 424.7413\n",
            "Epoch 9731/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 450.0426 - val_loss: 429.8716\n",
            "Epoch 9732/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 449.1672 - val_loss: 523.2960\n",
            "Epoch 9733/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 413.4227 - val_loss: 401.5357\n",
            "Epoch 9734/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 472.2984 - val_loss: 431.6361\n",
            "Epoch 9735/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 445.8000 - val_loss: 434.7342\n",
            "Epoch 9736/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 435.7214 - val_loss: 433.8430\n",
            "Epoch 9737/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 395.2940 - val_loss: 446.7115\n",
            "Epoch 9738/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 480.9859 - val_loss: 441.1668\n",
            "Epoch 9739/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 469.8807 - val_loss: 505.7856\n",
            "Epoch 9740/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 402.7488 - val_loss: 420.0490\n",
            "Epoch 9741/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 450.5360 - val_loss: 505.1913\n",
            "Epoch 9742/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 455.6393 - val_loss: 460.0143\n",
            "Epoch 9743/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 427.3697 - val_loss: 435.2456\n",
            "Epoch 9744/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 467.6229 - val_loss: 412.7423\n",
            "Epoch 9745/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 459.4446 - val_loss: 413.4708\n",
            "Epoch 9746/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 471.2937 - val_loss: 436.6080\n",
            "Epoch 9747/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 415.7316 - val_loss: 520.5164\n",
            "Epoch 9748/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 464.3980 - val_loss: 448.4017\n",
            "Epoch 9749/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 453.4806 - val_loss: 430.4511\n",
            "Epoch 9750/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 471.6407 - val_loss: 442.7560\n",
            "Epoch 9751/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 417.8267 - val_loss: 454.5844\n",
            "Epoch 9752/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 390.9067 - val_loss: 414.1501\n",
            "Epoch 9753/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 452.8239 - val_loss: 553.4533\n",
            "Epoch 9754/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 441.2280 - val_loss: 480.0545\n",
            "Epoch 9755/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 498.8001 - val_loss: 461.4099\n",
            "Epoch 9756/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 428.2690 - val_loss: 484.4879\n",
            "Epoch 9757/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 465.8350 - val_loss: 452.1653\n",
            "Epoch 9758/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 442.7012 - val_loss: 477.2301\n",
            "Epoch 9759/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 451.9683 - val_loss: 403.9644\n",
            "Epoch 9760/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 425.9381 - val_loss: 387.8839\n",
            "Epoch 9761/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 394.9792 - val_loss: 395.6766\n",
            "Epoch 9762/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 438.6265 - val_loss: 508.4510\n",
            "Epoch 9763/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 445.6665 - val_loss: 464.0685\n",
            "Epoch 9764/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 472.8713 - val_loss: 513.4649\n",
            "Epoch 9765/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 431.2249 - val_loss: 553.4974\n",
            "Epoch 9766/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 517.7612 - val_loss: 486.2505\n",
            "Epoch 9767/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 498.4369 - val_loss: 595.8790\n",
            "Epoch 9768/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 645.0191 - val_loss: 526.9154\n",
            "Epoch 9769/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 472.2273 - val_loss: 495.5540\n",
            "Epoch 9770/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 481.6386 - val_loss: 587.7416\n",
            "Epoch 9771/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 589.0793 - val_loss: 521.1486\n",
            "Epoch 9772/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 605.5151 - val_loss: 714.8410\n",
            "Epoch 9773/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 805.5760 - val_loss: 607.3738\n",
            "Epoch 9774/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 533.5379 - val_loss: 610.1663\n",
            "Epoch 9775/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 533.1164 - val_loss: 883.4788\n",
            "Epoch 9776/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 728.3966 - val_loss: 579.6548\n",
            "Epoch 9777/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 463.0141 - val_loss: 496.0408\n",
            "Epoch 9778/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 488.6328 - val_loss: 516.3983\n",
            "Epoch 9779/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 503.7656 - val_loss: 644.5162\n",
            "Epoch 9780/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 758.8520 - val_loss: 934.6140\n",
            "Epoch 9781/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 855.0772 - val_loss: 921.3662\n",
            "Epoch 9782/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 811.3591 - val_loss: 776.4701\n",
            "Epoch 9783/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 791.4662 - val_loss: 1097.5365\n",
            "Epoch 9784/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1021.6595 - val_loss: 773.3975\n",
            "Epoch 9785/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 821.4124 - val_loss: 669.2402\n",
            "Epoch 9786/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 634.2636 - val_loss: 654.3723\n",
            "Epoch 9787/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 701.1558 - val_loss: 624.7669\n",
            "Epoch 9788/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 551.7347 - val_loss: 593.6104\n",
            "Epoch 9789/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 583.0316 - val_loss: 734.9704\n",
            "Epoch 9790/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 755.8817 - val_loss: 629.0634\n",
            "Epoch 9791/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 622.8706 - val_loss: 567.2427\n",
            "Epoch 9792/10000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 628.0307 - val_loss: 581.6452\n",
            "Epoch 9793/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 621.1703 - val_loss: 605.8112\n",
            "Epoch 9794/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 649.8720 - val_loss: 550.6562\n",
            "Epoch 9795/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 537.7508 - val_loss: 553.1111\n",
            "Epoch 9796/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 515.6921 - val_loss: 515.3578\n",
            "Epoch 9797/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 624.7895 - val_loss: 498.6244\n",
            "Epoch 9798/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 534.8418 - val_loss: 493.7347\n",
            "Epoch 9799/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 479.4370 - val_loss: 527.9891\n",
            "Epoch 9800/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 494.7154 - val_loss: 604.6207\n",
            "Epoch 9801/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 596.3937 - val_loss: 692.4214\n",
            "Epoch 9802/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 666.3655 - val_loss: 647.7297\n",
            "Epoch 9803/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 656.5001 - val_loss: 976.4678\n",
            "Epoch 9804/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 762.1498 - val_loss: 597.3241\n",
            "Epoch 9805/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 597.2270 - val_loss: 595.0240\n",
            "Epoch 9806/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 573.9729 - val_loss: 535.4796\n",
            "Epoch 9807/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 540.2707 - val_loss: 502.9188\n",
            "Epoch 9808/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 544.4421 - val_loss: 528.6435\n",
            "Epoch 9809/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 491.4658 - val_loss: 513.3954\n",
            "Epoch 9810/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 476.8300 - val_loss: 547.5662\n",
            "Epoch 9811/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 506.1820 - val_loss: 549.5502\n",
            "Epoch 9812/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 548.2561 - val_loss: 540.0760\n",
            "Epoch 9813/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 502.6533 - val_loss: 505.8274\n",
            "Epoch 9814/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 495.8871 - val_loss: 502.5206\n",
            "Epoch 9815/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 458.4762 - val_loss: 608.3156\n",
            "Epoch 9816/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 869.8515 - val_loss: 1021.6368\n",
            "Epoch 9817/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1086.6296 - val_loss: 888.0369\n",
            "Epoch 9818/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 784.7619 - val_loss: 671.4736\n",
            "Epoch 9819/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 652.9526 - val_loss: 597.3301\n",
            "Epoch 9820/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 516.6172 - val_loss: 514.4531\n",
            "Epoch 9821/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 509.8952 - val_loss: 669.7803\n",
            "Epoch 9822/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 631.6546 - val_loss: 617.3649\n",
            "Epoch 9823/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 581.7716 - val_loss: 728.8488\n",
            "Epoch 9824/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 700.9341 - val_loss: 581.3387\n",
            "Epoch 9825/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 555.8630 - val_loss: 513.2026\n",
            "Epoch 9826/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 481.0664 - val_loss: 513.0212\n",
            "Epoch 9827/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 536.3537 - val_loss: 501.8853\n",
            "Epoch 9828/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 565.0750 - val_loss: 485.0298\n",
            "Epoch 9829/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 541.7048 - val_loss: 561.3196\n",
            "Epoch 9830/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 427.9109 - val_loss: 473.4753\n",
            "Epoch 9831/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 482.6921 - val_loss: 522.8558\n",
            "Epoch 9832/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 445.4109 - val_loss: 510.1234\n",
            "Epoch 9833/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 523.0143 - val_loss: 492.7585\n",
            "Epoch 9834/10000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 577.3881 - val_loss: 601.4990\n",
            "Epoch 9835/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 528.8211 - val_loss: 579.4397\n",
            "Epoch 9836/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 512.5075 - val_loss: 595.6475\n",
            "Epoch 9837/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 621.3332 - val_loss: 537.6340\n",
            "Epoch 9838/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 619.9259 - val_loss: 538.5278\n",
            "Epoch 9839/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 557.7916 - val_loss: 597.1219\n",
            "Epoch 9840/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 530.2128 - val_loss: 638.3608\n",
            "Epoch 9841/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 542.1839 - val_loss: 514.4848\n",
            "Epoch 9842/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 590.4390 - val_loss: 525.1908\n",
            "Epoch 9843/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 562.7170 - val_loss: 487.3148\n",
            "Epoch 9844/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 445.6299 - val_loss: 507.3668\n",
            "Epoch 9845/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 574.3436 - val_loss: 637.0858\n",
            "Epoch 9846/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 483.3760 - val_loss: 514.8895\n",
            "Epoch 9847/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 501.6447 - val_loss: 516.9658\n",
            "Epoch 9848/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 462.6932 - val_loss: 630.1910\n",
            "Epoch 9849/10000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 536.7836 - val_loss: 512.5884\n",
            "Epoch 9850/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 529.4076 - val_loss: 511.9627\n",
            "Epoch 9851/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 514.0447 - val_loss: 474.8932\n",
            "Epoch 9852/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 457.5109 - val_loss: 489.5840\n",
            "Epoch 9853/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 479.3978 - val_loss: 570.0078\n",
            "Epoch 9854/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 518.4351 - val_loss: 478.0916\n",
            "Epoch 9855/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 506.3836 - val_loss: 470.5988\n",
            "Epoch 9856/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 511.6776 - val_loss: 478.0780\n",
            "Epoch 9857/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 433.7011 - val_loss: 473.5528\n",
            "Epoch 9858/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 491.9345 - val_loss: 422.3649\n",
            "Epoch 9859/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 453.7027 - val_loss: 448.6603\n",
            "Epoch 9860/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 488.1010 - val_loss: 458.7375\n",
            "Epoch 9861/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 490.8187 - val_loss: 499.0281\n",
            "Epoch 9862/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 567.9009 - val_loss: 532.7117\n",
            "Epoch 9863/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 508.2069 - val_loss: 466.5662\n",
            "Epoch 9864/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 437.5831 - val_loss: 452.4831\n",
            "Epoch 9865/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 416.9465 - val_loss: 536.4864\n",
            "Epoch 9866/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 483.3437 - val_loss: 586.8799\n",
            "Epoch 9867/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 551.6847 - val_loss: 468.7076\n",
            "Epoch 9868/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 451.5531 - val_loss: 521.4317\n",
            "Epoch 9869/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 508.4140 - val_loss: 447.8590\n",
            "Epoch 9870/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 512.2350 - val_loss: 474.4566\n",
            "Epoch 9871/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 481.1277 - val_loss: 418.8112\n",
            "Epoch 9872/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 477.0815 - val_loss: 548.7385\n",
            "Epoch 9873/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 425.9876 - val_loss: 427.6413\n",
            "Epoch 9874/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 432.3700 - val_loss: 460.7450\n",
            "Epoch 9875/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 386.6192 - val_loss: 393.4348\n",
            "Epoch 9876/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 462.2393 - val_loss: 545.8412\n",
            "Epoch 9877/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 439.1994 - val_loss: 497.4438\n",
            "Epoch 9878/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 504.0975 - val_loss: 491.2025\n",
            "Epoch 9879/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 515.8622 - val_loss: 474.2863\n",
            "Epoch 9880/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 441.7555 - val_loss: 496.2317\n",
            "Epoch 9881/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 473.9672 - val_loss: 476.0428\n",
            "Epoch 9882/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 521.7446 - val_loss: 469.1894\n",
            "Epoch 9883/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 475.2357 - val_loss: 426.0298\n",
            "Epoch 9884/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 438.5023 - val_loss: 414.6674\n",
            "Epoch 9885/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 418.6257 - val_loss: 528.4058\n",
            "Epoch 9886/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 444.0259 - val_loss: 470.0410\n",
            "Epoch 9887/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 470.3212 - val_loss: 439.0625\n",
            "Epoch 9888/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 486.4082 - val_loss: 446.7725\n",
            "Epoch 9889/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 470.9058 - val_loss: 454.4897\n",
            "Epoch 9890/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 500.1881 - val_loss: 413.0426\n",
            "Epoch 9891/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 412.8976 - val_loss: 448.4314\n",
            "Epoch 9892/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 468.7598 - val_loss: 487.8453\n",
            "Epoch 9893/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 483.4721 - val_loss: 482.8164\n",
            "Epoch 9894/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 524.7553 - val_loss: 453.6129\n",
            "Epoch 9895/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 477.6124 - val_loss: 434.1327\n",
            "Epoch 9896/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 434.6400 - val_loss: 409.3475\n",
            "Epoch 9897/10000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 483.8927 - val_loss: 438.9266\n",
            "Epoch 9898/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 463.4892 - val_loss: 451.8291\n",
            "Epoch 9899/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 480.9268 - val_loss: 409.0094\n",
            "Epoch 9900/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 451.5013 - val_loss: 468.3130\n",
            "Epoch 9901/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 466.4677 - val_loss: 431.7734\n",
            "Epoch 9902/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 437.9853 - val_loss: 493.6004\n",
            "Epoch 9903/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 486.6537 - val_loss: 464.9223\n",
            "Epoch 9904/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 508.4767 - val_loss: 457.0346\n",
            "Epoch 9905/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 495.4371 - val_loss: 458.7744\n",
            "Epoch 9906/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 430.1207 - val_loss: 475.4658\n",
            "Epoch 9907/10000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 374.3406 - val_loss: 434.2784\n",
            "Epoch 9908/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 431.3666 - val_loss: 399.1391\n",
            "Epoch 9909/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 414.0539 - val_loss: 415.8661\n",
            "Epoch 9910/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 434.7038 - val_loss: 427.9831\n",
            "Epoch 9911/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 475.0041 - val_loss: 439.7504\n",
            "Epoch 9912/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 431.4298 - val_loss: 511.2628\n",
            "Epoch 9913/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 471.1501 - val_loss: 432.0561\n",
            "Epoch 9914/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 476.9240 - val_loss: 430.6387\n",
            "Epoch 9915/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 448.2627 - val_loss: 421.3508\n",
            "Epoch 9916/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 419.4790 - val_loss: 406.9738\n",
            "Epoch 9917/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 423.9917 - val_loss: 494.6248\n",
            "Epoch 9918/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 451.3116 - val_loss: 441.5605\n",
            "Epoch 9919/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 452.6469 - val_loss: 421.9075\n",
            "Epoch 9920/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 394.4520 - val_loss: 402.5636\n",
            "Epoch 9921/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 439.0536 - val_loss: 462.1472\n",
            "Epoch 9922/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 462.6183 - val_loss: 468.2975\n",
            "Epoch 9923/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 454.1678 - val_loss: 454.8793\n",
            "Epoch 9924/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 397.6827 - val_loss: 438.3557\n",
            "Epoch 9925/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 455.8917 - val_loss: 428.4894\n",
            "Epoch 9926/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 574.6277 - val_loss: 524.5427\n",
            "Epoch 9927/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 515.0111 - val_loss: 474.9979\n",
            "Epoch 9928/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 529.8758 - val_loss: 592.0303\n",
            "Epoch 9929/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 576.6412 - val_loss: 489.7492\n",
            "Epoch 9930/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 515.5042 - val_loss: 518.4268\n",
            "Epoch 9931/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 444.5615 - val_loss: 439.3387\n",
            "Epoch 9932/10000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 541.1228 - val_loss: 484.4846\n",
            "Epoch 9933/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 540.1182 - val_loss: 508.1769\n",
            "Epoch 9934/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 558.8606 - val_loss: 487.0368\n",
            "Epoch 9935/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 469.0970 - val_loss: 479.3723\n",
            "Epoch 9936/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 508.7844 - val_loss: 422.4720\n",
            "Epoch 9937/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 601.8101 - val_loss: 533.8971\n",
            "Epoch 9938/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 452.0794 - val_loss: 446.5201\n",
            "Epoch 9939/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 484.4748 - val_loss: 494.5515\n",
            "Epoch 9940/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 514.1196 - val_loss: 465.3735\n",
            "Epoch 9941/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 433.3348 - val_loss: 444.8655\n",
            "Epoch 9942/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 475.0652 - val_loss: 453.3999\n",
            "Epoch 9943/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 539.7047 - val_loss: 530.7300\n",
            "Epoch 9944/10000\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 570.3297 - val_loss: 457.3864\n",
            "Epoch 9945/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 553.1261 - val_loss: 507.7338\n",
            "Epoch 9946/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 593.7934 - val_loss: 670.1507\n",
            "Epoch 9947/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 521.3297 - val_loss: 456.8679\n",
            "Epoch 9948/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 535.2107 - val_loss: 420.8810\n",
            "Epoch 9949/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 457.9465 - val_loss: 519.0229\n",
            "Epoch 9950/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 537.3634 - val_loss: 451.0311\n",
            "Epoch 9951/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 389.5455 - val_loss: 587.2462\n",
            "Epoch 9952/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 429.3168 - val_loss: 509.5622\n",
            "Epoch 9953/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 516.6336 - val_loss: 458.1611\n",
            "Epoch 9954/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 456.4082 - val_loss: 457.9185\n",
            "Epoch 9955/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 538.4054 - val_loss: 451.4318\n",
            "Epoch 9956/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 395.8627 - val_loss: 585.7718\n",
            "Epoch 9957/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 899.2724 - val_loss: 529.7938\n",
            "Epoch 9958/10000\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 425.6711 - val_loss: 578.3668\n",
            "Epoch 9959/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 537.0291 - val_loss: 556.2940\n",
            "Epoch 9960/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 483.5454 - val_loss: 539.1135\n",
            "Epoch 9961/10000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 523.2850 - val_loss: 500.6987\n",
            "Epoch 9962/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 503.5828 - val_loss: 510.4107\n",
            "Epoch 9963/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 554.8936 - val_loss: 492.7160\n",
            "Epoch 9964/10000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 480.8375 - val_loss: 463.2608\n",
            "Epoch 9965/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 448.8015 - val_loss: 545.0832\n",
            "Epoch 9966/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 523.0775 - val_loss: 480.9132\n",
            "Epoch 9967/10000\n",
            "12/12 [==============================] - 1s 71ms/step - loss: 566.5718 - val_loss: 479.4921\n",
            "Epoch 9968/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 457.5249 - val_loss: 543.4597\n",
            "Epoch 9969/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 491.2403 - val_loss: 531.6614\n",
            "Epoch 9970/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 596.2521 - val_loss: 423.9798\n",
            "Epoch 9971/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 410.2011 - val_loss: 509.5814\n",
            "Epoch 9972/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 438.2177 - val_loss: 458.0096\n",
            "Epoch 9973/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 471.1482 - val_loss: 529.2137\n",
            "Epoch 9974/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 486.3036 - val_loss: 462.6724\n",
            "Epoch 9975/10000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 498.5844 - val_loss: 433.1283\n",
            "Epoch 9976/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 525.9932 - val_loss: 471.6321\n",
            "Epoch 9977/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 527.4506 - val_loss: 435.6961\n",
            "Epoch 9978/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 498.6748 - val_loss: 454.9260\n",
            "Epoch 9979/10000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 513.1878 - val_loss: 451.1998\n",
            "Epoch 9980/10000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 491.6480 - val_loss: 618.8964\n",
            "Epoch 9981/10000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 459.6254 - val_loss: 586.6116\n",
            "Epoch 9982/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 558.3437 - val_loss: 576.4494\n",
            "Epoch 9983/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 403.3146 - val_loss: 518.2543\n",
            "Epoch 9984/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 480.0353 - val_loss: 438.9814\n",
            "Epoch 9985/10000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 502.6564 - val_loss: 439.6579\n",
            "Epoch 9986/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 431.5005 - val_loss: 421.0643\n",
            "Epoch 9987/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 437.7559 - val_loss: 442.6888\n",
            "Epoch 9988/10000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 485.4076 - val_loss: 482.0513\n",
            "Epoch 9989/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 408.9170 - val_loss: 542.4457\n",
            "Epoch 9990/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 474.5452 - val_loss: 572.6028\n",
            "Epoch 9991/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 473.1567 - val_loss: 511.5482\n",
            "Epoch 9992/10000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 568.3590 - val_loss: 453.9006\n",
            "Epoch 9993/10000\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 484.8843 - val_loss: 487.1923\n",
            "Epoch 9994/10000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 515.0690 - val_loss: 491.4046\n",
            "Epoch 9995/10000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 486.2896 - val_loss: 440.8000\n",
            "Epoch 9996/10000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 520.2025 - val_loss: 457.8212\n",
            "Epoch 9997/10000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 432.9430 - val_loss: 414.2645\n",
            "Epoch 9998/10000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 381.8571 - val_loss: 497.1884\n",
            "Epoch 9999/10000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 438.8821 - val_loss: 421.9685\n",
            "Epoch 10000/10000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 421.1929 - val_loss: 428.2950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMlcJAHyMHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "130b30e6-f231-4b60-99fa-d8facf17f5e9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training'])\n",
        "plt.legend(['validation'])\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st5kqsO19Q96",
        "outputId": "352cb63f-29a9-4428-cdba-8c3ac6fbd6fc"
      },
      "source": [
        "print(min(history.history['val_loss']))\n",
        "print(history.history['val_loss'].index(min(history.history['val_loss'])))\n",
        "print()\n",
        "print(min(history.history['loss']))\n",
        "print(history.history['loss'].index(min(history.history['loss'])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "378.510009765625\n",
            "9652\n",
            "\n",
            "399.906494140625\n",
            "9653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTcpQhNZYAH"
      },
      "source": [
        "#saving a model\n",
        "\n",
        "model.save(\"covid_prediction.h5\")\n",
        "!cp \"covid_prediction.h5\" \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAfI5HUVapfP",
        "outputId": "d0b33827-92b6-48e0-e4d1-d0aa68cb29d3"
      },
      "source": [
        "#loading a model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/gdrive/My Drive/covid_prediction.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UlZ9xkvTFg3N",
        "outputId": "4a31d817-ff8a-433e-da3e-41fc1a14e4b5"
      },
      "source": [
        "#next day covid cases prediction\n",
        "def predict_next_day(test_data):\n",
        "  test_data = test_data.reshape((1, 14, n_features))\n",
        "  return int(np.round(model.predict(test_data, verbose=1)))\n",
        "\n",
        "Test_X, Test_Y = split_sequence(cases, n)\n",
        "Test_X = np.array(Test_X)\n",
        "Test_Y = np.array(Test_Y)\n",
        "Test_Y = Test_Y.reshape((Test_Y.shape[0], 1, n_features))\n",
        "Test_X = Test_X.reshape((Test_X.shape[0], Test_X.shape[1], n_features))\n",
        "Test_Y = Test_Y.reshape((Test_Y.shape[0], 1, n_features))\n",
        "test_prediction = model.predict(Test_X)\n",
        "input = np.array(cases[-14:])\n",
        "for i in range(0,30):\n",
        "  input = np.append(input, predict_next_day(input[-14:]))\n",
        "\n",
        "\n",
        "close_test = Test_Y.reshape((-1))\n",
        "test_prediction = test_prediction.reshape((-1))\n",
        "\n",
        "absolute_errors = np.abs(np.subtract(close_test, test_prediction))\n",
        "relative_errors = np.divide(absolute_errors, close_test) * 100\n",
        "\n",
        "\n",
        "trace2 = go.Scatter(\n",
        "    x = [i for i in range (0, len(Test_X))],\n",
        "    y = test_prediction,\n",
        "    name = 'Test Prediction',\n",
        "    mode='lines',\n",
        "    line=dict(width=4, color='Green')\n",
        ")\n",
        "trace3 = go.Scatter(\n",
        "    x = [i for i in range (0, len(Test_X))],\n",
        "    y = close_test,\n",
        "    mode='markers+lines',\n",
        "    name = 'Acquired Data'\n",
        ")\n",
        "trace1 = go.Scatter(\n",
        "    x = [i for i in range (len(Test_X)+1, len(Test_X)+1+len(input[14:]))],\n",
        "    y = input[14:],\n",
        "    name = 'Prediction',\n",
        "    mode='lines',\n",
        "    line=dict(width=4, color='Blue')\n",
        ")\n",
        "layout = go.Layout(\n",
        "    title = \"Covid Cases\",\n",
        "    xaxis = {'title' : \"Date\"},\n",
        "    yaxis = {'title' : \"Cases\"}\n",
        ")\n",
        "fig = go.Figure(data=[trace2, trace3, trace1], layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "467\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"338ccc19-880b-4512-b56c-ee4c4ebcc40a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"338ccc19-880b-4512-b56c-ee4c4ebcc40a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '338ccc19-880b-4512-b56c-ee4c4ebcc40a',\n",
              "                        [{\"line\": {\"color\": \"Green\", \"width\": 4}, \"mode\": \"lines\", \"name\": \"Test Prediction\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466], \"y\": [11.241304397583008, 16.843006134033203, 17.569536209106445, 20.47001075744629, 17.87381935119629, 60.5248908996582, 63.66655349731445, 68.84888458251953, 66.38038635253906, 112.7077407836914, 93.97392272949219, 120.72366333007812, 159.3737030029297, 137.4224395751953, 130.69212341308594, 159.76478576660156, 167.52870178222656, 254.154541015625, 241.79132080078125, 208.88385009765625, 271.763671875, 250.76937866210938, 413.66033935546875, 461.97027587890625, 177.8158416748047, 393.0187072753906, 291.5616760253906, 432.8465270996094, 354.4098205566406, 325.6651306152344, 386.5675964355469, 423.8577575683594, 344.58673095703125, 253.4837646484375, 255.9860076904297, 357.0665588378906, 260.35235595703125, 389.8179016113281, 316.89263916015625, 426.6253967285156, 316.45953369140625, 287.7394104003906, 398.4289855957031, 340.0230407714844, 364.1659851074219, 369.1087951660156, 290.9732971191406, 234.54103088378906, 385.1558532714844, 408.3506774902344, 316.1150207519531, 233.76219177246094, 254.26512145996094, 291.3758850097656, 281.9786071777344, 375.7782897949219, 291.6989440917969, 288.4111022949219, 333.6463928222656, 296.4016418457031, 360.4621887207031, 324.2409973144531, 493.50885009765625, 337.3144226074219, 271.0373840332031, 406.6135559082031, 222.40464782714844, 387.2239685058594, 347.79669189453125, 352.1422424316406, 436.5828552246094, 420.4464416503906, 428.01324462890625, 315.720458984375, 357.550048828125, 312.5207214355469, 437.22369384765625, 403.2928771972656, 297.1305236816406, 260.38909912109375, 336.2551574707031, 222.74790954589844, 410.5285949707031, 241.22213745117188, 281.6787414550781, 310.98529052734375, 324.2955322265625, 517.536865234375, 526.8853149414062, 651.3253784179688, 415.8753356933594, 492.7775573730469, 647.371826171875, 412.0774230957031, 394.3145751953125, 283.57684326171875, 263.2570495605469, 274.4830627441406, 382.7455139160156, 298.37994384765625, 400.70758056640625, 311.581298828125, 295.7702331542969, 284.5079650878906, 259.40826416015625, 255.75909423828125, 261.453369140625, 276.230712890625, 293.6606750488281, 193.05418395996094, 284.8737487792969, 230.86410522460938, 331.4726867675781, 359.4497985839844, 267.4490661621094, 302.9659729003906, 261.39324951171875, 247.3993682861328, 316.1526184082031, 267.7873229980469, 238.5879669189453, 207.00477600097656, 260.10870361328125, 354.0494689941406, 292.7702331542969, 282.1990051269531, 315.998291015625, 336.2254333496094, 365.3165283203125, 367.98016357421875, 316.3000793457031, 273.267822265625, 421.8344421386719, 423.6990051269531, 424.20361328125, 463.6446838378906, 596.8642578125, 464.1061706542969, 343.7131652832031, 578.981689453125, 570.4276733398438, 661.3550415039062, 653.8684692382812, 638.750732421875, 484.8512268066406, 688.0003051757812, 783.5779418945312, 681.039306640625, 745.2322998046875, 837.81787109375, 867.1801147460938, 529.9949340820312, 648.5438842773438, 606.3939819335938, 801.906982421875, 844.7568969726562, 846.0907592773438, 678.828857421875, 531.9208984375, 673.5673217773438, 734.6004028320312, 780.7796020507812, 794.3914184570312, 865.1050415039062, 895.6687622070312, 529.7595825195312, 675.72265625, 925.7334594726562, 735.3964233398438, 871.3626098632812, 786.5098266601562, 627.7470092773438, 530.4623413085938, 657.5985717773438, 811.9307250976562, 652.8036499023438, 581.8309936523438, 596.0523681640625, 470.88677978515625, 338.2098388671875, 442.8969421386719, 504.116455078125, 437.0551452636719, 461.4522399902344, 528.1303100585938, 550.1904907226562, 428.530029296875, 363.5628967285156, 693.1310424804688, 611.9890747070312, 820.3817138671875, 771.1094970703125, 872.326904296875, 903.4971313476562, 754.3336791992188, 895.596435546875, 1106.1650390625, 1274.754150390625, 1647.8768310546875, 1799.319580078125, 954.0260620117188, 1202.3839111328125, 1562.185546875, 1947.1651611328125, 2030.11083984375, 2370.072998046875, 2412.390625, 1413.6824951171875, 2028.164306640625, 2451.194580078125, 3280.502685546875, 4322.93798828125, 5357.828125, 5053.3232421875, 3357.51318359375, 4906.78125, 5687.3896484375, 7231.6337890625, 8322.228515625, 8691.4873046875, 7516.83154296875, 8975.23046875, 7732.87158203125, 10727.5498046875, 10827.380859375, 13277.4609375, 14567.5888671875, 11716.677734375, 10367.5029296875, 10612.662109375, 17435.689453125, 20158.56640625, 20952.68359375, 21159.779296875, 18059.4375, 17593.48046875, 20333.34375, 22923.8203125, 27522.279296875, 27699.77734375, 25962.9453125, 23215.60546875, 22713.763671875, 25748.73828125, 32119.25, 26330.73046875, 24807.953125, 24770.861328125, 21794.3828125, 16841.080078125, 18112.01953125, 18873.9140625, 21049.26953125, 22118.96484375, 22849.552734375, 22626.125, 16658.962890625, 15782.4794921875, 32665.9609375, 16495.65625, 17758.146484375, 14627.93359375, 10782.0517578125, 8288.65625, 8964.7734375, 13332.375, 11951.96484375, 12607.431640625, 11955.6650390625, 9215.9111328125, 5253.41259765625, 9063.28125, 14469.4208984375, 11855.1484375, 12828.84375, 11316.837890625, 8628.7314453125, 3644.428466796875, 7524.0966796875, 12571.595703125, 12319.11328125, 10714.888671875, 10028.9287109375, 7569.94091796875, 5058.72900390625, 5049.18017578125, 12610.1865234375, 12160.2216796875, 12393.005859375, 8656.552734375, 3775.507568359375, 3440.5615234375, 6188.279296875, 8656.5302734375, 9663.2548828125, 10457.712890625, 10514.490234375, 5975.7412109375, 5539.96142578125, 6746.0625, 9390.5283203125, 12008.4990234375, 8631.9169921875, 6322.916015625, 1843.1168212890625, 5052.1376953125, 5133.5927734375, 8253.3203125, 8739.701171875, 6145.42236328125, 6501.0595703125, 6212.79150390625, 4849.42236328125, 4131.25732421875, 6784.1083984375, 6673.02099609375, 5722.6748046875, 5968.861328125, 4817.59765625, 2195.399658203125, 3572.030517578125, 6533.5263671875, 6804.93603515625, 6565.3955078125, 5543.125, 4398.181640625, 3320.612548828125, 2895.075439453125, 6699.9765625, 6486.892578125, 5915.4345703125, 5592.8935546875, 4569.53125, 2000.649169921875, 3148.351318359375, 6748.55615234375, 6875.0361328125, 6401.20703125, 6006.38037109375, 5314.43701171875, 2252.938232421875, 3500.162353515625, 8539.337890625, 8579.91796875, 8623.7802734375, 8690.96484375, 6723.2333984375, 2628.181396484375, 6219.275390625, 12090.28125, 12013.6875, 12074.2236328125, 11532.826171875, 9468.3828125, 4268.0966796875, 7215.908203125, 15052.3515625, 16110.3916015625, 14556.2021484375, 15498.46875, 12795.810546875, 5156.90625, 9707.9833984375, 20243.27734375, 18131.125, 19354.416015625, 18590.62890625, 16159.3544921875, 7203.927734375, 14253.5283203125, 25006.6875, 27702.76953125, 26165.560546875, 26518.47265625, 20347.1171875, 12679.517578125, 17761.54296875, 29167.494140625, 33750.3828125, 32399.69140625, 34413.30078125, 27600.91015625, 12559.2939453125, 20107.484375, 35694.43359375, 37991.59375, 32994.90625, 27932.296875, 22020.74609375, 10318.689453125, 9880.59765625, 28297.56640625, 27270.9609375, 23736.478515625, 22779.90234375, 20001.056640625, 14284.427734375, 12558.060546875, 21044.189453125, 20887.77734375, 19177.5078125, 15564.900390625, 11549.3408203125, 6534.6650390625, 6514.873046875, 13885.54296875, 13687.5546875, 11141.1669921875, 9189.2099609375, 8131.70361328125, 4293.8212890625, 5847.4091796875, 8273.28515625, 8434.822265625, 7559.9169921875, 5493.8623046875, 4802.9453125, 2451.400146484375, 4060.603271484375, 4205.8232421875, 5057.6123046875, 5406.82763671875, 4424.75244140625, 2989.553955078125, 716.5288696289062, 2873.110595703125, 4077.30419921875, 3753.443603515625, 3047.14794921875, 2640.955078125, 2415.932861328125, 1226.921630859375, 893.8700561523438, 2657.529541015625, 2030.106201171875, 1942.08349609375, 1349.67724609375, 1448.0806884765625, 593.4464721679688, 916.7930908203125, 1285.673828125, 1103.8341064453125, 1068.1312255859375, 734.9877319335938, 799.23828125, 446.6585998535156, 515.4163208007812, 720.9308471679688, 598.7304077148438, 443.0074462890625, 291.9782409667969, 507.7301025390625, 167.09471130371094, 239.6022186279297, 409.25048828125, 182.1253204345703, 345.3398742675781, 290.6763916015625, 245.91502380371094, 257.21075439453125, 202.1393280029297, 284.93218994140625, 127.38978576660156, 152.9970245361328, 144.79270935058594, 94.32951354980469, 126.12786102294922]}, {\"mode\": \"markers+lines\", \"name\": \"Acquired Data\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466], \"y\": [20, 17, 36, 21, 52, 61, 49, 68, 70, 111, 98, 116, 152, 150, 170, 168, 249, 224, 193, 256, 243, 392, 437, 244, 475, 311, 435, 357, 370, 380, 401, 318, 260, 268, 380, 336, 457, 334, 515, 306, 263, 313, 342, 381, 381, 344, 285, 316, 422, 300, 228, 270, 318, 313, 406, 311, 303, 337, 288, 345, 330, 556, 322, 411, 401, 241, 272, 356, 382, 471, 403, 472, 316, 361, 341, 443, 396, 352, 333, 412, 219, 374, 236, 292, 361, 362, 576, 575, 599, 400, 282, 359, 376, 440, 375, 396, 407, 450, 314, 352, 309, 311, 296, 300, 294, 298, 276, 319, 193, 247, 239, 382, 371, 259, 314, 231, 205, 257, 277, 262, 265, 305, 370, 299, 267, 264, 333, 353, 339, 358, 279, 399, 380, 418, 458, 584, 443, 337, 502, 512, 615, 657, 658, 548, 575, 680, 640, 726, 809, 843, 624, 619, 551, 715, 811, 825, 778, 594, 595, 597, 735, 767, 903, 900, 581, 548, 763, 729, 887, 791, 759, 631, 502, 550, 595, 612, 691, 567, 437, 302, 400, 421, 506, 594, 603, 502, 377, 605, 600, 837, 757, 1002, 910, 748, 711, 974, 1136, 1587, 1584, 1350, 1306, 1326, 1552, 1967, 2292, 2367, 1934, 2006, 2236, 3003, 4280, 4739, 5300, 4178, 4394, 5068, 6526, 8099, 7705, 9622, 8536, 7482, 9291, 10040, 12107, 13632, 13628, 11742, 10241, 16300, 18820, 20156, 21629, 21897, 17171, 15578, 19364, 24692, 27143, 27086, 27875, 24785, 21713, 25454, 25221, 22683, 24051, 25571, 21854, 20816, 19152, 19883, 23975, 22464, 24213, 17856, 15002, 32733, 15356, 16690, 17304, 15177, 11482, 5736, 9113, 13823, 14863, 13236, 12427, 9176, 4421, 8310, 12166, 13750, 13105, 11499, 8976, 4896, 6874, 12455, 11953, 11010, 11246, 8590, 4633, 7192, 12358, 13115, 9081, 4878, 3842, 3211, 7624, 12780, 13464, 10896, 7006, 5782, 4385, 7596, 14220, 12119, 8763, 10744, 9133, 4863, 5394, 9126, 9436, 7979, 7292, 5970, 3332, 4890, 6943, 7008, 6693, 6304, 4566, 2674, 4603, 6790, 7153, 6145, 5864, 4711, 2504, 4326, 6801, 6495, 6053, 5966, 4725, 2431, 3999, 6960, 7013, 6378, 6585, 5334, 2542, 5176, 8699, 9074, 8772, 8509, 7040, 3891, 6304, 12147, 12143, 11536, 12097, 10101, 4786, 7936, 15698, 15253, 15831, 14855, 13569, 6169, 9953, 17277, 21111, 18873, 21063, 17272, 10895, 14394, 25053, 27274, 25996, 26456, 21850, 14579, 16740, 30802, 34150, 35145, 31759, 29266, 16973, 20862, 32891, 35253, 30541, 28073, 22958, 9921, 8246, 14908, 27890, 28499, 24892, 21733, 12016, 13203, 21266, 21126, 17846, 15786, 12151, 7302, 9244, 13922, 12763, 10866, 9510, 7224, 3467, 5711, 8893, 8426, 6789, 6475, 4616, 2523, 2296, 3899, 6427, 6047, 4771, 3856, 2031, 3097, 3948, 3694, 3289, 2897, 2169, 1111, 1727, 2348, 2087, 1678, 1517, 1075, 559, 1000, 1267, 1227, 946, 775, 579, 333, 588, 659, 572, 317, 415, 310, 195, 532, 428, 382, 341, 238, 226, 140, 215, 238, 218, 190, 168, 133, 73]}, {\"line\": {\"color\": \"Blue\", \"width\": 4}, \"mode\": \"lines\", \"name\": \"Prediction\", \"type\": \"scatter\", \"x\": [468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497], \"y\": [97, 136, 114, 78, 64, 78, 50, 49, 54, 50, 46, 44, 41, 41, 42, 44, 37, 38, 40, 36, 41, 45, 47, 50, 55, 62, 71, 80, 90, 96]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Covid Cases\"}, \"xaxis\": {\"title\": {\"text\": \"Date\"}}, \"yaxis\": {\"title\": {\"text\": \"Cases\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('338ccc19-880b-4512-b56c-ee4c4ebcc40a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooUlmXTzEDPZ",
        "outputId": "816d20fe-0c46-4cc3-cc8c-dca9060a94af"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SB61ErudFyu",
        "outputId": "43ceda6c-ec5c-4934-e0ce-749b40c33615"
      },
      "source": [
        "Test_Y[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkM4Jt9-6ssT",
        "outputId": "d8ab98e9-ed90-4666-e397-243d1c794336"
      },
      "source": [
        "# The median of absolute errors\n",
        "print(\"Mediana błedu bezwzględnego wynosi: \" + str(np.median(absolute_errors)))\n",
        "print(\"Najwieksza pomyłka wynosi blisko: \"+ str(int(np.ceil(max(relative_errors)))) + \" % i jest dla argumentu o wartości: \" + str(Test_Y[np.argmax(relative_errors)]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mediana błedu bezwzględnego wynosi: 148.2265625\n",
            "Najwieksza pomyłka wynosi blisko: 113 % i jest dla argumentu o wartości: [[15356]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqAnI6LoVAn_",
        "outputId": "80a0f4cd-be13-4cc8-d490-99dc2bfe0726"
      },
      "source": [
        "np.argmax(relative_errors)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO6Cq23g805i",
        "outputId": "760ebb3c-0421-4b63-80aa-c34a6e6a0739"
      },
      "source": [
        "# Relative errors [%]\n",
        "np.round(relative_errors, 2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.3790e+01, 9.2000e-01, 5.1200e+01, 2.5200e+00, 6.5630e+01,\n",
              "       7.8000e-01, 2.9930e+01, 1.2500e+00, 5.1700e+00, 1.5400e+00,\n",
              "       4.1100e+00, 4.0700e+00, 4.8500e+00, 8.3900e+00, 2.3120e+01,\n",
              "       4.9000e+00, 3.2720e+01, 1.3460e+01, 2.5280e+01, 1.8400e+01,\n",
              "       1.1840e+01, 3.6030e+01, 5.3400e+00, 8.9330e+01, 6.2570e+01,\n",
              "       2.6370e+01, 3.2970e+01, 2.1250e+01, 4.2100e+00, 1.4300e+01,\n",
              "       3.6000e+00, 3.3290e+01, 3.2530e+01, 5.4200e+00, 3.2640e+01,\n",
              "       6.2700e+00, 4.3030e+01, 1.6710e+01, 3.8470e+01, 3.9420e+01,\n",
              "       2.0330e+01, 8.0700e+00, 1.6500e+01, 1.0760e+01, 4.4200e+00,\n",
              "       7.3000e+00, 2.1000e+00, 2.5780e+01, 8.7300e+00, 3.6120e+01,\n",
              "       3.8650e+01, 1.3420e+01, 2.0040e+01, 6.9100e+00, 3.0550e+01,\n",
              "       2.0830e+01, 3.7300e+00, 1.4420e+01, 1.5850e+01, 1.4090e+01,\n",
              "       9.2300e+00, 4.1680e+01, 5.3260e+01, 1.7930e+01, 3.2410e+01,\n",
              "       6.8720e+01, 1.8230e+01, 8.7700e+00, 8.9500e+00, 2.5240e+01,\n",
              "       8.3300e+00, 1.0920e+01, 3.5450e+01, 1.2540e+01, 4.8500e+00,\n",
              "       2.9450e+01, 1.0410e+01, 1.4570e+01, 1.0770e+01, 3.6800e+01,\n",
              "       5.3540e+01, 4.0440e+01, 7.3950e+01, 1.7390e+01, 2.1970e+01,\n",
              "       1.4090e+01, 4.3700e+01, 9.9900e+00, 1.2040e+01, 6.2830e+01,\n",
              "       4.7470e+01, 3.7260e+01, 7.2170e+01, 6.3500e+00, 5.1500e+00,\n",
              "       2.8390e+01, 3.5320e+01, 3.9000e+01, 2.1890e+01, 1.5230e+01,\n",
              "       2.9680e+01, 1.9000e-01, 8.0000e-02, 5.1600e+00, 1.1770e+01,\n",
              "       1.4170e+01, 5.2700e+00, 1.3410e+01, 5.2160e+01, 2.1840e+01,\n",
              "       1.9190e+01, 3.9560e+01, 1.0650e+01, 3.8780e+01, 1.4830e+01,\n",
              "       3.1150e+01, 2.7510e+01, 3.7400e+00, 1.4130e+01, 2.2100e+00,\n",
              "       9.9700e+00, 3.2130e+01, 2.9700e+01, 1.8410e+01, 9.6500e+00,\n",
              "       6.8900e+00, 5.1100e+00, 4.7500e+00, 7.7600e+00, 2.7900e+00,\n",
              "       1.3370e+01, 3.1510e+01, 1.1010e+01, 1.3600e+00, 7.3800e+00,\n",
              "       2.0610e+01, 3.4730e+01, 3.7720e+01, 3.1530e+01, 1.3080e+01,\n",
              "       7.2500e+00, 6.6000e-01, 6.3000e-01, 1.6560e+01, 1.5680e+01,\n",
              "       1.1800e+00, 2.2430e+01, 6.1900e+00, 7.8800e+00, 6.1000e-01,\n",
              "       3.8970e+01, 1.4380e+01, 1.7700e+01, 1.5190e+01, 1.1200e+00,\n",
              "       2.3900e+00, 8.7500e+00, 1.4280e+01, 1.0600e+01, 1.2830e+01,\n",
              "       5.0000e-02, 1.8000e+00, 1.2030e+01, 3.8800e+00, 5.4160e+01,\n",
              "       3.3300e+00, 1.1440e+01, 2.6990e+01, 1.7090e+01, 1.0160e+01,\n",
              "       3.6200e+00, 5.2000e-01, 5.6700e+00, 1.9560e+01, 3.6460e+01,\n",
              "       6.6700e+00, 1.5800e+01, 5.1200e+00, 7.7500e+00, 1.1990e+01,\n",
              "       1.0720e+01, 1.9740e+01, 1.3630e+01, 2.2310e+01, 1.2420e+01,\n",
              "       9.6000e+00, 1.3670e+01, 3.9910e+01, 1.5520e+01, 2.6880e+01,\n",
              "       8.3700e+00, 2.3040e+01, 4.1400e+00, 2.0790e+01, 6.0900e+00,\n",
              "       8.0500e+00, 2.6300e+00, 1.9680e+01, 4.0300e+00, 3.3280e+01,\n",
              "       2.6950e+01, 9.3200e+00, 6.6000e-01, 1.0100e+00, 1.1430e+01,\n",
              "       1.3000e-01, 2.4740e+01, 2.9530e+01, 9.2900e+00, 1.8380e+01,\n",
              "       2.3350e+01, 8.7800e+00, 1.0900e+00, 2.0950e+01, 2.3590e+01,\n",
              "       3.1800e+00, 1.2850e+01, 1.0710e+01, 8.0100e+00, 9.6700e+00,\n",
              "       1.1940e+01, 1.9960e+01, 1.6770e+01, 6.8500e+00, 1.0570e+01,\n",
              "       2.6000e+00, 6.8900e+00, 2.2000e-01, 1.2400e+00, 3.4890e+01,\n",
              "       7.3600e+00, 1.0000e-02, 3.1300e+00, 3.3700e+00, 5.1700e+00,\n",
              "       1.2940e+01, 5.0100e+00, 7.1600e+00, 1.4000e+00, 2.2700e+00,\n",
              "       6.8600e+00, 6.3300e+00, 4.6100e+00, 1.1600e+00, 2.7350e+01,\n",
              "       1.6080e+01, 3.1500e+00, 3.1300e+00, 2.7000e-01, 1.9100e+01,\n",
              "       5.4300e+00, 5.0800e+00, 1.2200e+01, 1.5400e+00, 5.6300e+00,\n",
              "       2.6710e+01, 1.1040e+01, 5.1780e+01, 1.1272e+02, 1.1600e+00,\n",
              "       2.6200e+00, 3.6200e+00, 6.1000e+00, 4.4500e+01, 1.6300e+00,\n",
              "       3.5500e+00, 1.9590e+01, 4.7500e+00, 3.7900e+00, 4.3000e-01,\n",
              "       1.8830e+01, 9.0600e+00, 1.8930e+01, 1.3780e+01, 2.1100e+00,\n",
              "       1.5800e+00, 3.8700e+00, 2.5560e+01, 9.4600e+00, 9.4000e-01,\n",
              "       3.0600e+00, 2.6800e+00, 1.0820e+01, 1.1870e+01, 9.1900e+00,\n",
              "       2.9790e+01, 2.0400e+00, 7.2800e+00, 3.6470e+01, 7.7460e+01,\n",
              "       1.7300e+00, 7.1500e+00, 1.8830e+01, 3.2270e+01, 2.8230e+01,\n",
              "       4.0200e+00, 5.0080e+01, 3.3500e+00, 2.6340e+01, 1.1190e+01,\n",
              "       3.3960e+01, 9.1000e-01, 1.5000e+00, 4.1150e+01, 7.9820e+01,\n",
              "       3.8900e+00, 4.8300e+00, 9.5600e+00, 7.3800e+00, 2.2980e+01,\n",
              "       1.0850e+01, 4.0700e+00, 4.5540e+01, 1.5520e+01, 2.2900e+00,\n",
              "       4.7800e+00, 1.4500e+01, 5.3200e+00, 5.5100e+00, 1.7900e+01,\n",
              "       2.2400e+01, 3.7800e+00, 4.8700e+00, 6.8400e+00, 5.4700e+00,\n",
              "       6.6400e+00, 3.2610e+01, 3.3080e+01, 1.4900e+00, 1.2000e-01,\n",
              "       2.2700e+00, 6.2500e+00, 3.2900e+00, 1.7700e+01, 2.1270e+01,\n",
              "       3.0400e+00, 1.9700e+00, 3.6000e-01, 8.7900e+00, 3.7000e-01,\n",
              "       1.1370e+01, 3.2380e+01, 1.8400e+00, 5.4500e+00, 1.6900e+00,\n",
              "       2.1400e+00, 4.5000e+00, 3.2450e+01, 1.3400e+00, 4.7000e-01,\n",
              "       1.0600e+00, 4.6700e+00, 4.6600e+00, 6.2600e+00, 1.0820e+01,\n",
              "       9.0700e+00, 4.1100e+00, 5.6200e+00, 8.0500e+00, 4.3300e+00,\n",
              "       5.7000e+00, 1.6410e+01, 2.4600e+00, 1.7170e+01, 1.4120e+01,\n",
              "       2.5500e+00, 1.1740e+01, 6.4400e+00, 3.3880e+01, 9.8000e-01,\n",
              "       1.8000e-01, 1.5700e+00, 6.5000e-01, 2.4000e-01, 6.8800e+00,\n",
              "       1.3030e+01, 6.1000e+00, 5.3100e+00, 1.1700e+00, 7.8100e+00,\n",
              "       8.3600e+00, 5.6900e+00, 2.6000e+01, 3.6200e+00, 8.5200e+00,\n",
              "       7.7700e+00, 8.0300e+00, 5.0000e-01, 4.0800e+00, 4.0100e+00,\n",
              "       1.9820e+01, 8.9810e+01, 2.2200e+00, 1.6710e+01, 8.4900e+00,\n",
              "       7.9700e+00, 1.8880e+01, 4.8800e+00, 1.0400e+00, 1.1300e+00,\n",
              "       7.4600e+00, 1.4000e+00, 4.9500e+00, 1.0510e+01, 2.9520e+01,\n",
              "       2.6000e-01, 7.2400e+00, 2.5300e+00, 3.3700e+00, 1.2570e+01,\n",
              "       2.3850e+01, 2.3900e+00, 6.9700e+00, 1.0000e-01, 1.1360e+01,\n",
              "       1.5150e+01, 4.0500e+00, 2.8400e+00, 7.6860e+01, 7.8700e+00,\n",
              "       2.1310e+01, 1.0590e+01, 7.2600e+00, 2.2470e+01, 6.4720e+01,\n",
              "       7.2300e+00, 3.2800e+00, 1.6100e+00, 7.3500e+00, 8.8400e+00,\n",
              "       1.1380e+01, 1.0430e+01, 4.8240e+01, 1.3180e+01, 2.7300e+00,\n",
              "       1.5740e+01, 1.1030e+01, 3.4710e+01, 6.1600e+00, 8.3200e+00,\n",
              "       1.4700e+00, 1.0040e+01, 1.2910e+01, 5.1600e+00, 3.8040e+01,\n",
              "       3.4130e+01, 1.2340e+01, 9.4000e+00, 4.6700e+00, 3.9750e+01,\n",
              "       2.9640e+01, 6.3780e+01, 1.4310e+01, 5.4960e+01, 4.3800e+00,\n",
              "       5.2320e+01, 1.2700e+00, 2.2130e+01, 8.8100e+00, 8.3720e+01,\n",
              "       5.9800e+00, 1.9720e+01, 4.1560e+01, 1.9480e+01, 1.3810e+01,\n",
              "       2.9080e+01, 7.2780e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lppqRsrHyGaI",
        "outputId": "e3435317-31f0-4f0d-abfd-a9a478e6fb85"
      },
      "source": [
        "next_day = predict_next_day(np.array(cases[-14:]))\n",
        "print(next_day)\n",
        "print(\"Przewidywany margines błędu: [\" + str(np.round(next_day - np.median((relative_errors/100)*next_day))) + \" ; \" +  str(np.round(next_day + np.median((relative_errors/100)*next_day))) + \"]\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "97\n",
            "Przewidywany margines błędu: [87.0 ; 107.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4DX3Lh2d3YN",
        "outputId": "f5f289ed-fe19-4881-b56f-9746d2870eef"
      },
      "source": [
        "np.array(cases[-15:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([317, 415, 310, 195, 532, 428, 382, 341, 238, 226, 140, 215, 238,\n",
              "       218, 190])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ed_oBnUWJb-",
        "outputId": "c8c0d231-6996-4c0d-c091-84a684f3c516"
      },
      "source": [
        "np.median(absolute_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228.40553283691406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsHbfapDLaa5",
        "outputId": "6c6417dc-a31b-4b50-eed7-242245eb2c2b"
      },
      "source": [
        "#coefficient of variance\n",
        "np.std(cases)/np.mean(cases) * 100 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133.6160118760004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLKkytzdHg8k",
        "outputId": "b729d2b0-1966-42d1-b51f-bfab61972fcb"
      },
      "source": [
        "len(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPRke2yOEhq3",
        "outputId": "0bca2872-1bcd-4416-9160-e2ccecb9a2c8"
      },
      "source": [
        "len(close_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}