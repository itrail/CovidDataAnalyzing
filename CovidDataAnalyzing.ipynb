{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovidDataAnalyzing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWkdlBXQ8RTMoZwz6A2FGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itrail/CovidDataAnalyzing/blob/main/CovidDataAnalyzing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvzhk04YYklr",
        "outputId": "220bc1cd-3814-4777-99db-ac225df429c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5edWpu_mXuR3"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import json\n",
        "from itertools import islice\n",
        "from datetime import timedelta, date, datetime, timezone\n",
        "from openpyxl import load_workbook\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objects as go\n",
        "from numpy import mean, average\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHG73YdD3lu7"
      },
      "source": [
        "#creating json file with excel covid19 data \n",
        "\n",
        "def create_json():\n",
        "  covid_data = []\n",
        "  #open a spreadsheet and sheet\n",
        "  wb = load_workbook('covid19.xlsx')\n",
        "  sheet = wb['newCases2021']\n",
        "\n",
        "  #copy row by row with loop\n",
        "  for row in islice(sheet.values, 1, sheet.max_row):\n",
        "      data = OrderedDict()\n",
        "      day = row[0]\n",
        "      day  = day.strftime(\"%d.%m.%Y\")\n",
        "      data['date'] = day\n",
        "      data['cases'] = str(row[1])\n",
        "      covid_data.append(data)\n",
        "  newlist = sorted(covid_data, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "  j = json.dumps(newlist) \n",
        "\n",
        "  #save data in json file\n",
        "  with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vmjpa4BCZsP"
      },
      "source": [
        "def update_json():\n",
        "  with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "    json_object = json.load(f)\n",
        "    f.close()\n",
        "  #open a spreadsheet and sheet\n",
        "  wb = load_workbook('covid19.xlsx')\n",
        "  sheet = wb['newCases2020']\n",
        "\n",
        "  #copy row by row with loop\n",
        "  for row in islice(sheet.values, 1, sheet.max_row):\n",
        "      data = OrderedDict()\n",
        "      day = row[0]\n",
        "      day  = day.strftime(\"%d.%m.%Y\")\n",
        "      data['date'] = day\n",
        "      data['cases'] = str(row[1])\n",
        "      json_object.append(data)\n",
        "  newlist = sorted(json_object, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "  j = json.dumps(newlist) \n",
        "  with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)\n",
        "\n",
        "#update_json()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLhM0pGa9TZJ"
      },
      "source": [
        "#create_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgwePQKFsvkw",
        "outputId": "4d47c14e-f963-4010-a6f7-6e71561dfe91"
      },
      "source": [
        "import requests\n",
        "\n",
        "#data actualization\n",
        "covid_data=[]\n",
        "#url of webpage with covid data\n",
        "url = 'https://www.worldometers.info/coronavirus/country/poland/'\n",
        "\n",
        "#get the page content\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "#find lists, here's data about new cases and deaths\n",
        "data_iterator = iter(soup.find_all('li', {'class': 'news_li'}))\n",
        "\n",
        "#delta is variable to substracting date, if its before 12 data probably hasn't been updated\n",
        "now = datetime.now(timezone(timedelta(hours=2)))\n",
        "if now.hour >= 11:\n",
        "  delta = 0\n",
        "else:\n",
        "  delta = 1\n",
        "\n",
        "#getting todays date\n",
        "today = date.today()\n",
        "#loop for all obtained data\n",
        "with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "  json_object = json.load(f)\n",
        "  f.close()\n",
        "days = []\n",
        "for item in json_object:\n",
        "  days.append(item['date'])\n",
        "iterator = 0;\n",
        "while True:\n",
        "    try:\n",
        "      #substracting dates\n",
        "      day  = today - timedelta(days=delta)\n",
        "      day  = day .strftime(\"%d.%m.%Y\")\n",
        "      #getting the next row and cleaning the info\n",
        "      newData = next(data_iterator).text\n",
        "      newData = newData.split(\" new cases and \", 1)\n",
        "      newCases = newData[0]\n",
        "      newDeaths= newData[1].replace(' new deaths in Poland\\xa0[source]', '')\n",
        "      newCases = newCases.replace(',', '')\n",
        "      data = {\"date\": day, \"cases\": newCases, }\n",
        "\n",
        "      #saving data if is not in json file\n",
        "      if data['date'] not in days:\n",
        "        print(data)\n",
        "        json_object.append(data)\n",
        "        \n",
        "      print(day  + \": \" + newCases)\n",
        "      delta += 1\n",
        "      iterator += 1\n",
        "    except StopIteration:\n",
        "      break\n",
        "\n",
        "#sorting by dates\n",
        "newlist = sorted(json_object, key=lambda x: datetime.strptime(x['date'], '%d.%m.%Y'))\n",
        "j = json.dumps(newlist) \n",
        "with open('/content/gdrive/My Drive/data.json', 'w') as f:\n",
        "    f.write(j)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'date': '17.06.2021', 'cases': '218'}\n",
            "17.06.2021: 218\n",
            "{'date': '16.06.2021', 'cases': '238'}\n",
            "16.06.2021: 238\n",
            "15.06.2021: 216\n",
            "14.06.2021: 136\n",
            "13.06.2021: 226\n",
            "12.06.2021: 238\n",
            "11.06.2021: 338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQZjLbxD6v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc149c1-8c18-434d-927a-92082a5f1a1f"
      },
      "source": [
        "#print the data\n",
        "with open('/content/gdrive/My Drive/data.json', 'r') as f:\n",
        "  json_object = json.load(f)\n",
        "  f.close()\n",
        "\n",
        "cases = []\n",
        "days = []\n",
        "for item in json_object:\n",
        "  print(item)\n",
        "  cases.append(int(item['cases']))\n",
        "  days.append(item['date'])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'date': '27.02.2020', 'cases': '0'}\n",
            "{'date': '28.02.2020', 'cases': '0'}\n",
            "{'date': '29.02.2020', 'cases': '0'}\n",
            "{'date': '01.03.2020', 'cases': '0'}\n",
            "{'date': '02.03.2020', 'cases': '0'}\n",
            "{'date': '03.03.2020', 'cases': '0'}\n",
            "{'date': '04.03.2020', 'cases': '1'}\n",
            "{'date': '05.03.2020', 'cases': '0'}\n",
            "{'date': '06.03.2020', 'cases': '4'}\n",
            "{'date': '07.03.2020', 'cases': '1'}\n",
            "{'date': '08.03.2020', 'cases': '5'}\n",
            "{'date': '09.03.2020', 'cases': '6'}\n",
            "{'date': '10.03.2020', 'cases': '5'}\n",
            "{'date': '11.03.2020', 'cases': '9'}\n",
            "{'date': '12.03.2020', 'cases': '20'}\n",
            "{'date': '13.03.2020', 'cases': '17'}\n",
            "{'date': '14.03.2020', 'cases': '36'}\n",
            "{'date': '15.03.2020', 'cases': '21'}\n",
            "{'date': '16.03.2020', 'cases': '52'}\n",
            "{'date': '17.03.2020', 'cases': '61'}\n",
            "{'date': '18.03.2020', 'cases': '49'}\n",
            "{'date': '19.03.2020', 'cases': '68'}\n",
            "{'date': '20.03.2020', 'cases': '70'}\n",
            "{'date': '21.03.2020', 'cases': '111'}\n",
            "{'date': '22.03.2020', 'cases': '98'}\n",
            "{'date': '23.03.2020', 'cases': '116'}\n",
            "{'date': '24.03.2020', 'cases': '152'}\n",
            "{'date': '25.03.2020', 'cases': '150'}\n",
            "{'date': '26.03.2020', 'cases': '170'}\n",
            "{'date': '27.03.2020', 'cases': '168'}\n",
            "{'date': '28.03.2020', 'cases': '249'}\n",
            "{'date': '29.03.2020', 'cases': '224'}\n",
            "{'date': '30.03.2020', 'cases': '193'}\n",
            "{'date': '31.03.2020', 'cases': '256'}\n",
            "{'date': '01.04.2020', 'cases': '243'}\n",
            "{'date': '02.04.2020', 'cases': '392'}\n",
            "{'date': '03.04.2020', 'cases': '437'}\n",
            "{'date': '04.04.2020', 'cases': '244'}\n",
            "{'date': '05.04.2020', 'cases': '475'}\n",
            "{'date': '06.04.2020', 'cases': '311'}\n",
            "{'date': '07.04.2020', 'cases': '435'}\n",
            "{'date': '08.04.2020', 'cases': '357'}\n",
            "{'date': '09.04.2020', 'cases': '370'}\n",
            "{'date': '10.04.2020', 'cases': '380'}\n",
            "{'date': '11.04.2020', 'cases': '401'}\n",
            "{'date': '12.04.2020', 'cases': '318'}\n",
            "{'date': '13.04.2020', 'cases': '260'}\n",
            "{'date': '14.04.2020', 'cases': '268'}\n",
            "{'date': '15.04.2020', 'cases': '380'}\n",
            "{'date': '16.04.2020', 'cases': '336'}\n",
            "{'date': '17.04.2020', 'cases': '457'}\n",
            "{'date': '18.04.2020', 'cases': '334'}\n",
            "{'date': '19.04.2020', 'cases': '515'}\n",
            "{'date': '20.04.2020', 'cases': '306'}\n",
            "{'date': '21.04.2020', 'cases': '263'}\n",
            "{'date': '22.04.2020', 'cases': '313'}\n",
            "{'date': '23.04.2020', 'cases': '342'}\n",
            "{'date': '24.04.2020', 'cases': '381'}\n",
            "{'date': '25.04.2020', 'cases': '381'}\n",
            "{'date': '26.04.2020', 'cases': '344'}\n",
            "{'date': '27.04.2020', 'cases': '285'}\n",
            "{'date': '28.04.2020', 'cases': '316'}\n",
            "{'date': '29.04.2020', 'cases': '422'}\n",
            "{'date': '30.04.2020', 'cases': '300'}\n",
            "{'date': '01.05.2020', 'cases': '228'}\n",
            "{'date': '02.05.2020', 'cases': '270'}\n",
            "{'date': '03.05.2020', 'cases': '318'}\n",
            "{'date': '04.05.2020', 'cases': '313'}\n",
            "{'date': '05.05.2020', 'cases': '406'}\n",
            "{'date': '06.05.2020', 'cases': '311'}\n",
            "{'date': '07.05.2020', 'cases': '303'}\n",
            "{'date': '08.05.2020', 'cases': '337'}\n",
            "{'date': '09.05.2020', 'cases': '288'}\n",
            "{'date': '10.05.2020', 'cases': '345'}\n",
            "{'date': '11.05.2020', 'cases': '330'}\n",
            "{'date': '12.05.2020', 'cases': '556'}\n",
            "{'date': '13.05.2020', 'cases': '322'}\n",
            "{'date': '14.05.2020', 'cases': '411'}\n",
            "{'date': '15.05.2020', 'cases': '401'}\n",
            "{'date': '16.05.2020', 'cases': '241'}\n",
            "{'date': '17.05.2020', 'cases': '272'}\n",
            "{'date': '18.05.2020', 'cases': '356'}\n",
            "{'date': '19.05.2020', 'cases': '382'}\n",
            "{'date': '20.05.2020', 'cases': '471'}\n",
            "{'date': '21.05.2020', 'cases': '403'}\n",
            "{'date': '22.05.2020', 'cases': '472'}\n",
            "{'date': '23.05.2020', 'cases': '316'}\n",
            "{'date': '24.05.2020', 'cases': '361'}\n",
            "{'date': '25.05.2020', 'cases': '341'}\n",
            "{'date': '26.05.2020', 'cases': '443'}\n",
            "{'date': '27.05.2020', 'cases': '396'}\n",
            "{'date': '28.05.2020', 'cases': '352'}\n",
            "{'date': '29.05.2020', 'cases': '333'}\n",
            "{'date': '30.05.2020', 'cases': '412'}\n",
            "{'date': '31.05.2020', 'cases': '219'}\n",
            "{'date': '01.06.2020', 'cases': '374'}\n",
            "{'date': '02.06.2020', 'cases': '236'}\n",
            "{'date': '03.06.2020', 'cases': '292'}\n",
            "{'date': '04.06.2020', 'cases': '361'}\n",
            "{'date': '05.06.2020', 'cases': '362'}\n",
            "{'date': '06.06.2020', 'cases': '576'}\n",
            "{'date': '07.06.2020', 'cases': '575'}\n",
            "{'date': '08.06.2020', 'cases': '599'}\n",
            "{'date': '09.06.2020', 'cases': '400'}\n",
            "{'date': '10.06.2020', 'cases': '282'}\n",
            "{'date': '11.06.2020', 'cases': '359'}\n",
            "{'date': '12.06.2020', 'cases': '376'}\n",
            "{'date': '13.06.2020', 'cases': '440'}\n",
            "{'date': '14.06.2020', 'cases': '375'}\n",
            "{'date': '15.06.2020', 'cases': '396'}\n",
            "{'date': '16.06.2020', 'cases': '407'}\n",
            "{'date': '17.06.2020', 'cases': '450'}\n",
            "{'date': '18.06.2020', 'cases': '314'}\n",
            "{'date': '19.06.2020', 'cases': '352'}\n",
            "{'date': '20.06.2020', 'cases': '309'}\n",
            "{'date': '21.06.2020', 'cases': '311'}\n",
            "{'date': '22.06.2020', 'cases': '296'}\n",
            "{'date': '23.06.2020', 'cases': '300'}\n",
            "{'date': '24.06.2020', 'cases': '294'}\n",
            "{'date': '25.06.2020', 'cases': '298'}\n",
            "{'date': '26.06.2020', 'cases': '276'}\n",
            "{'date': '27.06.2020', 'cases': '319'}\n",
            "{'date': '28.06.2020', 'cases': '193'}\n",
            "{'date': '29.06.2020', 'cases': '247'}\n",
            "{'date': '30.06.2020', 'cases': '239'}\n",
            "{'date': '01.07.2020', 'cases': '382'}\n",
            "{'date': '02.07.2020', 'cases': '371'}\n",
            "{'date': '03.07.2020', 'cases': '259'}\n",
            "{'date': '04.07.2020', 'cases': '314'}\n",
            "{'date': '05.07.2020', 'cases': '231'}\n",
            "{'date': '06.07.2020', 'cases': '205'}\n",
            "{'date': '07.07.2020', 'cases': '257'}\n",
            "{'date': '08.07.2020', 'cases': '277'}\n",
            "{'date': '09.07.2020', 'cases': '262'}\n",
            "{'date': '10.07.2020', 'cases': '265'}\n",
            "{'date': '11.07.2020', 'cases': '305'}\n",
            "{'date': '12.07.2020', 'cases': '370'}\n",
            "{'date': '13.07.2020', 'cases': '299'}\n",
            "{'date': '14.07.2020', 'cases': '267'}\n",
            "{'date': '15.07.2020', 'cases': '264'}\n",
            "{'date': '16.07.2020', 'cases': '333'}\n",
            "{'date': '17.07.2020', 'cases': '353'}\n",
            "{'date': '18.07.2020', 'cases': '339'}\n",
            "{'date': '19.07.2020', 'cases': '358'}\n",
            "{'date': '20.07.2020', 'cases': '279'}\n",
            "{'date': '21.07.2020', 'cases': '399'}\n",
            "{'date': '22.07.2020', 'cases': '380'}\n",
            "{'date': '23.07.2020', 'cases': '418'}\n",
            "{'date': '24.07.2020', 'cases': '458'}\n",
            "{'date': '25.07.2020', 'cases': '584'}\n",
            "{'date': '26.07.2020', 'cases': '443'}\n",
            "{'date': '27.07.2020', 'cases': '337'}\n",
            "{'date': '28.07.2020', 'cases': '502'}\n",
            "{'date': '29.07.2020', 'cases': '512'}\n",
            "{'date': '30.07.2020', 'cases': '615'}\n",
            "{'date': '31.07.2020', 'cases': '657'}\n",
            "{'date': '01.08.2020', 'cases': '658'}\n",
            "{'date': '02.08.2020', 'cases': '548'}\n",
            "{'date': '03.08.2020', 'cases': '575'}\n",
            "{'date': '04.08.2020', 'cases': '680'}\n",
            "{'date': '05.08.2020', 'cases': '640'}\n",
            "{'date': '06.08.2020', 'cases': '726'}\n",
            "{'date': '07.08.2020', 'cases': '809'}\n",
            "{'date': '08.08.2020', 'cases': '843'}\n",
            "{'date': '09.08.2020', 'cases': '624'}\n",
            "{'date': '10.08.2020', 'cases': '619'}\n",
            "{'date': '11.08.2020', 'cases': '551'}\n",
            "{'date': '12.08.2020', 'cases': '715'}\n",
            "{'date': '13.08.2020', 'cases': '811'}\n",
            "{'date': '14.08.2020', 'cases': '825'}\n",
            "{'date': '15.08.2020', 'cases': '778'}\n",
            "{'date': '16.08.2020', 'cases': '594'}\n",
            "{'date': '17.08.2020', 'cases': '595'}\n",
            "{'date': '18.08.2020', 'cases': '597'}\n",
            "{'date': '19.08.2020', 'cases': '735'}\n",
            "{'date': '20.08.2020', 'cases': '767'}\n",
            "{'date': '21.08.2020', 'cases': '903'}\n",
            "{'date': '22.08.2020', 'cases': '900'}\n",
            "{'date': '23.08.2020', 'cases': '581'}\n",
            "{'date': '24.08.2020', 'cases': '548'}\n",
            "{'date': '25.08.2020', 'cases': '763'}\n",
            "{'date': '26.08.2020', 'cases': '729'}\n",
            "{'date': '27.08.2020', 'cases': '887'}\n",
            "{'date': '28.08.2020', 'cases': '791'}\n",
            "{'date': '29.08.2020', 'cases': '759'}\n",
            "{'date': '30.08.2020', 'cases': '631'}\n",
            "{'date': '31.08.2020', 'cases': '502'}\n",
            "{'date': '01.09.2020', 'cases': '550'}\n",
            "{'date': '02.09.2020', 'cases': '595'}\n",
            "{'date': '03.09.2020', 'cases': '612'}\n",
            "{'date': '04.09.2020', 'cases': '691'}\n",
            "{'date': '05.09.2020', 'cases': '567'}\n",
            "{'date': '06.09.2020', 'cases': '437'}\n",
            "{'date': '07.09.2020', 'cases': '302'}\n",
            "{'date': '08.09.2020', 'cases': '400'}\n",
            "{'date': '09.09.2020', 'cases': '421'}\n",
            "{'date': '10.09.2020', 'cases': '506'}\n",
            "{'date': '11.09.2020', 'cases': '594'}\n",
            "{'date': '12.09.2020', 'cases': '603'}\n",
            "{'date': '13.09.2020', 'cases': '502'}\n",
            "{'date': '14.09.2020', 'cases': '377'}\n",
            "{'date': '15.09.2020', 'cases': '605'}\n",
            "{'date': '16.09.2020', 'cases': '600'}\n",
            "{'date': '17.09.2020', 'cases': '837'}\n",
            "{'date': '18.09.2020', 'cases': '757'}\n",
            "{'date': '19.09.2020', 'cases': '1002'}\n",
            "{'date': '20.09.2020', 'cases': '910'}\n",
            "{'date': '21.09.2020', 'cases': '748'}\n",
            "{'date': '22.09.2020', 'cases': '711'}\n",
            "{'date': '23.09.2020', 'cases': '974'}\n",
            "{'date': '24.09.2020', 'cases': '1136'}\n",
            "{'date': '25.09.2020', 'cases': '1587'}\n",
            "{'date': '26.09.2020', 'cases': '1584'}\n",
            "{'date': '27.09.2020', 'cases': '1350'}\n",
            "{'date': '28.09.2020', 'cases': '1306'}\n",
            "{'date': '29.09.2020', 'cases': '1326'}\n",
            "{'date': '30.09.2020', 'cases': '1552'}\n",
            "{'date': '01.10.2020', 'cases': '1967'}\n",
            "{'date': '02.10.2020', 'cases': '2292'}\n",
            "{'date': '03.10.2020', 'cases': '2367'}\n",
            "{'date': '04.10.2020', 'cases': '1934'}\n",
            "{'date': '05.10.2020', 'cases': '2006'}\n",
            "{'date': '06.10.2020', 'cases': '2236'}\n",
            "{'date': '07.10.2020', 'cases': '3003'}\n",
            "{'date': '08.10.2020', 'cases': '4280'}\n",
            "{'date': '09.10.2020', 'cases': '4739'}\n",
            "{'date': '10.10.2020', 'cases': '5300'}\n",
            "{'date': '11.10.2020', 'cases': '4178'}\n",
            "{'date': '12.10.2020', 'cases': '4394'}\n",
            "{'date': '13.10.2020', 'cases': '5068'}\n",
            "{'date': '14.10.2020', 'cases': '6526'}\n",
            "{'date': '15.10.2020', 'cases': '8099'}\n",
            "{'date': '16.10.2020', 'cases': '7705'}\n",
            "{'date': '17.10.2020', 'cases': '9622'}\n",
            "{'date': '18.10.2020', 'cases': '8536'}\n",
            "{'date': '19.10.2020', 'cases': '7482'}\n",
            "{'date': '20.10.2020', 'cases': '9291'}\n",
            "{'date': '21.10.2020', 'cases': '10040'}\n",
            "{'date': '22.10.2020', 'cases': '12107'}\n",
            "{'date': '23.10.2020', 'cases': '13632'}\n",
            "{'date': '24.10.2020', 'cases': '13628'}\n",
            "{'date': '25.10.2020', 'cases': '11742'}\n",
            "{'date': '26.10.2020', 'cases': '10241'}\n",
            "{'date': '27.10.2020', 'cases': '16300'}\n",
            "{'date': '28.10.2020', 'cases': '18820'}\n",
            "{'date': '29.10.2020', 'cases': '20156'}\n",
            "{'date': '30.10.2020', 'cases': '21629'}\n",
            "{'date': '31.10.2020', 'cases': '21897'}\n",
            "{'date': '01.11.2020', 'cases': '17171'}\n",
            "{'date': '02.11.2020', 'cases': '15578'}\n",
            "{'date': '03.11.2020', 'cases': '19364'}\n",
            "{'date': '04.11.2020', 'cases': '24692'}\n",
            "{'date': '05.11.2020', 'cases': '27143'}\n",
            "{'date': '06.11.2020', 'cases': '27086'}\n",
            "{'date': '07.11.2020', 'cases': '27875'}\n",
            "{'date': '08.11.2020', 'cases': '24785'}\n",
            "{'date': '09.11.2020', 'cases': '21713'}\n",
            "{'date': '10.11.2020', 'cases': '25454'}\n",
            "{'date': '11.11.2020', 'cases': '25221'}\n",
            "{'date': '12.11.2020', 'cases': '22683'}\n",
            "{'date': '13.11.2020', 'cases': '24051'}\n",
            "{'date': '14.11.2020', 'cases': '25571'}\n",
            "{'date': '15.11.2020', 'cases': '21854'}\n",
            "{'date': '16.11.2020', 'cases': '20816'}\n",
            "{'date': '17.11.2020', 'cases': '19152'}\n",
            "{'date': '18.11.2020', 'cases': '19883'}\n",
            "{'date': '19.11.2020', 'cases': '23975'}\n",
            "{'date': '20.11.2020', 'cases': '22464'}\n",
            "{'date': '21.11.2020', 'cases': '24213'}\n",
            "{'date': '22.11.2020', 'cases': '17856'}\n",
            "{'date': '23.11.2020', 'cases': '15002'}\n",
            "{'date': '24.11.2020', 'cases': '32733'}\n",
            "{'date': '25.11.2020', 'cases': '15356'}\n",
            "{'date': '26.11.2020', 'cases': '16690'}\n",
            "{'date': '27.11.2020', 'cases': '17304'}\n",
            "{'date': '28.11.2020', 'cases': '15177'}\n",
            "{'date': '29.11.2020', 'cases': '11482'}\n",
            "{'date': '30.11.2020', 'cases': '5736'}\n",
            "{'date': '01.12.2020', 'cases': '9113'}\n",
            "{'date': '02.12.2020', 'cases': '13823'}\n",
            "{'date': '03.12.2020', 'cases': '14863'}\n",
            "{'date': '04.12.2020', 'cases': '13236'}\n",
            "{'date': '05.12.2020', 'cases': '12427'}\n",
            "{'date': '06.12.2020', 'cases': '9176'}\n",
            "{'date': '07.12.2020', 'cases': '4421'}\n",
            "{'date': '08.12.2020', 'cases': '8310'}\n",
            "{'date': '09.12.2020', 'cases': '12166'}\n",
            "{'date': '10.12.2020', 'cases': '13750'}\n",
            "{'date': '11.12.2020', 'cases': '13105'}\n",
            "{'date': '12.12.2020', 'cases': '11499'}\n",
            "{'date': '13.12.2020', 'cases': '8976'}\n",
            "{'date': '14.12.2020', 'cases': '4896'}\n",
            "{'date': '15.12.2020', 'cases': '6874'}\n",
            "{'date': '16.12.2020', 'cases': '12455'}\n",
            "{'date': '17.12.2020', 'cases': '11953'}\n",
            "{'date': '18.12.2020', 'cases': '11010'}\n",
            "{'date': '19.12.2020', 'cases': '11246'}\n",
            "{'date': '20.12.2020', 'cases': '8590'}\n",
            "{'date': '21.12.2020', 'cases': '4633'}\n",
            "{'date': '22.12.2020', 'cases': '7192'}\n",
            "{'date': '23.12.2020', 'cases': '12358'}\n",
            "{'date': '24.12.2020', 'cases': '13115'}\n",
            "{'date': '25.12.2020', 'cases': '9081'}\n",
            "{'date': '26.12.2020', 'cases': '4878'}\n",
            "{'date': '27.12.2020', 'cases': '3842'}\n",
            "{'date': '28.12.2020', 'cases': '3211'}\n",
            "{'date': '29.12.2020', 'cases': '7624'}\n",
            "{'date': '30.12.2020', 'cases': '12780'}\n",
            "{'date': '31.12.2020', 'cases': '13464'}\n",
            "{'date': '01.01.2021', 'cases': '10896'}\n",
            "{'date': '02.01.2021', 'cases': '7006'}\n",
            "{'date': '03.01.2021', 'cases': '5782'}\n",
            "{'date': '04.01.2021', 'cases': '4385'}\n",
            "{'date': '05.01.2021', 'cases': '7596'}\n",
            "{'date': '06.01.2021', 'cases': '14220'}\n",
            "{'date': '07.01.2021', 'cases': '12119'}\n",
            "{'date': '08.01.2021', 'cases': '8763'}\n",
            "{'date': '09.01.2021', 'cases': '10744'}\n",
            "{'date': '10.01.2021', 'cases': '9133'}\n",
            "{'date': '11.01.2021', 'cases': '4863'}\n",
            "{'date': '12.01.2021', 'cases': '5394'}\n",
            "{'date': '13.01.2021', 'cases': '9126'}\n",
            "{'date': '14.01.2021', 'cases': '9436'}\n",
            "{'date': '15.01.2021', 'cases': '7979'}\n",
            "{'date': '16.01.2021', 'cases': '7292'}\n",
            "{'date': '17.01.2021', 'cases': '5970'}\n",
            "{'date': '18.01.2021', 'cases': '3332'}\n",
            "{'date': '19.01.2021', 'cases': '4890'}\n",
            "{'date': '20.01.2021', 'cases': '6943'}\n",
            "{'date': '21.01.2021', 'cases': '7008'}\n",
            "{'date': '22.01.2021', 'cases': '6693'}\n",
            "{'date': '23.01.2021', 'cases': '6304'}\n",
            "{'date': '24.01.2021', 'cases': '4566'}\n",
            "{'date': '25.01.2021', 'cases': '2674'}\n",
            "{'date': '26.01.2021', 'cases': '4603'}\n",
            "{'date': '27.01.2021', 'cases': '6790'}\n",
            "{'date': '28.01.2021', 'cases': '7153'}\n",
            "{'date': '29.01.2021', 'cases': '6145'}\n",
            "{'date': '30.01.2021', 'cases': '5864'}\n",
            "{'date': '31.01.2021', 'cases': '4711'}\n",
            "{'date': '01.02.2021', 'cases': '2504'}\n",
            "{'date': '02.02.2021', 'cases': '4326'}\n",
            "{'date': '03.02.2021', 'cases': '6801'}\n",
            "{'date': '04.02.2021', 'cases': '6495'}\n",
            "{'date': '05.02.2021', 'cases': '6053'}\n",
            "{'date': '06.02.2021', 'cases': '5966'}\n",
            "{'date': '07.02.2021', 'cases': '4725'}\n",
            "{'date': '08.02.2021', 'cases': '2431'}\n",
            "{'date': '09.02.2021', 'cases': '3999'}\n",
            "{'date': '10.02.2021', 'cases': '6960'}\n",
            "{'date': '11.02.2021', 'cases': '7013'}\n",
            "{'date': '12.02.2021', 'cases': '6378'}\n",
            "{'date': '13.02.2021', 'cases': '6585'}\n",
            "{'date': '14.02.2021', 'cases': '5334'}\n",
            "{'date': '15.02.2021', 'cases': '2542'}\n",
            "{'date': '16.02.2021', 'cases': '5176'}\n",
            "{'date': '17.02.2021', 'cases': '8699'}\n",
            "{'date': '18.02.2021', 'cases': '9074'}\n",
            "{'date': '19.02.2021', 'cases': '8772'}\n",
            "{'date': '20.02.2021', 'cases': '8509'}\n",
            "{'date': '21.02.2021', 'cases': '7040'}\n",
            "{'date': '22.02.2021', 'cases': '3891'}\n",
            "{'date': '23.02.2021', 'cases': '6304'}\n",
            "{'date': '24.02.2021', 'cases': '12147'}\n",
            "{'date': '25.02.2021', 'cases': '12143'}\n",
            "{'date': '26.02.2021', 'cases': '11536'}\n",
            "{'date': '27.02.2021', 'cases': '12097'}\n",
            "{'date': '28.02.2021', 'cases': '10101'}\n",
            "{'date': '01.03.2021', 'cases': '4786'}\n",
            "{'date': '02.03.2021', 'cases': '7936'}\n",
            "{'date': '03.03.2021', 'cases': '15698'}\n",
            "{'date': '04.03.2021', 'cases': '15253'}\n",
            "{'date': '05.03.2021', 'cases': '15831'}\n",
            "{'date': '06.03.2021', 'cases': '14855'}\n",
            "{'date': '07.03.2021', 'cases': '13569'}\n",
            "{'date': '08.03.2021', 'cases': '6169'}\n",
            "{'date': '09.03.2021', 'cases': '9953'}\n",
            "{'date': '10.03.2021', 'cases': '17277'}\n",
            "{'date': '11.03.2021', 'cases': '21111'}\n",
            "{'date': '12.03.2021', 'cases': '18873'}\n",
            "{'date': '13.03.2021', 'cases': '21063'}\n",
            "{'date': '14.03.2021', 'cases': '17272'}\n",
            "{'date': '15.03.2021', 'cases': '10895'}\n",
            "{'date': '16.03.2021', 'cases': '14394'}\n",
            "{'date': '17.03.2021', 'cases': '25053'}\n",
            "{'date': '18.03.2021', 'cases': '27274'}\n",
            "{'date': '19.03.2021', 'cases': '25996'}\n",
            "{'date': '20.03.2021', 'cases': '26456'}\n",
            "{'date': '21.03.2021', 'cases': '21850'}\n",
            "{'date': '22.03.2021', 'cases': '14579'}\n",
            "{'date': '23.03.2021', 'cases': '16740'}\n",
            "{'date': '24.03.2021', 'cases': '30802'}\n",
            "{'date': '25.03.2021', 'cases': '34150'}\n",
            "{'date': '26.03.2021', 'cases': '35145'}\n",
            "{'date': '27.03.2021', 'cases': '31759'}\n",
            "{'date': '28.03.2021', 'cases': '29266'}\n",
            "{'date': '29.03.2021', 'cases': '16973'}\n",
            "{'date': '30.03.2021', 'cases': '20862'}\n",
            "{'date': '31.03.2021', 'cases': '32891'}\n",
            "{'date': '01.04.2021', 'cases': '35253'}\n",
            "{'date': '02.04.2021', 'cases': '30541'}\n",
            "{'date': '03.04.2021', 'cases': '28073'}\n",
            "{'date': '04.04.2021', 'cases': '22958'}\n",
            "{'date': '05.04.2021', 'cases': '9921'}\n",
            "{'date': '06.04.2021', 'cases': '8246'}\n",
            "{'date': '07.04.2021', 'cases': '14908'}\n",
            "{'date': '08.04.2021', 'cases': '27890'}\n",
            "{'date': '09.04.2021', 'cases': '28499'}\n",
            "{'date': '10.04.2021', 'cases': '24892'}\n",
            "{'date': '11.04.2021', 'cases': '21733'}\n",
            "{'date': '12.04.2021', 'cases': '12016'}\n",
            "{'date': '13.04.2021', 'cases': '13203'}\n",
            "{'date': '14.04.2021', 'cases': '21266'}\n",
            "{'date': '15.04.2021', 'cases': '21126'}\n",
            "{'date': '16.04.2021', 'cases': '17846'}\n",
            "{'date': '17.04.2021', 'cases': '15786'}\n",
            "{'date': '18.04.2021', 'cases': '12151'}\n",
            "{'date': '19.04.2021', 'cases': '7302'}\n",
            "{'date': '20.04.2021', 'cases': '9244'}\n",
            "{'date': '21.04.2021', 'cases': '13922'}\n",
            "{'date': '22.04.2021', 'cases': '12763'}\n",
            "{'date': '23.04.2021', 'cases': '10866'}\n",
            "{'date': '24.04.2021', 'cases': '9510'}\n",
            "{'date': '25.04.2021', 'cases': '7224'}\n",
            "{'date': '26.04.2021', 'cases': '3467'}\n",
            "{'date': '27.04.2021', 'cases': '5711'}\n",
            "{'date': '28.04.2021', 'cases': '8893'}\n",
            "{'date': '29.04.2021', 'cases': '8426'}\n",
            "{'date': '30.04.2021', 'cases': '6789'}\n",
            "{'date': '01.05.2021', 'cases': '6475'}\n",
            "{'date': '02.05.2021', 'cases': '4616'}\n",
            "{'date': '03.05.2021', 'cases': '2523'}\n",
            "{'date': '04.05.2021', 'cases': '2296'}\n",
            "{'date': '05.05.2021', 'cases': '3899'}\n",
            "{'date': '06.05.2021', 'cases': '6427'}\n",
            "{'date': '07.05.2021', 'cases': '6047'}\n",
            "{'date': '08.05.2021', 'cases': '4771'}\n",
            "{'date': '09.05.2021', 'cases': '3856'}\n",
            "{'date': '10.05.2021', 'cases': '2031'}\n",
            "{'date': '11.05.2021', 'cases': '3097'}\n",
            "{'date': '12.05.2021', 'cases': '3948'}\n",
            "{'date': '13.05.2021', 'cases': '3694'}\n",
            "{'date': '14.05.2021', 'cases': '3289'}\n",
            "{'date': '15.05.2021', 'cases': '2897'}\n",
            "{'date': '16.05.2021', 'cases': '2169'}\n",
            "{'date': '17.05.2021', 'cases': '1111'}\n",
            "{'date': '18.05.2021', 'cases': '1727'}\n",
            "{'date': '19.05.2021', 'cases': '2348'}\n",
            "{'date': '20.05.2021', 'cases': '2087'}\n",
            "{'date': '21.05.2021', 'cases': '1678'}\n",
            "{'date': '22.05.2021', 'cases': '1517'}\n",
            "{'date': '23.05.2021', 'cases': '1075'}\n",
            "{'date': '24.05.2021', 'cases': '559'}\n",
            "{'date': '25.05.2021', 'cases': '1000'}\n",
            "{'date': '26.05.2021', 'cases': '1267'}\n",
            "{'date': '27.05.2021', 'cases': '1227'}\n",
            "{'date': '28.05.2021', 'cases': '946'}\n",
            "{'date': '29.05.2021', 'cases': '775'}\n",
            "{'date': '30.05.2021', 'cases': '579'}\n",
            "{'date': '31.05.2021', 'cases': '333'}\n",
            "{'date': '01.06.2021', 'cases': '588'}\n",
            "{'date': '02.06.2021', 'cases': '659'}\n",
            "{'date': '03.06.2021', 'cases': '572'}\n",
            "{'date': '04.06.2021', 'cases': '317'}\n",
            "{'date': '05.06.2021', 'cases': '415'}\n",
            "{'date': '06.06.2021', 'cases': '310'}\n",
            "{'date': '07.06.2021', 'cases': '195'}\n",
            "{'date': '08.06.2021', 'cases': '532'}\n",
            "{'date': '09.06.2021', 'cases': '428'}\n",
            "{'date': '10.06.2021', 'cases': '382'}\n",
            "{'date': '11.06.2021', 'cases': '341'}\n",
            "{'date': '12.06.2021', 'cases': '238'}\n",
            "{'date': '13.06.2021', 'cases': '226'}\n",
            "{'date': '14.06.2021', 'cases': '140'}\n",
            "{'date': '15.06.2021', 'cases': '215'}\n",
            "{'date': '16.06.2021', 'cases': '238'}\n",
            "{'date': '17.06.2021', 'cases': '218'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzUAqh7pkDjV",
        "outputId": "77b9e86a-b26d-4f50-e7d9-3c4725815128"
      },
      "source": [
        "average = 0\n",
        "for n in range(1, 8):\n",
        "  i = -8 + n\n",
        "  average = ((n-1)*average+ cases[i])/n\n",
        "  print(str(cases[i]) + \":\" + str(average))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "341:341.0\n",
            "238:289.5\n",
            "226:268.3333333333333\n",
            "140:236.25\n",
            "215:232.0\n",
            "238:233.0\n",
            "218:230.85714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAb7jTvuoIuD",
        "outputId": "fae04df5-5684-4ebb-9d90-ba79ecf37583"
      },
      "source": [
        "today = date.today()\n",
        "n=0\n",
        "sum=0\n",
        "for day in days:\n",
        "  date_dt2 = datetime.strptime(day, '%d.%m.%Y')\n",
        "  if date_dt2.month == today.month-1:\n",
        "    n=n+1\n",
        "    #print(cases[days.index(day)])\n",
        "    sum=sum+cases[days.index(day)]\n",
        "    \n",
        "last_month_avg = sum/n\n",
        "print(last_month_avg)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1470.532258064516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "oqR51LuIh6a2",
        "outputId": "ed08666e-3314-4dee-ef0a-9a4d0e503e2e"
      },
      "source": [
        "#plotting covid cases\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=days, y=cases, name='Covid Cases', mode='markers+lines'))\n",
        "fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [last_month_avg], name='Last month average', mode='lines'))\n",
        "#fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [average], name='Last 7 days average', mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=days, y=(len(json_object)+1) * [mean(cases)], name='Todays Average', mode='lines'))\n",
        "fig.update_layout(width=1300, height=500, title='Number of covid19 cases by day in 2021', xaxis_title='Days', yaxis_title='Cases')\n",
        "fig.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0923d175-ac1b-4b53-932d-3d1b4f0d9a1d\" class=\"plotly-graph-div\" style=\"height:500px; width:1300px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0923d175-ac1b-4b53-932d-3d1b4f0d9a1d\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0923d175-ac1b-4b53-932d-3d1b4f0d9a1d',\n",
              "                        [{\"mode\": \"markers+lines\", \"name\": \"Covid Cases\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\", \"10.06.2021\", \"11.06.2021\", \"12.06.2021\", \"13.06.2021\", \"14.06.2021\", \"15.06.2021\", \"16.06.2021\", \"17.06.2021\"], \"y\": [0, 0, 0, 0, 0, 0, 1, 0, 4, 1, 5, 6, 5, 9, 20, 17, 36, 21, 52, 61, 49, 68, 70, 111, 98, 116, 152, 150, 170, 168, 249, 224, 193, 256, 243, 392, 437, 244, 475, 311, 435, 357, 370, 380, 401, 318, 260, 268, 380, 336, 457, 334, 515, 306, 263, 313, 342, 381, 381, 344, 285, 316, 422, 300, 228, 270, 318, 313, 406, 311, 303, 337, 288, 345, 330, 556, 322, 411, 401, 241, 272, 356, 382, 471, 403, 472, 316, 361, 341, 443, 396, 352, 333, 412, 219, 374, 236, 292, 361, 362, 576, 575, 599, 400, 282, 359, 376, 440, 375, 396, 407, 450, 314, 352, 309, 311, 296, 300, 294, 298, 276, 319, 193, 247, 239, 382, 371, 259, 314, 231, 205, 257, 277, 262, 265, 305, 370, 299, 267, 264, 333, 353, 339, 358, 279, 399, 380, 418, 458, 584, 443, 337, 502, 512, 615, 657, 658, 548, 575, 680, 640, 726, 809, 843, 624, 619, 551, 715, 811, 825, 778, 594, 595, 597, 735, 767, 903, 900, 581, 548, 763, 729, 887, 791, 759, 631, 502, 550, 595, 612, 691, 567, 437, 302, 400, 421, 506, 594, 603, 502, 377, 605, 600, 837, 757, 1002, 910, 748, 711, 974, 1136, 1587, 1584, 1350, 1306, 1326, 1552, 1967, 2292, 2367, 1934, 2006, 2236, 3003, 4280, 4739, 5300, 4178, 4394, 5068, 6526, 8099, 7705, 9622, 8536, 7482, 9291, 10040, 12107, 13632, 13628, 11742, 10241, 16300, 18820, 20156, 21629, 21897, 17171, 15578, 19364, 24692, 27143, 27086, 27875, 24785, 21713, 25454, 25221, 22683, 24051, 25571, 21854, 20816, 19152, 19883, 23975, 22464, 24213, 17856, 15002, 32733, 15356, 16690, 17304, 15177, 11482, 5736, 9113, 13823, 14863, 13236, 12427, 9176, 4421, 8310, 12166, 13750, 13105, 11499, 8976, 4896, 6874, 12455, 11953, 11010, 11246, 8590, 4633, 7192, 12358, 13115, 9081, 4878, 3842, 3211, 7624, 12780, 13464, 10896, 7006, 5782, 4385, 7596, 14220, 12119, 8763, 10744, 9133, 4863, 5394, 9126, 9436, 7979, 7292, 5970, 3332, 4890, 6943, 7008, 6693, 6304, 4566, 2674, 4603, 6790, 7153, 6145, 5864, 4711, 2504, 4326, 6801, 6495, 6053, 5966, 4725, 2431, 3999, 6960, 7013, 6378, 6585, 5334, 2542, 5176, 8699, 9074, 8772, 8509, 7040, 3891, 6304, 12147, 12143, 11536, 12097, 10101, 4786, 7936, 15698, 15253, 15831, 14855, 13569, 6169, 9953, 17277, 21111, 18873, 21063, 17272, 10895, 14394, 25053, 27274, 25996, 26456, 21850, 14579, 16740, 30802, 34150, 35145, 31759, 29266, 16973, 20862, 32891, 35253, 30541, 28073, 22958, 9921, 8246, 14908, 27890, 28499, 24892, 21733, 12016, 13203, 21266, 21126, 17846, 15786, 12151, 7302, 9244, 13922, 12763, 10866, 9510, 7224, 3467, 5711, 8893, 8426, 6789, 6475, 4616, 2523, 2296, 3899, 6427, 6047, 4771, 3856, 2031, 3097, 3948, 3694, 3289, 2897, 2169, 1111, 1727, 2348, 2087, 1678, 1517, 1075, 559, 1000, 1267, 1227, 946, 775, 579, 333, 588, 659, 572, 317, 415, 310, 195, 532, 428, 382, 341, 238, 226, 140, 215, 238, 218]}, {\"mode\": \"lines\", \"name\": \"Last month average\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\", \"10.06.2021\", \"11.06.2021\", \"12.06.2021\", \"13.06.2021\", \"14.06.2021\", \"15.06.2021\", \"16.06.2021\", \"17.06.2021\"], \"y\": [1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516, 1470.532258064516]}, {\"mode\": \"lines\", \"name\": \"Todays Average\", \"type\": \"scatter\", \"x\": [\"27.02.2020\", \"28.02.2020\", \"29.02.2020\", \"01.03.2020\", \"02.03.2020\", \"03.03.2020\", \"04.03.2020\", \"05.03.2020\", \"06.03.2020\", \"07.03.2020\", \"08.03.2020\", \"09.03.2020\", \"10.03.2020\", \"11.03.2020\", \"12.03.2020\", \"13.03.2020\", \"14.03.2020\", \"15.03.2020\", \"16.03.2020\", \"17.03.2020\", \"18.03.2020\", \"19.03.2020\", \"20.03.2020\", \"21.03.2020\", \"22.03.2020\", \"23.03.2020\", \"24.03.2020\", \"25.03.2020\", \"26.03.2020\", \"27.03.2020\", \"28.03.2020\", \"29.03.2020\", \"30.03.2020\", \"31.03.2020\", \"01.04.2020\", \"02.04.2020\", \"03.04.2020\", \"04.04.2020\", \"05.04.2020\", \"06.04.2020\", \"07.04.2020\", \"08.04.2020\", \"09.04.2020\", \"10.04.2020\", \"11.04.2020\", \"12.04.2020\", \"13.04.2020\", \"14.04.2020\", \"15.04.2020\", \"16.04.2020\", \"17.04.2020\", \"18.04.2020\", \"19.04.2020\", \"20.04.2020\", \"21.04.2020\", \"22.04.2020\", \"23.04.2020\", \"24.04.2020\", \"25.04.2020\", \"26.04.2020\", \"27.04.2020\", \"28.04.2020\", \"29.04.2020\", \"30.04.2020\", \"01.05.2020\", \"02.05.2020\", \"03.05.2020\", \"04.05.2020\", \"05.05.2020\", \"06.05.2020\", \"07.05.2020\", \"08.05.2020\", \"09.05.2020\", \"10.05.2020\", \"11.05.2020\", \"12.05.2020\", \"13.05.2020\", \"14.05.2020\", \"15.05.2020\", \"16.05.2020\", \"17.05.2020\", \"18.05.2020\", \"19.05.2020\", \"20.05.2020\", \"21.05.2020\", \"22.05.2020\", \"23.05.2020\", \"24.05.2020\", \"25.05.2020\", \"26.05.2020\", \"27.05.2020\", \"28.05.2020\", \"29.05.2020\", \"30.05.2020\", \"31.05.2020\", \"01.06.2020\", \"02.06.2020\", \"03.06.2020\", \"04.06.2020\", \"05.06.2020\", \"06.06.2020\", \"07.06.2020\", \"08.06.2020\", \"09.06.2020\", \"10.06.2020\", \"11.06.2020\", \"12.06.2020\", \"13.06.2020\", \"14.06.2020\", \"15.06.2020\", \"16.06.2020\", \"17.06.2020\", \"18.06.2020\", \"19.06.2020\", \"20.06.2020\", \"21.06.2020\", \"22.06.2020\", \"23.06.2020\", \"24.06.2020\", \"25.06.2020\", \"26.06.2020\", \"27.06.2020\", \"28.06.2020\", \"29.06.2020\", \"30.06.2020\", \"01.07.2020\", \"02.07.2020\", \"03.07.2020\", \"04.07.2020\", \"05.07.2020\", \"06.07.2020\", \"07.07.2020\", \"08.07.2020\", \"09.07.2020\", \"10.07.2020\", \"11.07.2020\", \"12.07.2020\", \"13.07.2020\", \"14.07.2020\", \"15.07.2020\", \"16.07.2020\", \"17.07.2020\", \"18.07.2020\", \"19.07.2020\", \"20.07.2020\", \"21.07.2020\", \"22.07.2020\", \"23.07.2020\", \"24.07.2020\", \"25.07.2020\", \"26.07.2020\", \"27.07.2020\", \"28.07.2020\", \"29.07.2020\", \"30.07.2020\", \"31.07.2020\", \"01.08.2020\", \"02.08.2020\", \"03.08.2020\", \"04.08.2020\", \"05.08.2020\", \"06.08.2020\", \"07.08.2020\", \"08.08.2020\", \"09.08.2020\", \"10.08.2020\", \"11.08.2020\", \"12.08.2020\", \"13.08.2020\", \"14.08.2020\", \"15.08.2020\", \"16.08.2020\", \"17.08.2020\", \"18.08.2020\", \"19.08.2020\", \"20.08.2020\", \"21.08.2020\", \"22.08.2020\", \"23.08.2020\", \"24.08.2020\", \"25.08.2020\", \"26.08.2020\", \"27.08.2020\", \"28.08.2020\", \"29.08.2020\", \"30.08.2020\", \"31.08.2020\", \"01.09.2020\", \"02.09.2020\", \"03.09.2020\", \"04.09.2020\", \"05.09.2020\", \"06.09.2020\", \"07.09.2020\", \"08.09.2020\", \"09.09.2020\", \"10.09.2020\", \"11.09.2020\", \"12.09.2020\", \"13.09.2020\", \"14.09.2020\", \"15.09.2020\", \"16.09.2020\", \"17.09.2020\", \"18.09.2020\", \"19.09.2020\", \"20.09.2020\", \"21.09.2020\", \"22.09.2020\", \"23.09.2020\", \"24.09.2020\", \"25.09.2020\", \"26.09.2020\", \"27.09.2020\", \"28.09.2020\", \"29.09.2020\", \"30.09.2020\", \"01.10.2020\", \"02.10.2020\", \"03.10.2020\", \"04.10.2020\", \"05.10.2020\", \"06.10.2020\", \"07.10.2020\", \"08.10.2020\", \"09.10.2020\", \"10.10.2020\", \"11.10.2020\", \"12.10.2020\", \"13.10.2020\", \"14.10.2020\", \"15.10.2020\", \"16.10.2020\", \"17.10.2020\", \"18.10.2020\", \"19.10.2020\", \"20.10.2020\", \"21.10.2020\", \"22.10.2020\", \"23.10.2020\", \"24.10.2020\", \"25.10.2020\", \"26.10.2020\", \"27.10.2020\", \"28.10.2020\", \"29.10.2020\", \"30.10.2020\", \"31.10.2020\", \"01.11.2020\", \"02.11.2020\", \"03.11.2020\", \"04.11.2020\", \"05.11.2020\", \"06.11.2020\", \"07.11.2020\", \"08.11.2020\", \"09.11.2020\", \"10.11.2020\", \"11.11.2020\", \"12.11.2020\", \"13.11.2020\", \"14.11.2020\", \"15.11.2020\", \"16.11.2020\", \"17.11.2020\", \"18.11.2020\", \"19.11.2020\", \"20.11.2020\", \"21.11.2020\", \"22.11.2020\", \"23.11.2020\", \"24.11.2020\", \"25.11.2020\", \"26.11.2020\", \"27.11.2020\", \"28.11.2020\", \"29.11.2020\", \"30.11.2020\", \"01.12.2020\", \"02.12.2020\", \"03.12.2020\", \"04.12.2020\", \"05.12.2020\", \"06.12.2020\", \"07.12.2020\", \"08.12.2020\", \"09.12.2020\", \"10.12.2020\", \"11.12.2020\", \"12.12.2020\", \"13.12.2020\", \"14.12.2020\", \"15.12.2020\", \"16.12.2020\", \"17.12.2020\", \"18.12.2020\", \"19.12.2020\", \"20.12.2020\", \"21.12.2020\", \"22.12.2020\", \"23.12.2020\", \"24.12.2020\", \"25.12.2020\", \"26.12.2020\", \"27.12.2020\", \"28.12.2020\", \"29.12.2020\", \"30.12.2020\", \"31.12.2020\", \"01.01.2021\", \"02.01.2021\", \"03.01.2021\", \"04.01.2021\", \"05.01.2021\", \"06.01.2021\", \"07.01.2021\", \"08.01.2021\", \"09.01.2021\", \"10.01.2021\", \"11.01.2021\", \"12.01.2021\", \"13.01.2021\", \"14.01.2021\", \"15.01.2021\", \"16.01.2021\", \"17.01.2021\", \"18.01.2021\", \"19.01.2021\", \"20.01.2021\", \"21.01.2021\", \"22.01.2021\", \"23.01.2021\", \"24.01.2021\", \"25.01.2021\", \"26.01.2021\", \"27.01.2021\", \"28.01.2021\", \"29.01.2021\", \"30.01.2021\", \"31.01.2021\", \"01.02.2021\", \"02.02.2021\", \"03.02.2021\", \"04.02.2021\", \"05.02.2021\", \"06.02.2021\", \"07.02.2021\", \"08.02.2021\", \"09.02.2021\", \"10.02.2021\", \"11.02.2021\", \"12.02.2021\", \"13.02.2021\", \"14.02.2021\", \"15.02.2021\", \"16.02.2021\", \"17.02.2021\", \"18.02.2021\", \"19.02.2021\", \"20.02.2021\", \"21.02.2021\", \"22.02.2021\", \"23.02.2021\", \"24.02.2021\", \"25.02.2021\", \"26.02.2021\", \"27.02.2021\", \"28.02.2021\", \"01.03.2021\", \"02.03.2021\", \"03.03.2021\", \"04.03.2021\", \"05.03.2021\", \"06.03.2021\", \"07.03.2021\", \"08.03.2021\", \"09.03.2021\", \"10.03.2021\", \"11.03.2021\", \"12.03.2021\", \"13.03.2021\", \"14.03.2021\", \"15.03.2021\", \"16.03.2021\", \"17.03.2021\", \"18.03.2021\", \"19.03.2021\", \"20.03.2021\", \"21.03.2021\", \"22.03.2021\", \"23.03.2021\", \"24.03.2021\", \"25.03.2021\", \"26.03.2021\", \"27.03.2021\", \"28.03.2021\", \"29.03.2021\", \"30.03.2021\", \"31.03.2021\", \"01.04.2021\", \"02.04.2021\", \"03.04.2021\", \"04.04.2021\", \"05.04.2021\", \"06.04.2021\", \"07.04.2021\", \"08.04.2021\", \"09.04.2021\", \"10.04.2021\", \"11.04.2021\", \"12.04.2021\", \"13.04.2021\", \"14.04.2021\", \"15.04.2021\", \"16.04.2021\", \"17.04.2021\", \"18.04.2021\", \"19.04.2021\", \"20.04.2021\", \"21.04.2021\", \"22.04.2021\", \"23.04.2021\", \"24.04.2021\", \"25.04.2021\", \"26.04.2021\", \"27.04.2021\", \"28.04.2021\", \"29.04.2021\", \"30.04.2021\", \"01.05.2021\", \"02.05.2021\", \"03.05.2021\", \"04.05.2021\", \"05.05.2021\", \"06.05.2021\", \"07.05.2021\", \"08.05.2021\", \"09.05.2021\", \"10.05.2021\", \"11.05.2021\", \"12.05.2021\", \"13.05.2021\", \"14.05.2021\", \"15.05.2021\", \"16.05.2021\", \"17.05.2021\", \"18.05.2021\", \"19.05.2021\", \"20.05.2021\", \"21.05.2021\", \"22.05.2021\", \"23.05.2021\", \"24.05.2021\", \"25.05.2021\", \"26.05.2021\", \"27.05.2021\", \"28.05.2021\", \"29.05.2021\", \"30.05.2021\", \"31.05.2021\", \"01.06.2021\", \"02.06.2021\", \"03.06.2021\", \"04.06.2021\", \"05.06.2021\", \"06.06.2021\", \"07.06.2021\", \"08.06.2021\", \"09.06.2021\", \"10.06.2021\", \"11.06.2021\", \"12.06.2021\", \"13.06.2021\", \"14.06.2021\", \"15.06.2021\", \"16.06.2021\", \"17.06.2021\"], \"y\": [6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652, 6034.16142557652]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Number of covid19 cases by day in 2021\"}, \"width\": 1300, \"xaxis\": {\"title\": {\"text\": \"Days\"}}, \"yaxis\": {\"title\": {\"text\": \"Cases\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0923d175-ac1b-4b53-932d-3d1b4f0d9a1d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDoOI7OvBEwe"
      },
      "source": [
        "#libraries for creating neural network\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWPAcZn7xGAA"
      },
      "source": [
        "def split_sequence(seq, n_steps):\n",
        "  IN = []\n",
        "  OUT = []\n",
        "  for i in range(len(seq)-n_steps):\n",
        "    TEMP = []\n",
        "    for j in range(i,n_steps):\n",
        "      TEMP.append(seq[j])\n",
        "    IN.append(TEMP)\n",
        "    OUT.append(seq[j+1])\n",
        "    n_steps=n_steps+1\n",
        "  print(len(IN))\n",
        "  return IN,OUT"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMCkOinmxJCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9e8b83-3191-4dcd-cd40-18c21fc8c4a2"
      },
      "source": [
        "#splitting the sequences of 14-days covid datasets\n",
        "n = 14\n",
        "X, Y = split_sequence(cases, n)\n",
        "print(len(X))\n",
        "print(len(Test_X))\n",
        "limit = 0.2*len(X)\n",
        "\n",
        "#splitting for validation data and training data\n",
        "Validation_X = []\n",
        "Validation_Y = []\n",
        "i=0\n",
        "while(i<limit):\n",
        "    r=random.randint(1,len(X))\n",
        "    r=r-1\n",
        "    Validation_X.append(X[r])\n",
        "    Validation_Y.append(Y[r])\n",
        "    del X[r], Y[r]\n",
        "    i+=1\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "Validation_X = np.array(Validation_X)\n",
        "Validation_Y = np.array(Validation_Y)\n",
        "\n",
        "#for i in range(len(Validation_X)):\n",
        "#    print(Validation_X[i], Validation_Y[i])\n",
        "\n",
        "#print of training data set\n",
        "for i in range(len(X)):\n",
        "    print(X[i], Y[i])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "463\n",
            "463\n",
            "370\n",
            "[0 0 0 0 0 0 1 0 4 1 5 6 5 9] 20\n",
            "[ 0  0  0  0  1  0  4  1  5  6  5  9 20 17] 36\n",
            "[ 0  0  0  1  0  4  1  5  6  5  9 20 17 36] 21\n",
            "[ 0  1  0  4  1  5  6  5  9 20 17 36 21 52] 61\n",
            "[ 1  0  4  1  5  6  5  9 20 17 36 21 52 61] 49\n",
            "[ 0  4  1  5  6  5  9 20 17 36 21 52 61 49] 68\n",
            "[ 4  1  5  6  5  9 20 17 36 21 52 61 49 68] 70\n",
            "[  6   5   9  20  17  36  21  52  61  49  68  70 111  98] 116\n",
            "[  5   9  20  17  36  21  52  61  49  68  70 111  98 116] 152\n",
            "[  9  20  17  36  21  52  61  49  68  70 111  98 116 152] 150\n",
            "[ 20  17  36  21  52  61  49  68  70 111  98 116 152 150] 170\n",
            "[ 36  21  52  61  49  68  70 111  98 116 152 150 170 168] 249\n",
            "[ 21  52  61  49  68  70 111  98 116 152 150 170 168 249] 224\n",
            "[ 52  61  49  68  70 111  98 116 152 150 170 168 249 224] 193\n",
            "[ 61  49  68  70 111  98 116 152 150 170 168 249 224 193] 256\n",
            "[ 49  68  70 111  98 116 152 150 170 168 249 224 193 256] 243\n",
            "[ 68  70 111  98 116 152 150 170 168 249 224 193 256 243] 392\n",
            "[ 70 111  98 116 152 150 170 168 249 224 193 256 243 392] 437\n",
            "[111  98 116 152 150 170 168 249 224 193 256 243 392 437] 244\n",
            "[ 98 116 152 150 170 168 249 224 193 256 243 392 437 244] 475\n",
            "[116 152 150 170 168 249 224 193 256 243 392 437 244 475] 311\n",
            "[152 150 170 168 249 224 193 256 243 392 437 244 475 311] 435\n",
            "[150 170 168 249 224 193 256 243 392 437 244 475 311 435] 357\n",
            "[170 168 249 224 193 256 243 392 437 244 475 311 435 357] 370\n",
            "[168 249 224 193 256 243 392 437 244 475 311 435 357 370] 380\n",
            "[224 193 256 243 392 437 244 475 311 435 357 370 380 401] 318\n",
            "[193 256 243 392 437 244 475 311 435 357 370 380 401 318] 260\n",
            "[256 243 392 437 244 475 311 435 357 370 380 401 318 260] 268\n",
            "[392 437 244 475 311 435 357 370 380 401 318 260 268 380] 336\n",
            "[437 244 475 311 435 357 370 380 401 318 260 268 380 336] 457\n",
            "[244 475 311 435 357 370 380 401 318 260 268 380 336 457] 334\n",
            "[475 311 435 357 370 380 401 318 260 268 380 336 457 334] 515\n",
            "[357 370 380 401 318 260 268 380 336 457 334 515 306 263] 313\n",
            "[401 318 260 268 380 336 457 334 515 306 263 313 342 381] 381\n",
            "[260 268 380 336 457 334 515 306 263 313 342 381 381 344] 285\n",
            "[268 380 336 457 334 515 306 263 313 342 381 381 344 285] 316\n",
            "[380 336 457 334 515 306 263 313 342 381 381 344 285 316] 422\n",
            "[336 457 334 515 306 263 313 342 381 381 344 285 316 422] 300\n",
            "[457 334 515 306 263 313 342 381 381 344 285 316 422 300] 228\n",
            "[334 515 306 263 313 342 381 381 344 285 316 422 300 228] 270\n",
            "[306 263 313 342 381 381 344 285 316 422 300 228 270 318] 313\n",
            "[263 313 342 381 381 344 285 316 422 300 228 270 318 313] 406\n",
            "[313 342 381 381 344 285 316 422 300 228 270 318 313 406] 311\n",
            "[381 381 344 285 316 422 300 228 270 318 313 406 311 303] 337\n",
            "[381 344 285 316 422 300 228 270 318 313 406 311 303 337] 288\n",
            "[285 316 422 300 228 270 318 313 406 311 303 337 288 345] 330\n",
            "[316 422 300 228 270 318 313 406 311 303 337 288 345 330] 556\n",
            "[422 300 228 270 318 313 406 311 303 337 288 345 330 556] 322\n",
            "[300 228 270 318 313 406 311 303 337 288 345 330 556 322] 411\n",
            "[228 270 318 313 406 311 303 337 288 345 330 556 322 411] 401\n",
            "[270 318 313 406 311 303 337 288 345 330 556 322 411 401] 241\n",
            "[318 313 406 311 303 337 288 345 330 556 322 411 401 241] 272\n",
            "[406 311 303 337 288 345 330 556 322 411 401 241 272 356] 382\n",
            "[303 337 288 345 330 556 322 411 401 241 272 356 382 471] 403\n",
            "[337 288 345 330 556 322 411 401 241 272 356 382 471 403] 472\n",
            "[288 345 330 556 322 411 401 241 272 356 382 471 403 472] 316\n",
            "[345 330 556 322 411 401 241 272 356 382 471 403 472 316] 361\n",
            "[330 556 322 411 401 241 272 356 382 471 403 472 316 361] 341\n",
            "[411 401 241 272 356 382 471 403 472 316 361 341 443 396] 352\n",
            "[401 241 272 356 382 471 403 472 316 361 341 443 396 352] 333\n",
            "[272 356 382 471 403 472 316 361 341 443 396 352 333 412] 219\n",
            "[382 471 403 472 316 361 341 443 396 352 333 412 219 374] 236\n",
            "[471 403 472 316 361 341 443 396 352 333 412 219 374 236] 292\n",
            "[403 472 316 361 341 443 396 352 333 412 219 374 236 292] 361\n",
            "[316 361 341 443 396 352 333 412 219 374 236 292 361 362] 576\n",
            "[361 341 443 396 352 333 412 219 374 236 292 361 362 576] 575\n",
            "[341 443 396 352 333 412 219 374 236 292 361 362 576 575] 599\n",
            "[443 396 352 333 412 219 374 236 292 361 362 576 575 599] 400\n",
            "[352 333 412 219 374 236 292 361 362 576 575 599 400 282] 359\n",
            "[412 219 374 236 292 361 362 576 575 599 400 282 359 376] 440\n",
            "[374 236 292 361 362 576 575 599 400 282 359 376 440 375] 396\n",
            "[236 292 361 362 576 575 599 400 282 359 376 440 375 396] 407\n",
            "[292 361 362 576 575 599 400 282 359 376 440 375 396 407] 450\n",
            "[361 362 576 575 599 400 282 359 376 440 375 396 407 450] 314\n",
            "[362 576 575 599 400 282 359 376 440 375 396 407 450 314] 352\n",
            "[575 599 400 282 359 376 440 375 396 407 450 314 352 309] 311\n",
            "[599 400 282 359 376 440 375 396 407 450 314 352 309 311] 296\n",
            "[400 282 359 376 440 375 396 407 450 314 352 309 311 296] 300\n",
            "[359 376 440 375 396 407 450 314 352 309 311 296 300 294] 298\n",
            "[376 440 375 396 407 450 314 352 309 311 296 300 294 298] 276\n",
            "[440 375 396 407 450 314 352 309 311 296 300 294 298 276] 319\n",
            "[375 396 407 450 314 352 309 311 296 300 294 298 276 319] 193\n",
            "[396 407 450 314 352 309 311 296 300 294 298 276 319 193] 247\n",
            "[407 450 314 352 309 311 296 300 294 298 276 319 193 247] 239\n",
            "[450 314 352 309 311 296 300 294 298 276 319 193 247 239] 382\n",
            "[314 352 309 311 296 300 294 298 276 319 193 247 239 382] 371\n",
            "[311 296 300 294 298 276 319 193 247 239 382 371 259 314] 231\n",
            "[296 300 294 298 276 319 193 247 239 382 371 259 314 231] 205\n",
            "[300 294 298 276 319 193 247 239 382 371 259 314 231 205] 257\n",
            "[294 298 276 319 193 247 239 382 371 259 314 231 205 257] 277\n",
            "[298 276 319 193 247 239 382 371 259 314 231 205 257 277] 262\n",
            "[276 319 193 247 239 382 371 259 314 231 205 257 277 262] 265\n",
            "[319 193 247 239 382 371 259 314 231 205 257 277 262 265] 305\n",
            "[193 247 239 382 371 259 314 231 205 257 277 262 265 305] 370\n",
            "[247 239 382 371 259 314 231 205 257 277 262 265 305 370] 299\n",
            "[382 371 259 314 231 205 257 277 262 265 305 370 299 267] 264\n",
            "[371 259 314 231 205 257 277 262 265 305 370 299 267 264] 333\n",
            "[259 314 231 205 257 277 262 265 305 370 299 267 264 333] 353\n",
            "[314 231 205 257 277 262 265 305 370 299 267 264 333 353] 339\n",
            "[231 205 257 277 262 265 305 370 299 267 264 333 353 339] 358\n",
            "[205 257 277 262 265 305 370 299 267 264 333 353 339 358] 279\n",
            "[277 262 265 305 370 299 267 264 333 353 339 358 279 399] 380\n",
            "[262 265 305 370 299 267 264 333 353 339 358 279 399 380] 418\n",
            "[265 305 370 299 267 264 333 353 339 358 279 399 380 418] 458\n",
            "[299 267 264 333 353 339 358 279 399 380 418 458 584 443] 337\n",
            "[267 264 333 353 339 358 279 399 380 418 458 584 443 337] 502\n",
            "[333 353 339 358 279 399 380 418 458 584 443 337 502 512] 615\n",
            "[353 339 358 279 399 380 418 458 584 443 337 502 512 615] 657\n",
            "[339 358 279 399 380 418 458 584 443 337 502 512 615 657] 658\n",
            "[358 279 399 380 418 458 584 443 337 502 512 615 657 658] 548\n",
            "[279 399 380 418 458 584 443 337 502 512 615 657 658 548] 575\n",
            "[399 380 418 458 584 443 337 502 512 615 657 658 548 575] 680\n",
            "[380 418 458 584 443 337 502 512 615 657 658 548 575 680] 640\n",
            "[458 584 443 337 502 512 615 657 658 548 575 680 640 726] 809\n",
            "[443 337 502 512 615 657 658 548 575 680 640 726 809 843] 624\n",
            "[337 502 512 615 657 658 548 575 680 640 726 809 843 624] 619\n",
            "[512 615 657 658 548 575 680 640 726 809 843 624 619 551] 715\n",
            "[615 657 658 548 575 680 640 726 809 843 624 619 551 715] 811\n",
            "[657 658 548 575 680 640 726 809 843 624 619 551 715 811] 825\n",
            "[658 548 575 680 640 726 809 843 624 619 551 715 811 825] 778\n",
            "[548 575 680 640 726 809 843 624 619 551 715 811 825 778] 594\n",
            "[575 680 640 726 809 843 624 619 551 715 811 825 778 594] 595\n",
            "[680 640 726 809 843 624 619 551 715 811 825 778 594 595] 597\n",
            "[726 809 843 624 619 551 715 811 825 778 594 595 597 735] 767\n",
            "[809 843 624 619 551 715 811 825 778 594 595 597 735 767] 903\n",
            "[843 624 619 551 715 811 825 778 594 595 597 735 767 903] 900\n",
            "[619 551 715 811 825 778 594 595 597 735 767 903 900 581] 548\n",
            "[715 811 825 778 594 595 597 735 767 903 900 581 548 763] 729\n",
            "[811 825 778 594 595 597 735 767 903 900 581 548 763 729] 887\n",
            "[778 594 595 597 735 767 903 900 581 548 763 729 887 791] 759\n",
            "[594 595 597 735 767 903 900 581 548 763 729 887 791 759] 631\n",
            "[595 597 735 767 903 900 581 548 763 729 887 791 759 631] 502\n",
            "[597 735 767 903 900 581 548 763 729 887 791 759 631 502] 550\n",
            "[735 767 903 900 581 548 763 729 887 791 759 631 502 550] 595\n",
            "[767 903 900 581 548 763 729 887 791 759 631 502 550 595] 612\n",
            "[903 900 581 548 763 729 887 791 759 631 502 550 595 612] 691\n",
            "[900 581 548 763 729 887 791 759 631 502 550 595 612 691] 567\n",
            "[581 548 763 729 887 791 759 631 502 550 595 612 691 567] 437\n",
            "[763 729 887 791 759 631 502 550 595 612 691 567 437 302] 400\n",
            "[729 887 791 759 631 502 550 595 612 691 567 437 302 400] 421\n",
            "[887 791 759 631 502 550 595 612 691 567 437 302 400 421] 506\n",
            "[791 759 631 502 550 595 612 691 567 437 302 400 421 506] 594\n",
            "[631 502 550 595 612 691 567 437 302 400 421 506 594 603] 502\n",
            "[502 550 595 612 691 567 437 302 400 421 506 594 603 502] 377\n",
            "[550 595 612 691 567 437 302 400 421 506 594 603 502 377] 605\n",
            "[595 612 691 567 437 302 400 421 506 594 603 502 377 605] 600\n",
            "[612 691 567 437 302 400 421 506 594 603 502 377 605 600] 837\n",
            "[691 567 437 302 400 421 506 594 603 502 377 605 600 837] 757\n",
            "[567 437 302 400 421 506 594 603 502 377 605 600 837 757] 1002\n",
            "[ 302  400  421  506  594  603  502  377  605  600  837  757 1002  910] 748\n",
            "[ 400  421  506  594  603  502  377  605  600  837  757 1002  910  748] 711\n",
            "[ 506  594  603  502  377  605  600  837  757 1002  910  748  711  974] 1136\n",
            "[ 603  502  377  605  600  837  757 1002  910  748  711  974 1136 1587] 1584\n",
            "[ 502  377  605  600  837  757 1002  910  748  711  974 1136 1587 1584] 1350\n",
            "[ 377  605  600  837  757 1002  910  748  711  974 1136 1587 1584 1350] 1306\n",
            "[ 600  837  757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326] 1552\n",
            "[ 837  757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326 1552] 1967\n",
            "[ 757 1002  910  748  711  974 1136 1587 1584 1350 1306 1326 1552 1967] 2292\n",
            "[1002  910  748  711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292] 2367\n",
            "[ 910  748  711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367] 1934\n",
            "[ 748  711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934] 2006\n",
            "[ 711  974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006] 2236\n",
            "[ 974 1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236] 3003\n",
            "[1136 1587 1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003] 4280\n",
            "[1584 1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739] 5300\n",
            "[1350 1306 1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300] 4178\n",
            "[1326 1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394] 5068\n",
            "[1552 1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068] 6526\n",
            "[1967 2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526] 8099\n",
            "[2292 2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099] 7705\n",
            "[2367 1934 2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705] 9622\n",
            "[2006 2236 3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536] 7482\n",
            "[3003 4280 4739 5300 4178 4394 5068 6526 8099 7705 9622 8536 7482 9291] 10040\n",
            "[ 4280  4739  5300  4178  4394  5068  6526  8099  7705  9622  8536  7482\n",
            "  9291 10040] 12107\n",
            "[ 4739  5300  4178  4394  5068  6526  8099  7705  9622  8536  7482  9291\n",
            " 10040 12107] 13632\n",
            "[ 5300  4178  4394  5068  6526  8099  7705  9622  8536  7482  9291 10040\n",
            " 12107 13632] 13628\n",
            "[ 4178  4394  5068  6526  8099  7705  9622  8536  7482  9291 10040 12107\n",
            " 13632 13628] 11742\n",
            "[ 4394  5068  6526  8099  7705  9622  8536  7482  9291 10040 12107 13632\n",
            " 13628 11742] 10241\n",
            "[ 5068  6526  8099  7705  9622  8536  7482  9291 10040 12107 13632 13628\n",
            " 11742 10241] 16300\n",
            "[ 8099  7705  9622  8536  7482  9291 10040 12107 13632 13628 11742 10241\n",
            " 16300 18820] 20156\n",
            "[ 9622  8536  7482  9291 10040 12107 13632 13628 11742 10241 16300 18820\n",
            " 20156 21629] 21897\n",
            "[ 8536  7482  9291 10040 12107 13632 13628 11742 10241 16300 18820 20156\n",
            " 21629 21897] 17171\n",
            "[ 7482  9291 10040 12107 13632 13628 11742 10241 16300 18820 20156 21629\n",
            " 21897 17171] 15578\n",
            "[ 9291 10040 12107 13632 13628 11742 10241 16300 18820 20156 21629 21897\n",
            " 17171 15578] 19364\n",
            "[10040 12107 13632 13628 11742 10241 16300 18820 20156 21629 21897 17171\n",
            " 15578 19364] 24692\n",
            "[12107 13632 13628 11742 10241 16300 18820 20156 21629 21897 17171 15578\n",
            " 19364 24692] 27143\n",
            "[13632 13628 11742 10241 16300 18820 20156 21629 21897 17171 15578 19364\n",
            " 24692 27143] 27086\n",
            "[13628 11742 10241 16300 18820 20156 21629 21897 17171 15578 19364 24692\n",
            " 27143 27086] 27875\n",
            "[11742 10241 16300 18820 20156 21629 21897 17171 15578 19364 24692 27143\n",
            " 27086 27875] 24785\n",
            "[18820 20156 21629 21897 17171 15578 19364 24692 27143 27086 27875 24785\n",
            " 21713 25454] 25221\n",
            "[20156 21629 21897 17171 15578 19364 24692 27143 27086 27875 24785 21713\n",
            " 25454 25221] 22683\n",
            "[21629 21897 17171 15578 19364 24692 27143 27086 27875 24785 21713 25454\n",
            " 25221 22683] 24051\n",
            "[21897 17171 15578 19364 24692 27143 27086 27875 24785 21713 25454 25221\n",
            " 22683 24051] 25571\n",
            "[17171 15578 19364 24692 27143 27086 27875 24785 21713 25454 25221 22683\n",
            " 24051 25571] 21854\n",
            "[15578 19364 24692 27143 27086 27875 24785 21713 25454 25221 22683 24051\n",
            " 25571 21854] 20816\n",
            "[27143 27086 27875 24785 21713 25454 25221 22683 24051 25571 21854 20816\n",
            " 19152 19883] 23975\n",
            "[27086 27875 24785 21713 25454 25221 22683 24051 25571 21854 20816 19152\n",
            " 19883 23975] 22464\n",
            "[27875 24785 21713 25454 25221 22683 24051 25571 21854 20816 19152 19883\n",
            " 23975 22464] 24213\n",
            "[24785 21713 25454 25221 22683 24051 25571 21854 20816 19152 19883 23975\n",
            " 22464 24213] 17856\n",
            "[21713 25454 25221 22683 24051 25571 21854 20816 19152 19883 23975 22464\n",
            " 24213 17856] 15002\n",
            "[25454 25221 22683 24051 25571 21854 20816 19152 19883 23975 22464 24213\n",
            " 17856 15002] 32733\n",
            "[25221 22683 24051 25571 21854 20816 19152 19883 23975 22464 24213 17856\n",
            " 15002 32733] 15356\n",
            "[22683 24051 25571 21854 20816 19152 19883 23975 22464 24213 17856 15002\n",
            " 32733 15356] 16690\n",
            "[24051 25571 21854 20816 19152 19883 23975 22464 24213 17856 15002 32733\n",
            " 15356 16690] 17304\n",
            "[25571 21854 20816 19152 19883 23975 22464 24213 17856 15002 32733 15356\n",
            " 16690 17304] 15177\n",
            "[21854 20816 19152 19883 23975 22464 24213 17856 15002 32733 15356 16690\n",
            " 17304 15177] 11482\n",
            "[19152 19883 23975 22464 24213 17856 15002 32733 15356 16690 17304 15177\n",
            " 11482  5736] 9113\n",
            "[23975 22464 24213 17856 15002 32733 15356 16690 17304 15177 11482  5736\n",
            "  9113 13823] 14863\n",
            "[24213 17856 15002 32733 15356 16690 17304 15177 11482  5736  9113 13823\n",
            " 14863 13236] 12427\n",
            "[15002 32733 15356 16690 17304 15177 11482  5736  9113 13823 14863 13236\n",
            " 12427  9176] 4421\n",
            "[32733 15356 16690 17304 15177 11482  5736  9113 13823 14863 13236 12427\n",
            "  9176  4421] 8310\n",
            "[15177 11482  5736  9113 13823 14863 13236 12427  9176  4421  8310 12166\n",
            " 13750 13105] 11499\n",
            "[11482  5736  9113 13823 14863 13236 12427  9176  4421  8310 12166 13750\n",
            " 13105 11499] 8976\n",
            "[ 5736  9113 13823 14863 13236 12427  9176  4421  8310 12166 13750 13105\n",
            " 11499  8976] 4896\n",
            "[ 9113 13823 14863 13236 12427  9176  4421  8310 12166 13750 13105 11499\n",
            "  8976  4896] 6874\n",
            "[13823 14863 13236 12427  9176  4421  8310 12166 13750 13105 11499  8976\n",
            "  4896  6874] 12455\n",
            "[14863 13236 12427  9176  4421  8310 12166 13750 13105 11499  8976  4896\n",
            "  6874 12455] 11953\n",
            "[12427  9176  4421  8310 12166 13750 13105 11499  8976  4896  6874 12455\n",
            " 11953 11010] 11246\n",
            "[ 9176  4421  8310 12166 13750 13105 11499  8976  4896  6874 12455 11953\n",
            " 11010 11246] 8590\n",
            "[ 4421  8310 12166 13750 13105 11499  8976  4896  6874 12455 11953 11010\n",
            " 11246  8590] 4633\n",
            "[ 8310 12166 13750 13105 11499  8976  4896  6874 12455 11953 11010 11246\n",
            "  8590  4633] 7192\n",
            "[12166 13750 13105 11499  8976  4896  6874 12455 11953 11010 11246  8590\n",
            "  4633  7192] 12358\n",
            "[13750 13105 11499  8976  4896  6874 12455 11953 11010 11246  8590  4633\n",
            "  7192 12358] 13115\n",
            "[11499  8976  4896  6874 12455 11953 11010 11246  8590  4633  7192 12358\n",
            " 13115  9081] 4878\n",
            "[ 8976  4896  6874 12455 11953 11010 11246  8590  4633  7192 12358 13115\n",
            "  9081  4878] 3842\n",
            "[ 4896  6874 12455 11953 11010 11246  8590  4633  7192 12358 13115  9081\n",
            "  4878  3842] 3211\n",
            "[ 6874 12455 11953 11010 11246  8590  4633  7192 12358 13115  9081  4878\n",
            "  3842  3211] 7624\n",
            "[12455 11953 11010 11246  8590  4633  7192 12358 13115  9081  4878  3842\n",
            "  3211  7624] 12780\n",
            "[11953 11010 11246  8590  4633  7192 12358 13115  9081  4878  3842  3211\n",
            "  7624 12780] 13464\n",
            "[11010 11246  8590  4633  7192 12358 13115  9081  4878  3842  3211  7624\n",
            " 12780 13464] 10896\n",
            "[11246  8590  4633  7192 12358 13115  9081  4878  3842  3211  7624 12780\n",
            " 13464 10896] 7006\n",
            "[ 8590  4633  7192 12358 13115  9081  4878  3842  3211  7624 12780 13464\n",
            " 10896  7006] 5782\n",
            "[ 4633  7192 12358 13115  9081  4878  3842  3211  7624 12780 13464 10896\n",
            "  7006  5782] 4385\n",
            "[ 7192 12358 13115  9081  4878  3842  3211  7624 12780 13464 10896  7006\n",
            "  5782  4385] 7596\n",
            "[12358 13115  9081  4878  3842  3211  7624 12780 13464 10896  7006  5782\n",
            "  4385  7596] 14220\n",
            "[13115  9081  4878  3842  3211  7624 12780 13464 10896  7006  5782  4385\n",
            "  7596 14220] 12119\n",
            "[ 9081  4878  3842  3211  7624 12780 13464 10896  7006  5782  4385  7596\n",
            " 14220 12119] 8763\n",
            "[ 4878  3842  3211  7624 12780 13464 10896  7006  5782  4385  7596 14220\n",
            " 12119  8763] 10744\n",
            "[ 3842  3211  7624 12780 13464 10896  7006  5782  4385  7596 14220 12119\n",
            "  8763 10744] 9133\n",
            "[ 7624 12780 13464 10896  7006  5782  4385  7596 14220 12119  8763 10744\n",
            "  9133  4863] 5394\n",
            "[12780 13464 10896  7006  5782  4385  7596 14220 12119  8763 10744  9133\n",
            "  4863  5394] 9126\n",
            "[13464 10896  7006  5782  4385  7596 14220 12119  8763 10744  9133  4863\n",
            "  5394  9126] 9436\n",
            "[10896  7006  5782  4385  7596 14220 12119  8763 10744  9133  4863  5394\n",
            "  9126  9436] 7979\n",
            "[ 7006  5782  4385  7596 14220 12119  8763 10744  9133  4863  5394  9126\n",
            "  9436  7979] 7292\n",
            "[ 7596 14220 12119  8763 10744  9133  4863  5394  9126  9436  7979  7292\n",
            "  5970  3332] 4890\n",
            "[14220 12119  8763 10744  9133  4863  5394  9126  9436  7979  7292  5970\n",
            "  3332  4890] 6943\n",
            "[12119  8763 10744  9133  4863  5394  9126  9436  7979  7292  5970  3332\n",
            "  4890  6943] 7008\n",
            "[ 8763 10744  9133  4863  5394  9126  9436  7979  7292  5970  3332  4890\n",
            "  6943  7008] 6693\n",
            "[10744  9133  4863  5394  9126  9436  7979  7292  5970  3332  4890  6943\n",
            "  7008  6693] 6304\n",
            "[9133 4863 5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304] 4566\n",
            "[4863 5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566] 2674\n",
            "[5394 9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674] 4603\n",
            "[9126 9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603] 6790\n",
            "[9436 7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790] 7153\n",
            "[7979 7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153] 6145\n",
            "[7292 5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145] 5864\n",
            "[5970 3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864] 4711\n",
            "[3332 4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711] 2504\n",
            "[4890 6943 7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504] 4326\n",
            "[7008 6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801] 6495\n",
            "[6693 6304 4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495] 6053\n",
            "[4566 2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966] 4725\n",
            "[2674 4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725] 2431\n",
            "[4603 6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431] 3999\n",
            "[6790 7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999] 6960\n",
            "[7153 6145 5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960] 7013\n",
            "[5864 4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378] 6585\n",
            "[4711 2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585] 5334\n",
            "[2504 4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334] 2542\n",
            "[4326 6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542] 5176\n",
            "[6801 6495 6053 5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176] 8699\n",
            "[5966 4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772] 8509\n",
            "[4725 2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509] 7040\n",
            "[2431 3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040] 3891\n",
            "[3999 6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040 3891] 6304\n",
            "[6960 7013 6378 6585 5334 2542 5176 8699 9074 8772 8509 7040 3891 6304] 12147\n",
            "[ 7013  6378  6585  5334  2542  5176  8699  9074  8772  8509  7040  3891\n",
            "  6304 12147] 12143\n",
            "[ 6378  6585  5334  2542  5176  8699  9074  8772  8509  7040  3891  6304\n",
            " 12147 12143] 11536\n",
            "[ 6585  5334  2542  5176  8699  9074  8772  8509  7040  3891  6304 12147\n",
            " 12143 11536] 12097\n",
            "[ 5334  2542  5176  8699  9074  8772  8509  7040  3891  6304 12147 12143\n",
            " 11536 12097] 10101\n",
            "[ 2542  5176  8699  9074  8772  8509  7040  3891  6304 12147 12143 11536\n",
            " 12097 10101] 4786\n",
            "[ 5176  8699  9074  8772  8509  7040  3891  6304 12147 12143 11536 12097\n",
            " 10101  4786] 7936\n",
            "[ 8699  9074  8772  8509  7040  3891  6304 12147 12143 11536 12097 10101\n",
            "  4786  7936] 15698\n",
            "[ 9074  8772  8509  7040  3891  6304 12147 12143 11536 12097 10101  4786\n",
            "  7936 15698] 15253\n",
            "[ 8772  8509  7040  3891  6304 12147 12143 11536 12097 10101  4786  7936\n",
            " 15698 15253] 15831\n",
            "[ 7040  3891  6304 12147 12143 11536 12097 10101  4786  7936 15698 15253\n",
            " 15831 14855] 13569\n",
            "[ 6304 12147 12143 11536 12097 10101  4786  7936 15698 15253 15831 14855\n",
            " 13569  6169] 9953\n",
            "[12147 12143 11536 12097 10101  4786  7936 15698 15253 15831 14855 13569\n",
            "  6169  9953] 17277\n",
            "[12143 11536 12097 10101  4786  7936 15698 15253 15831 14855 13569  6169\n",
            "  9953 17277] 21111\n",
            "[11536 12097 10101  4786  7936 15698 15253 15831 14855 13569  6169  9953\n",
            " 17277 21111] 18873\n",
            "[10101  4786  7936 15698 15253 15831 14855 13569  6169  9953 17277 21111\n",
            " 18873 21063] 17272\n",
            "[ 4786  7936 15698 15253 15831 14855 13569  6169  9953 17277 21111 18873\n",
            " 21063 17272] 10895\n",
            "[ 7936 15698 15253 15831 14855 13569  6169  9953 17277 21111 18873 21063\n",
            " 17272 10895] 14394\n",
            "[15698 15253 15831 14855 13569  6169  9953 17277 21111 18873 21063 17272\n",
            " 10895 14394] 25053\n",
            "[15253 15831 14855 13569  6169  9953 17277 21111 18873 21063 17272 10895\n",
            " 14394 25053] 27274\n",
            "[15831 14855 13569  6169  9953 17277 21111 18873 21063 17272 10895 14394\n",
            " 25053 27274] 25996\n",
            "[13569  6169  9953 17277 21111 18873 21063 17272 10895 14394 25053 27274\n",
            " 25996 26456] 21850\n",
            "[ 6169  9953 17277 21111 18873 21063 17272 10895 14394 25053 27274 25996\n",
            " 26456 21850] 14579\n",
            "[ 9953 17277 21111 18873 21063 17272 10895 14394 25053 27274 25996 26456\n",
            " 21850 14579] 16740\n",
            "[21111 18873 21063 17272 10895 14394 25053 27274 25996 26456 21850 14579\n",
            " 16740 30802] 34150\n",
            "[18873 21063 17272 10895 14394 25053 27274 25996 26456 21850 14579 16740\n",
            " 30802 34150] 35145\n",
            "[21063 17272 10895 14394 25053 27274 25996 26456 21850 14579 16740 30802\n",
            " 34150 35145] 31759\n",
            "[17272 10895 14394 25053 27274 25996 26456 21850 14579 16740 30802 34150\n",
            " 35145 31759] 29266\n",
            "[10895 14394 25053 27274 25996 26456 21850 14579 16740 30802 34150 35145\n",
            " 31759 29266] 16973\n",
            "[14394 25053 27274 25996 26456 21850 14579 16740 30802 34150 35145 31759\n",
            " 29266 16973] 20862\n",
            "[25053 27274 25996 26456 21850 14579 16740 30802 34150 35145 31759 29266\n",
            " 16973 20862] 32891\n",
            "[27274 25996 26456 21850 14579 16740 30802 34150 35145 31759 29266 16973\n",
            " 20862 32891] 35253\n",
            "[25996 26456 21850 14579 16740 30802 34150 35145 31759 29266 16973 20862\n",
            " 32891 35253] 30541\n",
            "[26456 21850 14579 16740 30802 34150 35145 31759 29266 16973 20862 32891\n",
            " 35253 30541] 28073\n",
            "[21850 14579 16740 30802 34150 35145 31759 29266 16973 20862 32891 35253\n",
            " 30541 28073] 22958\n",
            "[16740 30802 34150 35145 31759 29266 16973 20862 32891 35253 30541 28073\n",
            " 22958  9921] 8246\n",
            "[30802 34150 35145 31759 29266 16973 20862 32891 35253 30541 28073 22958\n",
            "  9921  8246] 14908\n",
            "[34150 35145 31759 29266 16973 20862 32891 35253 30541 28073 22958  9921\n",
            "  8246 14908] 27890\n",
            "[35145 31759 29266 16973 20862 32891 35253 30541 28073 22958  9921  8246\n",
            " 14908 27890] 28499\n",
            "[31759 29266 16973 20862 32891 35253 30541 28073 22958  9921  8246 14908\n",
            " 27890 28499] 24892\n",
            "[29266 16973 20862 32891 35253 30541 28073 22958  9921  8246 14908 27890\n",
            " 28499 24892] 21733\n",
            "[16973 20862 32891 35253 30541 28073 22958  9921  8246 14908 27890 28499\n",
            " 24892 21733] 12016\n",
            "[20862 32891 35253 30541 28073 22958  9921  8246 14908 27890 28499 24892\n",
            " 21733 12016] 13203\n",
            "[32891 35253 30541 28073 22958  9921  8246 14908 27890 28499 24892 21733\n",
            " 12016 13203] 21266\n",
            "[30541 28073 22958  9921  8246 14908 27890 28499 24892 21733 12016 13203\n",
            " 21266 21126] 17846\n",
            "[28073 22958  9921  8246 14908 27890 28499 24892 21733 12016 13203 21266\n",
            " 21126 17846] 15786\n",
            "[ 8246 14908 27890 28499 24892 21733 12016 13203 21266 21126 17846 15786\n",
            " 12151  7302] 9244\n",
            "[28499 24892 21733 12016 13203 21266 21126 17846 15786 12151  7302  9244\n",
            " 13922 12763] 10866\n",
            "[21733 12016 13203 21266 21126 17846 15786 12151  7302  9244 13922 12763\n",
            " 10866  9510] 7224\n",
            "[12016 13203 21266 21126 17846 15786 12151  7302  9244 13922 12763 10866\n",
            "  9510  7224] 3467\n",
            "[13203 21266 21126 17846 15786 12151  7302  9244 13922 12763 10866  9510\n",
            "  7224  3467] 5711\n",
            "[21266 21126 17846 15786 12151  7302  9244 13922 12763 10866  9510  7224\n",
            "  3467  5711] 8893\n",
            "[21126 17846 15786 12151  7302  9244 13922 12763 10866  9510  7224  3467\n",
            "  5711  8893] 8426\n",
            "[17846 15786 12151  7302  9244 13922 12763 10866  9510  7224  3467  5711\n",
            "  8893  8426] 6789\n",
            "[15786 12151  7302  9244 13922 12763 10866  9510  7224  3467  5711  8893\n",
            "  8426  6789] 6475\n",
            "[12151  7302  9244 13922 12763 10866  9510  7224  3467  5711  8893  8426\n",
            "  6789  6475] 4616\n",
            "[ 7302  9244 13922 12763 10866  9510  7224  3467  5711  8893  8426  6789\n",
            "  6475  4616] 2523\n",
            "[ 9244 13922 12763 10866  9510  7224  3467  5711  8893  8426  6789  6475\n",
            "  4616  2523] 2296\n",
            "[13922 12763 10866  9510  7224  3467  5711  8893  8426  6789  6475  4616\n",
            "  2523  2296] 3899\n",
            "[12763 10866  9510  7224  3467  5711  8893  8426  6789  6475  4616  2523\n",
            "  2296  3899] 6427\n",
            "[10866  9510  7224  3467  5711  8893  8426  6789  6475  4616  2523  2296\n",
            "  3899  6427] 6047\n",
            "[9510 7224 3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047] 4771\n",
            "[7224 3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771] 3856\n",
            "[3467 5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856] 2031\n",
            "[5711 8893 8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031] 3097\n",
            "[8426 6789 6475 4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948] 3694\n",
            "[4616 2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897] 2169\n",
            "[2523 2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169] 1111\n",
            "[2296 3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111] 1727\n",
            "[3899 6427 6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727] 2348\n",
            "[6047 4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087] 1678\n",
            "[4771 3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678] 1517\n",
            "[3856 2031 3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517] 1075\n",
            "[3097 3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559] 1000\n",
            "[3948 3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000] 1267\n",
            "[3694 3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267] 1227\n",
            "[3289 2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227] 946\n",
            "[2897 2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946] 775\n",
            "[2169 1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946  775] 579\n",
            "[1111 1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946  775  579] 333\n",
            "[1727 2348 2087 1678 1517 1075  559 1000 1267 1227  946  775  579  333] 588\n",
            "[2348 2087 1678 1517 1075  559 1000 1267 1227  946  775  579  333  588] 659\n",
            "[2087 1678 1517 1075  559 1000 1267 1227  946  775  579  333  588  659] 572\n",
            "[1678 1517 1075  559 1000 1267 1227  946  775  579  333  588  659  572] 317\n",
            "[1517 1075  559 1000 1267 1227  946  775  579  333  588  659  572  317] 415\n",
            "[1075  559 1000 1267 1227  946  775  579  333  588  659  572  317  415] 310\n",
            "[ 559 1000 1267 1227  946  775  579  333  588  659  572  317  415  310] 195\n",
            "[1000 1267 1227  946  775  579  333  588  659  572  317  415  310  195] 532\n",
            "[1267 1227  946  775  579  333  588  659  572  317  415  310  195  532] 428\n",
            "[775 579 333 588 659 572 317 415 310 195 532 428 382 341] 238\n",
            "[579 333 588 659 572 317 415 310 195 532 428 382 341 238] 226\n",
            "[333 588 659 572 317 415 310 195 532 428 382 341 238 226] 140\n",
            "[588 659 572 317 415 310 195 532 428 382 341 238 226 140] 215\n",
            "[659 572 317 415 310 195 532 428 382 341 238 226 140 215] 238\n",
            "[572 317 415 310 195 532 428 382 341 238 226 140 215 238] 218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0PLxD5xXyz"
      },
      "source": [
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "Validation_X = Validation_X.reshape((Validation_X.shape[0], Validation_X.shape[1], n_features))\n",
        "Y = Y.reshape((Y.shape[0], 1, n_features))\n",
        "Validation_Y = Validation_Y.reshape((Validation_Y.shape[0], 1, n_features))\n",
        "look_back = n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_-ZW77mxava",
        "outputId": "b2a53adf-1415-4344-9a4c-c6c05126e5d2"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(368, 14, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw8wRQf3BCKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9f74ca-648f-47b9-ef93-3cca4685a5cb"
      },
      "source": [
        "#creating the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    LSTM(50,\n",
        "        activation='relu',\n",
        "        input_shape=(look_back,1))\n",
        ")\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "num_epochs = 12000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEeHxQe8xk84",
        "outputId": "9f9ac9c2-84c8-4835-92bb-26394e7d7e33"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kBvWEfHxn5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddffc98-c751-4862-dcda-b086d833f8bf"
      },
      "source": [
        "history = model.fit(X, Y, epochs=num_epochs, validation_data=(X,Y), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n",
            "Epoch 9501/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2216.2378 - val_loss: 2201.4485\n",
            "Epoch 9502/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2332.9154 - val_loss: 2203.0974\n",
            "Epoch 9503/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2170.9656 - val_loss: 2172.9629\n",
            "Epoch 9504/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2142.5587 - val_loss: 2079.8752\n",
            "Epoch 9505/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 2204.6524 - val_loss: 2110.5115\n",
            "Epoch 9506/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2060.3557 - val_loss: 2090.7419\n",
            "Epoch 9507/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2351.7951 - val_loss: 2062.3484\n",
            "Epoch 9508/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1677.2447 - val_loss: 2052.3262\n",
            "Epoch 9509/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2136.2157 - val_loss: 2007.4900\n",
            "Epoch 9510/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1987.0167 - val_loss: 2059.3228\n",
            "Epoch 9511/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1991.9826 - val_loss: 1984.6532\n",
            "Epoch 9512/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2016.4377 - val_loss: 1983.5665\n",
            "Epoch 9513/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2025.5667 - val_loss: 1932.9731\n",
            "Epoch 9514/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1846.8042 - val_loss: 1979.8344\n",
            "Epoch 9515/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2227.0785 - val_loss: 1983.8972\n",
            "Epoch 9516/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1939.6758 - val_loss: 1948.5133\n",
            "Epoch 9517/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2206.6683 - val_loss: 2006.0673\n",
            "Epoch 9518/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2202.7104 - val_loss: 1936.9834\n",
            "Epoch 9519/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2081.0952 - val_loss: 1944.3121\n",
            "Epoch 9520/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2004.4576 - val_loss: 1950.0038\n",
            "Epoch 9521/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2062.2825 - val_loss: 1933.7273\n",
            "Epoch 9522/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1877.3328 - val_loss: 1974.7327\n",
            "Epoch 9523/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2218.7970 - val_loss: 2023.1549\n",
            "Epoch 9524/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2200.5462 - val_loss: 2020.7952\n",
            "Epoch 9525/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2063.1569 - val_loss: 2006.4285\n",
            "Epoch 9526/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1867.5277 - val_loss: 2006.3186\n",
            "Epoch 9527/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2016.1189 - val_loss: 2034.7296\n",
            "Epoch 9528/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2167.7901 - val_loss: 2012.9700\n",
            "Epoch 9529/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1979.8726 - val_loss: 2013.8788\n",
            "Epoch 9530/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1914.9613 - val_loss: 2014.9528\n",
            "Epoch 9531/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1952.3019 - val_loss: 2001.2223\n",
            "Epoch 9532/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1912.3083 - val_loss: 1966.4066\n",
            "Epoch 9533/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1710.6282 - val_loss: 1947.6271\n",
            "Epoch 9534/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1842.5208 - val_loss: 1976.5925\n",
            "Epoch 9535/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1726.1549 - val_loss: 1992.6732\n",
            "Epoch 9536/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2112.7469 - val_loss: 2005.4471\n",
            "Epoch 9537/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2035.7393 - val_loss: 1961.0920\n",
            "Epoch 9538/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2076.7541 - val_loss: 1929.6975\n",
            "Epoch 9539/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1899.0816 - val_loss: 1858.3085\n",
            "Epoch 9540/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2027.8763 - val_loss: 1845.5291\n",
            "Epoch 9541/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1717.5745 - val_loss: 1829.7646\n",
            "Epoch 9542/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1964.0189 - val_loss: 1874.5859\n",
            "Epoch 9543/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1933.1704 - val_loss: 1839.3085\n",
            "Epoch 9544/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1921.0195 - val_loss: 1822.7942\n",
            "Epoch 9545/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1925.9859 - val_loss: 1861.4594\n",
            "Epoch 9546/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1849.0739 - val_loss: 1828.0333\n",
            "Epoch 9547/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1655.4307 - val_loss: 1782.3811\n",
            "Epoch 9548/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1901.7258 - val_loss: 1772.4670\n",
            "Epoch 9549/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1912.3710 - val_loss: 1742.5894\n",
            "Epoch 9550/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1680.9806 - val_loss: 1852.2244\n",
            "Epoch 9551/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1662.8504 - val_loss: 1874.2461\n",
            "Epoch 9552/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1984.8423 - val_loss: 1942.3829\n",
            "Epoch 9553/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2390.4174 - val_loss: 2604.7512\n",
            "Epoch 9554/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 2476.7318 - val_loss: 2245.5532\n",
            "Epoch 9555/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2497.2804 - val_loss: 2089.4819\n",
            "Epoch 9556/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1828.7577 - val_loss: 1957.2499\n",
            "Epoch 9557/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2008.0445 - val_loss: 1878.1930\n",
            "Epoch 9558/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1869.2510 - val_loss: 2215.0469\n",
            "Epoch 9559/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2113.4014 - val_loss: 2258.6196\n",
            "Epoch 9560/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2224.8116 - val_loss: 2352.4624\n",
            "Epoch 9561/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2232.8126 - val_loss: 2323.0415\n",
            "Epoch 9562/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2332.2539 - val_loss: 2376.2249\n",
            "Epoch 9563/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2421.4303 - val_loss: 2347.0762\n",
            "Epoch 9564/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2338.4058 - val_loss: 2319.7205\n",
            "Epoch 9565/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2247.1079 - val_loss: 2214.9731\n",
            "Epoch 9566/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2196.0558 - val_loss: 2174.8113\n",
            "Epoch 9567/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2256.4799 - val_loss: 2156.5437\n",
            "Epoch 9568/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2273.7203 - val_loss: 2042.8420\n",
            "Epoch 9569/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2009.3224 - val_loss: 2042.6531\n",
            "Epoch 9570/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1883.7161 - val_loss: 2048.8904\n",
            "Epoch 9571/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2049.7177 - val_loss: 2047.6383\n",
            "Epoch 9572/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1875.7103 - val_loss: 2053.2236\n",
            "Epoch 9573/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2176.3097 - val_loss: 2030.7158\n",
            "Epoch 9574/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1887.9501 - val_loss: 2084.0166\n",
            "Epoch 9575/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2152.4243 - val_loss: 2086.2151\n",
            "Epoch 9576/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1933.3729 - val_loss: 2178.4773\n",
            "Epoch 9577/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2146.8775 - val_loss: 2161.5085\n",
            "Epoch 9578/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1864.4310 - val_loss: 2104.1672\n",
            "Epoch 9579/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2050.3595 - val_loss: 2020.3434\n",
            "Epoch 9580/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1877.8513 - val_loss: 2045.9696\n",
            "Epoch 9581/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2025.6178 - val_loss: 2068.8062\n",
            "Epoch 9582/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1945.6692 - val_loss: 2054.9536\n",
            "Epoch 9583/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1970.6979 - val_loss: 2017.8914\n",
            "Epoch 9584/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1854.7728 - val_loss: 2018.6115\n",
            "Epoch 9585/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1804.2525 - val_loss: 2213.6726\n",
            "Epoch 9586/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2124.6825 - val_loss: 2016.4061\n",
            "Epoch 9587/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2052.5025 - val_loss: 1956.4010\n",
            "Epoch 9588/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2261.2794 - val_loss: 1962.3638\n",
            "Epoch 9589/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1726.4272 - val_loss: 1943.0856\n",
            "Epoch 9590/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 2099.1358 - val_loss: 2017.3311\n",
            "Epoch 9591/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1775.1168 - val_loss: 2014.9883\n",
            "Epoch 9592/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2070.0721 - val_loss: 1933.4078\n",
            "Epoch 9593/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1825.8064 - val_loss: 1965.3079\n",
            "Epoch 9594/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2018.8915 - val_loss: 2001.5997\n",
            "Epoch 9595/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1899.7907 - val_loss: 1952.9633\n",
            "Epoch 9596/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2071.1872 - val_loss: 1922.8033\n",
            "Epoch 9597/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1914.6541 - val_loss: 1860.2544\n",
            "Epoch 9598/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2004.9634 - val_loss: 1930.8694\n",
            "Epoch 9599/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1709.9998 - val_loss: 1811.9900\n",
            "Epoch 9600/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1643.6733 - val_loss: 1778.2942\n",
            "Epoch 9601/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1599.2266 - val_loss: 1731.7546\n",
            "Epoch 9602/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1902.1775 - val_loss: 1711.2960\n",
            "Epoch 9603/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1798.9739 - val_loss: 1717.1219\n",
            "Epoch 9604/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1600.4546 - val_loss: 1682.8224\n",
            "Epoch 9605/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1599.7139 - val_loss: 1723.5422\n",
            "Epoch 9606/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1747.4310 - val_loss: 1779.4948\n",
            "Epoch 9607/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1910.2651 - val_loss: 1777.5494\n",
            "Epoch 9608/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1611.9677 - val_loss: 1745.8015\n",
            "Epoch 9609/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1677.7868 - val_loss: 1836.4281\n",
            "Epoch 9610/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1967.2282 - val_loss: 1805.8210\n",
            "Epoch 9611/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1782.4695 - val_loss: 1877.6206\n",
            "Epoch 9612/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1780.1872 - val_loss: 1788.8295\n",
            "Epoch 9613/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1652.9001 - val_loss: 1755.2935\n",
            "Epoch 9614/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1918.6224 - val_loss: 1683.7257\n",
            "Epoch 9615/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1761.7169 - val_loss: 1681.5431\n",
            "Epoch 9616/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1600.9337 - val_loss: 1670.9993\n",
            "Epoch 9617/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1649.9897 - val_loss: 1773.8733\n",
            "Epoch 9618/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1710.6606 - val_loss: 1763.3665\n",
            "Epoch 9619/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1682.0661 - val_loss: 1770.3269\n",
            "Epoch 9620/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1793.7360 - val_loss: 1729.7275\n",
            "Epoch 9621/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1887.7409 - val_loss: 1726.7028\n",
            "Epoch 9622/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1771.1272 - val_loss: 1751.0469\n",
            "Epoch 9623/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1752.8001 - val_loss: 1753.4708\n",
            "Epoch 9624/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1625.2185 - val_loss: 1750.0977\n",
            "Epoch 9625/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1681.7757 - val_loss: 1587.1774\n",
            "Epoch 9626/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1810.3197 - val_loss: 1680.4467\n",
            "Epoch 9627/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1557.2568 - val_loss: 1755.8351\n",
            "Epoch 9628/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1776.5678 - val_loss: 1780.8849\n",
            "Epoch 9629/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1909.8907 - val_loss: 1786.0026\n",
            "Epoch 9630/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1830.2941 - val_loss: 1785.7219\n",
            "Epoch 9631/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2037.6006 - val_loss: 1737.2432\n",
            "Epoch 9632/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1594.8507 - val_loss: 1673.7400\n",
            "Epoch 9633/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1761.2044 - val_loss: 1658.7023\n",
            "Epoch 9634/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1592.7650 - val_loss: 1627.4817\n",
            "Epoch 9635/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1640.6692 - val_loss: 1535.5214\n",
            "Epoch 9636/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1457.6965 - val_loss: 1627.0621\n",
            "Epoch 9637/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1475.2113 - val_loss: 1624.7249\n",
            "Epoch 9638/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1769.3025 - val_loss: 1757.3030\n",
            "Epoch 9639/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2004.5850 - val_loss: 1924.7517\n",
            "Epoch 9640/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2035.2801 - val_loss: 1969.5721\n",
            "Epoch 9641/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2128.7475 - val_loss: 1912.5858\n",
            "Epoch 9642/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1937.0179 - val_loss: 1959.4358\n",
            "Epoch 9643/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1913.0742 - val_loss: 2111.0508\n",
            "Epoch 9644/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1967.6942 - val_loss: 1842.3330\n",
            "Epoch 9645/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1729.9241 - val_loss: 1772.1766\n",
            "Epoch 9646/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1792.2678 - val_loss: 1857.6866\n",
            "Epoch 9647/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1869.4897 - val_loss: 1831.6288\n",
            "Epoch 9648/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2084.1842 - val_loss: 1896.4115\n",
            "Epoch 9649/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1942.5073 - val_loss: 1925.3147\n",
            "Epoch 9650/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2159.1414 - val_loss: 1915.1199\n",
            "Epoch 9651/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1733.1519 - val_loss: 1889.2999\n",
            "Epoch 9652/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1937.6454 - val_loss: 1861.1038\n",
            "Epoch 9653/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1933.9909 - val_loss: 1800.4006\n",
            "Epoch 9654/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1910.3175 - val_loss: 1924.2203\n",
            "Epoch 9655/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1644.8263 - val_loss: 1792.4384\n",
            "Epoch 9656/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1754.2473 - val_loss: 1913.8412\n",
            "Epoch 9657/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1851.0075 - val_loss: 1899.0609\n",
            "Epoch 9658/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1888.1223 - val_loss: 1930.4653\n",
            "Epoch 9659/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1777.9274 - val_loss: 1895.1133\n",
            "Epoch 9660/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1650.6350 - val_loss: 1987.4686\n",
            "Epoch 9661/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2115.8232 - val_loss: 1936.9163\n",
            "Epoch 9662/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1987.9060 - val_loss: 1904.1887\n",
            "Epoch 9663/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2020.5668 - val_loss: 1840.9962\n",
            "Epoch 9664/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1839.6046 - val_loss: 1886.4271\n",
            "Epoch 9665/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2251.1728 - val_loss: 1769.5378\n",
            "Epoch 9666/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2087.7528 - val_loss: 1915.6450\n",
            "Epoch 9667/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2068.2906 - val_loss: 1966.2903\n",
            "Epoch 9668/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2121.3978 - val_loss: 1964.1042\n",
            "Epoch 9669/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2051.6697 - val_loss: 1893.5713\n",
            "Epoch 9670/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2007.3510 - val_loss: 1876.8112\n",
            "Epoch 9671/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1742.5202 - val_loss: 1873.4526\n",
            "Epoch 9672/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1757.5226 - val_loss: 1904.8259\n",
            "Epoch 9673/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1967.0871 - val_loss: 1888.9594\n",
            "Epoch 9674/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1800.9992 - val_loss: 1780.1583\n",
            "Epoch 9675/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2048.0935 - val_loss: 1804.0836\n",
            "Epoch 9676/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1818.4403 - val_loss: 1958.2496\n",
            "Epoch 9677/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1965.3247 - val_loss: 1906.2805\n",
            "Epoch 9678/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1766.7701 - val_loss: 1876.9718\n",
            "Epoch 9679/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1874.3872 - val_loss: 1827.3802\n",
            "Epoch 9680/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1874.0334 - val_loss: 1758.0615\n",
            "Epoch 9681/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1977.0122 - val_loss: 1813.0715\n",
            "Epoch 9682/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1738.6466 - val_loss: 1792.0618\n",
            "Epoch 9683/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1897.4159 - val_loss: 1890.9114\n",
            "Epoch 9684/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1825.8101 - val_loss: 1870.9774\n",
            "Epoch 9685/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1865.5781 - val_loss: 1905.3529\n",
            "Epoch 9686/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1810.2834 - val_loss: 1776.7328\n",
            "Epoch 9687/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1891.1882 - val_loss: 1782.5161\n",
            "Epoch 9688/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1724.2837 - val_loss: 1844.3766\n",
            "Epoch 9689/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1910.5861 - val_loss: 1731.1627\n",
            "Epoch 9690/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1912.3293 - val_loss: 1777.0107\n",
            "Epoch 9691/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1943.6629 - val_loss: 1849.9301\n",
            "Epoch 9692/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1734.4104 - val_loss: 1711.6393\n",
            "Epoch 9693/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1447.0502 - val_loss: 1844.2039\n",
            "Epoch 9694/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1831.5597 - val_loss: 1965.6689\n",
            "Epoch 9695/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1944.0852 - val_loss: 2128.7466\n",
            "Epoch 9696/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1709.8675 - val_loss: 2127.6494\n",
            "Epoch 9697/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2111.2937 - val_loss: 2113.5208\n",
            "Epoch 9698/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1963.1007 - val_loss: 1987.7427\n",
            "Epoch 9699/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1798.1893 - val_loss: 1999.5411\n",
            "Epoch 9700/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1984.3459 - val_loss: 1979.7004\n",
            "Epoch 9701/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2026.3824 - val_loss: 1914.9796\n",
            "Epoch 9702/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1857.2463 - val_loss: 1944.3109\n",
            "Epoch 9703/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1677.8858 - val_loss: 1985.1902\n",
            "Epoch 9704/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2257.0817 - val_loss: 2202.4900\n",
            "Epoch 9705/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2145.4884 - val_loss: 2176.9990\n",
            "Epoch 9706/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2012.6228 - val_loss: 1932.4211\n",
            "Epoch 9707/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2237.6070 - val_loss: 2030.8986\n",
            "Epoch 9708/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2157.7366 - val_loss: 2009.0333\n",
            "Epoch 9709/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2077.3427 - val_loss: 1985.2791\n",
            "Epoch 9710/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2103.8731 - val_loss: 1997.8007\n",
            "Epoch 9711/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2185.6068 - val_loss: 2052.7769\n",
            "Epoch 9712/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1850.4410 - val_loss: 1899.0172\n",
            "Epoch 9713/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2160.1580 - val_loss: 1828.9873\n",
            "Epoch 9714/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2111.7300 - val_loss: 1779.9531\n",
            "Epoch 9715/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1801.5649 - val_loss: 1813.9142\n",
            "Epoch 9716/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2000.4986 - val_loss: 1967.0482\n",
            "Epoch 9717/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2141.1104 - val_loss: 1741.3746\n",
            "Epoch 9718/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1622.7992 - val_loss: 1817.0304\n",
            "Epoch 9719/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1710.8470 - val_loss: 1793.3829\n",
            "Epoch 9720/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1829.3813 - val_loss: 1774.0902\n",
            "Epoch 9721/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1753.9641 - val_loss: 1755.3585\n",
            "Epoch 9722/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1750.5448 - val_loss: 1743.8148\n",
            "Epoch 9723/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1562.4467 - val_loss: 1699.7308\n",
            "Epoch 9724/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1757.6276 - val_loss: 1731.6228\n",
            "Epoch 9725/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1683.0386 - val_loss: 1685.3798\n",
            "Epoch 9726/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1653.7247 - val_loss: 1629.8148\n",
            "Epoch 9727/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1766.1547 - val_loss: 1629.5565\n",
            "Epoch 9728/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1691.5052 - val_loss: 1642.7764\n",
            "Epoch 9729/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1506.0461 - val_loss: 1826.4639\n",
            "Epoch 9730/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1879.7555 - val_loss: 1771.3923\n",
            "Epoch 9731/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1885.5905 - val_loss: 1860.5533\n",
            "Epoch 9732/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1989.0729 - val_loss: 1993.5325\n",
            "Epoch 9733/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2195.2031 - val_loss: 1974.0297\n",
            "Epoch 9734/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2029.2038 - val_loss: 1918.1095\n",
            "Epoch 9735/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2031.6751 - val_loss: 2114.2593\n",
            "Epoch 9736/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2011.6550 - val_loss: 2032.1740\n",
            "Epoch 9737/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2218.1256 - val_loss: 1923.2366\n",
            "Epoch 9738/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1917.4421 - val_loss: 2017.1218\n",
            "Epoch 9739/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1995.7754 - val_loss: 1862.5734\n",
            "Epoch 9740/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1775.5047 - val_loss: 1829.9532\n",
            "Epoch 9741/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2035.7188 - val_loss: 1910.3944\n",
            "Epoch 9742/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2049.2240 - val_loss: 1747.3788\n",
            "Epoch 9743/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1698.2582 - val_loss: 1779.2629\n",
            "Epoch 9744/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1690.8570 - val_loss: 1808.4622\n",
            "Epoch 9745/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1759.5248 - val_loss: 1860.8090\n",
            "Epoch 9746/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1897.6546 - val_loss: 1940.7460\n",
            "Epoch 9747/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2024.0369 - val_loss: 1838.8673\n",
            "Epoch 9748/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1933.4608 - val_loss: 1877.5277\n",
            "Epoch 9749/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1813.6583 - val_loss: 1859.7133\n",
            "Epoch 9750/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1758.5176 - val_loss: 1896.5204\n",
            "Epoch 9751/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2150.4114 - val_loss: 1845.4672\n",
            "Epoch 9752/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1781.3551 - val_loss: 1843.6011\n",
            "Epoch 9753/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1686.5504 - val_loss: 1812.7673\n",
            "Epoch 9754/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1795.4121 - val_loss: 1778.6836\n",
            "Epoch 9755/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1679.1933 - val_loss: 1772.4022\n",
            "Epoch 9756/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1801.1359 - val_loss: 1794.1510\n",
            "Epoch 9757/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1680.0805 - val_loss: 1667.0576\n",
            "Epoch 9758/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1496.5462 - val_loss: 1765.6215\n",
            "Epoch 9759/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1655.1185 - val_loss: 1654.9298\n",
            "Epoch 9760/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1762.9747 - val_loss: 1612.2787\n",
            "Epoch 9761/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1557.2830 - val_loss: 1566.9884\n",
            "Epoch 9762/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1779.2912 - val_loss: 1544.5292\n",
            "Epoch 9763/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1408.0343 - val_loss: 1506.2228\n",
            "Epoch 9764/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1605.1482 - val_loss: 1614.3517\n",
            "Epoch 9765/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1494.4316 - val_loss: 1631.9514\n",
            "Epoch 9766/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1541.7391 - val_loss: 1601.2084\n",
            "Epoch 9767/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1563.0051 - val_loss: 1504.1683\n",
            "Epoch 9768/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1532.6459 - val_loss: 1570.9375\n",
            "Epoch 9769/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1580.5735 - val_loss: 1558.3768\n",
            "Epoch 9770/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1557.9373 - val_loss: 1538.2432\n",
            "Epoch 9771/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1406.8828 - val_loss: 1522.7865\n",
            "Epoch 9772/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1366.8065 - val_loss: 1516.9943\n",
            "Epoch 9773/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1592.9823 - val_loss: 1475.8013\n",
            "Epoch 9774/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1656.6658 - val_loss: 1581.9409\n",
            "Epoch 9775/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1752.1553 - val_loss: 1634.8385\n",
            "Epoch 9776/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1745.5288 - val_loss: 1663.6094\n",
            "Epoch 9777/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1659.2051 - val_loss: 1641.1536\n",
            "Epoch 9778/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1947.2106 - val_loss: 1602.9214\n",
            "Epoch 9779/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1507.8097 - val_loss: 1587.3879\n",
            "Epoch 9780/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1580.3312 - val_loss: 1542.0426\n",
            "Epoch 9781/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1514.5532 - val_loss: 1508.3781\n",
            "Epoch 9782/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1483.1003 - val_loss: 1535.9053\n",
            "Epoch 9783/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1427.8600 - val_loss: 1528.7909\n",
            "Epoch 9784/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1431.9541 - val_loss: 1569.0781\n",
            "Epoch 9785/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1620.9890 - val_loss: 1545.9453\n",
            "Epoch 9786/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1573.5669 - val_loss: 1541.8033\n",
            "Epoch 9787/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1664.6303 - val_loss: 1576.5504\n",
            "Epoch 9788/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1738.7072 - val_loss: 1637.3521\n",
            "Epoch 9789/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1595.1788 - val_loss: 1666.7061\n",
            "Epoch 9790/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1540.3147 - val_loss: 1601.8571\n",
            "Epoch 9791/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1626.3896 - val_loss: 1556.0950\n",
            "Epoch 9792/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1546.0214 - val_loss: 1563.5721\n",
            "Epoch 9793/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1725.6145 - val_loss: 1568.5316\n",
            "Epoch 9794/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1591.5846 - val_loss: 1553.3911\n",
            "Epoch 9795/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1665.2245 - val_loss: 1507.1233\n",
            "Epoch 9796/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1590.5551 - val_loss: 1580.1980\n",
            "Epoch 9797/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1512.7619 - val_loss: 1565.9817\n",
            "Epoch 9798/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1717.5495 - val_loss: 1561.2634\n",
            "Epoch 9799/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1644.8338 - val_loss: 1574.3551\n",
            "Epoch 9800/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1618.2879 - val_loss: 1568.0110\n",
            "Epoch 9801/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1438.7436 - val_loss: 1579.7535\n",
            "Epoch 9802/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1797.9213 - val_loss: 1558.9148\n",
            "Epoch 9803/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1482.3398 - val_loss: 1493.9565\n",
            "Epoch 9804/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1578.4804 - val_loss: 1490.2568\n",
            "Epoch 9805/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1641.4269 - val_loss: 1492.8040\n",
            "Epoch 9806/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1392.3347 - val_loss: 1477.4426\n",
            "Epoch 9807/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1545.1370 - val_loss: 1468.1323\n",
            "Epoch 9808/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1545.6213 - val_loss: 1474.9524\n",
            "Epoch 9809/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1420.0958 - val_loss: 1470.7225\n",
            "Epoch 9810/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1616.0022 - val_loss: 1463.6984\n",
            "Epoch 9811/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1404.6171 - val_loss: 1455.7729\n",
            "Epoch 9812/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1336.7415 - val_loss: 1438.8860\n",
            "Epoch 9813/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1324.9688 - val_loss: 1447.9960\n",
            "Epoch 9814/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1316.2223 - val_loss: 1498.5408\n",
            "Epoch 9815/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1675.2362 - val_loss: 1497.1379\n",
            "Epoch 9816/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1430.9429 - val_loss: 1453.3336\n",
            "Epoch 9817/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1332.0466 - val_loss: 1470.8480\n",
            "Epoch 9818/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1481.1341 - val_loss: 1448.4172\n",
            "Epoch 9819/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1621.7435 - val_loss: 1448.3239\n",
            "Epoch 9820/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1492.8822 - val_loss: 1446.5811\n",
            "Epoch 9821/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1488.1731 - val_loss: 1430.8525\n",
            "Epoch 9822/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1447.7494 - val_loss: 1411.1742\n",
            "Epoch 9823/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1554.8183 - val_loss: 1445.6771\n",
            "Epoch 9824/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1600.5130 - val_loss: 1459.2474\n",
            "Epoch 9825/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1362.7756 - val_loss: 1418.9044\n",
            "Epoch 9826/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1441.9665 - val_loss: 1394.6779\n",
            "Epoch 9827/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1306.6648 - val_loss: 1394.7212\n",
            "Epoch 9828/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1390.3028 - val_loss: 1389.9362\n",
            "Epoch 9829/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1434.2595 - val_loss: 1419.7347\n",
            "Epoch 9830/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1418.0168 - val_loss: 1450.3894\n",
            "Epoch 9831/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1403.6293 - val_loss: 1433.0085\n",
            "Epoch 9832/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1536.0685 - val_loss: 1410.5765\n",
            "Epoch 9833/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1430.6336 - val_loss: 1406.6816\n",
            "Epoch 9834/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1526.2582 - val_loss: 1417.5500\n",
            "Epoch 9835/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1542.6187 - val_loss: 1385.6637\n",
            "Epoch 9836/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1334.7467 - val_loss: 1452.2461\n",
            "Epoch 9837/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1339.2662 - val_loss: 1454.7140\n",
            "Epoch 9838/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1285.8903 - val_loss: 1427.4951\n",
            "Epoch 9839/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1359.9264 - val_loss: 1425.6089\n",
            "Epoch 9840/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1319.3325 - val_loss: 1516.8159\n",
            "Epoch 9841/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1575.6584 - val_loss: 1481.2161\n",
            "Epoch 9842/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1624.4612 - val_loss: 1491.6277\n",
            "Epoch 9843/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1536.2215 - val_loss: 1489.2228\n",
            "Epoch 9844/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1310.1595 - val_loss: 1512.6841\n",
            "Epoch 9845/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1629.5956 - val_loss: 1594.1140\n",
            "Epoch 9846/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1455.4697 - val_loss: 1590.8805\n",
            "Epoch 9847/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1623.3207 - val_loss: 1516.9205\n",
            "Epoch 9848/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1767.2257 - val_loss: 1559.6707\n",
            "Epoch 9849/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1445.4837 - val_loss: 1585.3107\n",
            "Epoch 9850/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1814.1195 - val_loss: 1776.4285\n",
            "Epoch 9851/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1768.9270 - val_loss: 1774.8031\n",
            "Epoch 9852/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1899.2010 - val_loss: 1755.7904\n",
            "Epoch 9853/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1864.7791 - val_loss: 1798.5125\n",
            "Epoch 9854/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1561.5686 - val_loss: 1721.0950\n",
            "Epoch 9855/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1779.3882 - val_loss: 1853.0735\n",
            "Epoch 9856/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1708.5883 - val_loss: 1752.9237\n",
            "Epoch 9857/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1560.6024 - val_loss: 1680.3533\n",
            "Epoch 9858/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1662.4634 - val_loss: 1601.3502\n",
            "Epoch 9859/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1582.8848 - val_loss: 1649.3220\n",
            "Epoch 9860/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1613.0282 - val_loss: 1590.1661\n",
            "Epoch 9861/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1652.5032 - val_loss: 1588.5824\n",
            "Epoch 9862/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1427.4941 - val_loss: 1591.4658\n",
            "Epoch 9863/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1803.9970 - val_loss: 1667.5361\n",
            "Epoch 9864/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1610.8025 - val_loss: 1706.2217\n",
            "Epoch 9865/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1603.3139 - val_loss: 1608.3534\n",
            "Epoch 9866/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1663.4663 - val_loss: 1681.4771\n",
            "Epoch 9867/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1550.7234 - val_loss: 1609.2125\n",
            "Epoch 9868/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1771.7733 - val_loss: 1563.3220\n",
            "Epoch 9869/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1383.4527 - val_loss: 1558.7354\n",
            "Epoch 9870/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1500.2315 - val_loss: 1563.1829\n",
            "Epoch 9871/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1453.1921 - val_loss: 1557.4896\n",
            "Epoch 9872/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1620.6044 - val_loss: 1556.9652\n",
            "Epoch 9873/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1589.2047 - val_loss: 1540.1047\n",
            "Epoch 9874/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1537.9027 - val_loss: 1527.3156\n",
            "Epoch 9875/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1478.5973 - val_loss: 1592.5110\n",
            "Epoch 9876/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1629.2868 - val_loss: 1534.2244\n",
            "Epoch 9877/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1630.1700 - val_loss: 1698.8433\n",
            "Epoch 9878/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1845.5925 - val_loss: 1749.1094\n",
            "Epoch 9879/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1620.7934 - val_loss: 1767.4454\n",
            "Epoch 9880/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1711.4992 - val_loss: 1603.8883\n",
            "Epoch 9881/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1582.2983 - val_loss: 1617.0734\n",
            "Epoch 9882/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1634.0760 - val_loss: 1752.2518\n",
            "Epoch 9883/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1745.9830 - val_loss: 1715.3564\n",
            "Epoch 9884/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1670.7768 - val_loss: 1753.4222\n",
            "Epoch 9885/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1698.5414 - val_loss: 1748.2274\n",
            "Epoch 9886/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1731.5791 - val_loss: 1763.4869\n",
            "Epoch 9887/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1972.4005 - val_loss: 1806.7946\n",
            "Epoch 9888/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1784.2882 - val_loss: 1764.4540\n",
            "Epoch 9889/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1749.8824 - val_loss: 1755.6136\n",
            "Epoch 9890/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1741.0845 - val_loss: 1728.4656\n",
            "Epoch 9891/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1791.2725 - val_loss: 1786.7990\n",
            "Epoch 9892/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1829.9182 - val_loss: 1696.1006\n",
            "Epoch 9893/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1731.5884 - val_loss: 1676.8046\n",
            "Epoch 9894/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1635.9243 - val_loss: 1590.2203\n",
            "Epoch 9895/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1874.8115 - val_loss: 1583.2205\n",
            "Epoch 9896/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1567.8126 - val_loss: 1550.9884\n",
            "Epoch 9897/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1396.4151 - val_loss: 1480.6462\n",
            "Epoch 9898/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1505.5160 - val_loss: 1506.6827\n",
            "Epoch 9899/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1606.2884 - val_loss: 1488.4343\n",
            "Epoch 9900/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1626.4224 - val_loss: 1454.8514\n",
            "Epoch 9901/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1326.3917 - val_loss: 1458.7352\n",
            "Epoch 9902/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1481.2884 - val_loss: 1578.0798\n",
            "Epoch 9903/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1786.2617 - val_loss: 1583.5170\n",
            "Epoch 9904/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1482.9738 - val_loss: 1642.2855\n",
            "Epoch 9905/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1769.9269 - val_loss: 1686.4320\n",
            "Epoch 9906/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1632.0965 - val_loss: 1591.9893\n",
            "Epoch 9907/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1584.4815 - val_loss: 1457.0117\n",
            "Epoch 9908/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1364.6137 - val_loss: 1349.1475\n",
            "Epoch 9909/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1457.9754 - val_loss: 1682.8356\n",
            "Epoch 9910/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1880.1118 - val_loss: 1633.6592\n",
            "Epoch 9911/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1544.3895 - val_loss: 1621.2117\n",
            "Epoch 9912/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1800.8997 - val_loss: 1574.9083\n",
            "Epoch 9913/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1582.9832 - val_loss: 1577.8057\n",
            "Epoch 9914/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1508.8014 - val_loss: 1514.3721\n",
            "Epoch 9915/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1698.4633 - val_loss: 1519.0227\n",
            "Epoch 9916/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1525.8626 - val_loss: 1620.6167\n",
            "Epoch 9917/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1680.8060 - val_loss: 1600.3046\n",
            "Epoch 9918/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1546.2440 - val_loss: 1449.8359\n",
            "Epoch 9919/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1449.6634 - val_loss: 1540.8099\n",
            "Epoch 9920/12000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1493.3310 - val_loss: 1498.3116\n",
            "Epoch 9921/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1499.9575 - val_loss: 1509.1511\n",
            "Epoch 9922/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1437.2220 - val_loss: 1501.2953\n",
            "Epoch 9923/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1488.0173 - val_loss: 1491.7556\n",
            "Epoch 9924/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1541.3926 - val_loss: 1509.3516\n",
            "Epoch 9925/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1492.9162 - val_loss: 1510.1184\n",
            "Epoch 9926/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1573.9865 - val_loss: 1490.3311\n",
            "Epoch 9927/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1409.4712 - val_loss: 1432.8673\n",
            "Epoch 9928/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1314.3629 - val_loss: 1443.2152\n",
            "Epoch 9929/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1567.6597 - val_loss: 1509.8057\n",
            "Epoch 9930/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1374.2804 - val_loss: 1450.8976\n",
            "Epoch 9931/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1493.7780 - val_loss: 1433.8243\n",
            "Epoch 9932/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1459.1424 - val_loss: 1491.6115\n",
            "Epoch 9933/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1755.9584 - val_loss: 1560.9265\n",
            "Epoch 9934/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1846.4935 - val_loss: 1482.5603\n",
            "Epoch 9935/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1368.2955 - val_loss: 1439.7512\n",
            "Epoch 9936/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1407.9423 - val_loss: 1429.4653\n",
            "Epoch 9937/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1521.6273 - val_loss: 1416.7990\n",
            "Epoch 9938/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1449.4612 - val_loss: 1416.4230\n",
            "Epoch 9939/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1636.6758 - val_loss: 1384.8883\n",
            "Epoch 9940/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1486.9441 - val_loss: 1320.3118\n",
            "Epoch 9941/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1466.7557 - val_loss: 1590.8676\n",
            "Epoch 9942/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1587.6242 - val_loss: 1503.8512\n",
            "Epoch 9943/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1472.5234 - val_loss: 1482.8629\n",
            "Epoch 9944/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1368.6552 - val_loss: 1475.7708\n",
            "Epoch 9945/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1379.0742 - val_loss: 1494.9335\n",
            "Epoch 9946/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1406.0576 - val_loss: 1491.7191\n",
            "Epoch 9947/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1334.9411 - val_loss: 1511.9067\n",
            "Epoch 9948/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1528.0707 - val_loss: 1565.5798\n",
            "Epoch 9949/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1509.5503 - val_loss: 1555.9832\n",
            "Epoch 9950/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1400.7984 - val_loss: 1470.0212\n",
            "Epoch 9951/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1311.2805 - val_loss: 1477.8486\n",
            "Epoch 9952/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1500.4736 - val_loss: 1435.1156\n",
            "Epoch 9953/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1514.9944 - val_loss: 1459.3164\n",
            "Epoch 9954/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1591.8816 - val_loss: 1422.6112\n",
            "Epoch 9955/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1357.5296 - val_loss: 1399.1505\n",
            "Epoch 9956/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1481.7829 - val_loss: 1393.4686\n",
            "Epoch 9957/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1410.2992 - val_loss: 1358.8107\n",
            "Epoch 9958/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1346.3266 - val_loss: 1359.3015\n",
            "Epoch 9959/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1338.1093 - val_loss: 1399.7584\n",
            "Epoch 9960/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1407.0086 - val_loss: 1388.4250\n",
            "Epoch 9961/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1360.5283 - val_loss: 1521.4814\n",
            "Epoch 9962/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1492.2046 - val_loss: 1533.5833\n",
            "Epoch 9963/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1713.7019 - val_loss: 1543.5079\n",
            "Epoch 9964/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1645.2198 - val_loss: 1510.4161\n",
            "Epoch 9965/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1523.7856 - val_loss: 1506.1946\n",
            "Epoch 9966/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1442.1810 - val_loss: 1497.8610\n",
            "Epoch 9967/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1575.4584 - val_loss: 1534.5917\n",
            "Epoch 9968/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1602.3607 - val_loss: 1552.7219\n",
            "Epoch 9969/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1551.0536 - val_loss: 1557.7505\n",
            "Epoch 9970/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1481.2999 - val_loss: 1550.3224\n",
            "Epoch 9971/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1368.4755 - val_loss: 1542.0833\n",
            "Epoch 9972/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1676.5391 - val_loss: 1549.0061\n",
            "Epoch 9973/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1520.5912 - val_loss: 1503.0026\n",
            "Epoch 9974/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1360.7531 - val_loss: 1539.8373\n",
            "Epoch 9975/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1492.8512 - val_loss: 1489.0428\n",
            "Epoch 9976/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1598.5294 - val_loss: 1423.1163\n",
            "Epoch 9977/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1541.6463 - val_loss: 1481.6615\n",
            "Epoch 9978/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1443.9682 - val_loss: 1481.1989\n",
            "Epoch 9979/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1542.6680 - val_loss: 1435.5815\n",
            "Epoch 9980/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1392.4071 - val_loss: 1407.8274\n",
            "Epoch 9981/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1342.0461 - val_loss: 1385.9221\n",
            "Epoch 9982/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1615.1414 - val_loss: 1388.0300\n",
            "Epoch 9983/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1380.3964 - val_loss: 1369.8676\n",
            "Epoch 9984/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1415.6826 - val_loss: 1353.8430\n",
            "Epoch 9985/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1376.2639 - val_loss: 1399.5309\n",
            "Epoch 9986/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1305.0864 - val_loss: 1386.6351\n",
            "Epoch 9987/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1420.4511 - val_loss: 1474.8196\n",
            "Epoch 9988/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1524.4125 - val_loss: 1436.4766\n",
            "Epoch 9989/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1413.8020 - val_loss: 1409.1405\n",
            "Epoch 9990/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1513.3738 - val_loss: 1465.8246\n",
            "Epoch 9991/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1513.2184 - val_loss: 1406.2241\n",
            "Epoch 9992/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1431.7381 - val_loss: 1444.8141\n",
            "Epoch 9993/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1312.4046 - val_loss: 1462.7878\n",
            "Epoch 9994/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1540.7387 - val_loss: 1509.1520\n",
            "Epoch 9995/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1418.3624 - val_loss: 1437.7821\n",
            "Epoch 9996/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1491.4913 - val_loss: 1476.7114\n",
            "Epoch 9997/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1539.9127 - val_loss: 1519.3480\n",
            "Epoch 9998/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1732.0009 - val_loss: 1624.2716\n",
            "Epoch 9999/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1606.2895 - val_loss: 1473.4146\n",
            "Epoch 10000/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1609.3561 - val_loss: 1465.0269\n",
            "Epoch 10001/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1251.1677 - val_loss: 1443.9380\n",
            "Epoch 10002/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1400.3556 - val_loss: 1436.9352\n",
            "Epoch 10003/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1399.0054 - val_loss: 1453.3503\n",
            "Epoch 10004/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1410.0537 - val_loss: 1483.5535\n",
            "Epoch 10005/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1445.4324 - val_loss: 1460.8521\n",
            "Epoch 10006/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1622.4731 - val_loss: 1441.9181\n",
            "Epoch 10007/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1397.2291 - val_loss: 1542.2551\n",
            "Epoch 10008/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1545.4208 - val_loss: 1597.3373\n",
            "Epoch 10009/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1720.6431 - val_loss: 1615.9526\n",
            "Epoch 10010/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1640.3270 - val_loss: 1574.7946\n",
            "Epoch 10011/12000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1658.6082 - val_loss: 1601.6780\n",
            "Epoch 10012/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1474.1727 - val_loss: 1581.2410\n",
            "Epoch 10013/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1581.0494 - val_loss: 1494.4001\n",
            "Epoch 10014/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1384.0796 - val_loss: 1551.9410\n",
            "Epoch 10015/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1495.6878 - val_loss: 1518.7900\n",
            "Epoch 10016/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1552.9161 - val_loss: 1524.4797\n",
            "Epoch 10017/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1467.8268 - val_loss: 1514.6969\n",
            "Epoch 10018/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1359.9491 - val_loss: 1454.3645\n",
            "Epoch 10019/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1428.6039 - val_loss: 1436.4426\n",
            "Epoch 10020/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1456.4689 - val_loss: 1411.9680\n",
            "Epoch 10021/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1397.5131 - val_loss: 1383.0298\n",
            "Epoch 10022/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1417.4028 - val_loss: 1345.5195\n",
            "Epoch 10023/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1339.3788 - val_loss: 1352.6377\n",
            "Epoch 10024/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1362.7065 - val_loss: 1336.7639\n",
            "Epoch 10025/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1419.4297 - val_loss: 1346.1796\n",
            "Epoch 10026/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1383.1733 - val_loss: 1391.8361\n",
            "Epoch 10027/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1353.9142 - val_loss: 1392.2362\n",
            "Epoch 10028/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1276.9931 - val_loss: 1397.3798\n",
            "Epoch 10029/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1320.3971 - val_loss: 1446.1519\n",
            "Epoch 10030/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1488.6617 - val_loss: 1424.6801\n",
            "Epoch 10031/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1375.5768 - val_loss: 1410.0276\n",
            "Epoch 10032/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1305.4062 - val_loss: 1375.5776\n",
            "Epoch 10033/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1342.7395 - val_loss: 1433.4006\n",
            "Epoch 10034/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1309.4176 - val_loss: 1402.8623\n",
            "Epoch 10035/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1504.4627 - val_loss: 1373.4701\n",
            "Epoch 10036/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1330.3904 - val_loss: 1413.2390\n",
            "Epoch 10037/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1480.1204 - val_loss: 1406.7588\n",
            "Epoch 10038/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1329.1394 - val_loss: 1385.4866\n",
            "Epoch 10039/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1434.7507 - val_loss: 1378.5730\n",
            "Epoch 10040/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1441.6175 - val_loss: 1413.3037\n",
            "Epoch 10041/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1488.1511 - val_loss: 1386.7346\n",
            "Epoch 10042/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1466.6376 - val_loss: 1390.8059\n",
            "Epoch 10043/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1463.2018 - val_loss: 1364.7891\n",
            "Epoch 10044/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1270.7254 - val_loss: 1432.3433\n",
            "Epoch 10045/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1599.6040 - val_loss: 1363.9489\n",
            "Epoch 10046/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1311.7091 - val_loss: 1339.0153\n",
            "Epoch 10047/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1431.1730 - val_loss: 1374.0444\n",
            "Epoch 10048/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1220.0058 - val_loss: 1362.5537\n",
            "Epoch 10049/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1487.3135 - val_loss: 1516.0004\n",
            "Epoch 10050/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1519.2908 - val_loss: 1490.1469\n",
            "Epoch 10051/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1494.8547 - val_loss: 1513.5945\n",
            "Epoch 10052/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1462.3986 - val_loss: 1471.3860\n",
            "Epoch 10053/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1560.7752 - val_loss: 1476.9781\n",
            "Epoch 10054/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1477.0560 - val_loss: 1444.7281\n",
            "Epoch 10055/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1517.6073 - val_loss: 1460.3126\n",
            "Epoch 10056/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1319.0276 - val_loss: 1513.7152\n",
            "Epoch 10057/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1604.2798 - val_loss: 1710.8035\n",
            "Epoch 10058/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1708.2220 - val_loss: 1701.6123\n",
            "Epoch 10059/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1567.0832 - val_loss: 1665.5956\n",
            "Epoch 10060/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1653.9280 - val_loss: 1603.0508\n",
            "Epoch 10061/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1587.6692 - val_loss: 1591.4786\n",
            "Epoch 10062/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1551.8080 - val_loss: 1514.8425\n",
            "Epoch 10063/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1593.8675 - val_loss: 1474.8794\n",
            "Epoch 10064/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1596.7454 - val_loss: 1593.2335\n",
            "Epoch 10065/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1610.9579 - val_loss: 1611.8590\n",
            "Epoch 10066/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1837.7576 - val_loss: 1578.9623\n",
            "Epoch 10067/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1765.6917 - val_loss: 1522.8018\n",
            "Epoch 10068/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1625.2091 - val_loss: 1564.8052\n",
            "Epoch 10069/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1597.8982 - val_loss: 1578.1948\n",
            "Epoch 10070/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1457.4601 - val_loss: 1567.9148\n",
            "Epoch 10071/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1586.6192 - val_loss: 1517.6101\n",
            "Epoch 10072/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1770.6800 - val_loss: 1540.5487\n",
            "Epoch 10073/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1213.7199 - val_loss: 1527.6296\n",
            "Epoch 10074/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1646.2219 - val_loss: 1551.7188\n",
            "Epoch 10075/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1528.8641 - val_loss: 1543.2943\n",
            "Epoch 10076/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1526.6143 - val_loss: 1536.8446\n",
            "Epoch 10077/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1573.7869 - val_loss: 1522.4059\n",
            "Epoch 10078/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1587.8433 - val_loss: 1501.9088\n",
            "Epoch 10079/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1522.9651 - val_loss: 1508.5490\n",
            "Epoch 10080/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1499.1457 - val_loss: 1514.9686\n",
            "Epoch 10081/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1589.7092 - val_loss: 1535.5127\n",
            "Epoch 10082/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1706.7084 - val_loss: 1579.9453\n",
            "Epoch 10083/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1467.4637 - val_loss: 1591.2175\n",
            "Epoch 10084/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1794.7362 - val_loss: 1580.0930\n",
            "Epoch 10085/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1589.1807 - val_loss: 1640.1277\n",
            "Epoch 10086/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1650.6208 - val_loss: 1655.9843\n",
            "Epoch 10087/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1824.0493 - val_loss: 1616.2794\n",
            "Epoch 10088/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1633.5573 - val_loss: 1617.2758\n",
            "Epoch 10089/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1556.4554 - val_loss: 1541.9235\n",
            "Epoch 10090/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1559.6111 - val_loss: 1506.0125\n",
            "Epoch 10091/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1592.0801 - val_loss: 1512.6593\n",
            "Epoch 10092/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1554.9157 - val_loss: 1491.0585\n",
            "Epoch 10093/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1321.8183 - val_loss: 1464.3827\n",
            "Epoch 10094/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1351.6385 - val_loss: 1496.8091\n",
            "Epoch 10095/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1361.8643 - val_loss: 1487.7454\n",
            "Epoch 10096/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1476.6872 - val_loss: 1505.0406\n",
            "Epoch 10097/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1420.7813 - val_loss: 1500.3174\n",
            "Epoch 10098/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1519.9418 - val_loss: 1502.2024\n",
            "Epoch 10099/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1514.1086 - val_loss: 1523.8650\n",
            "Epoch 10100/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1449.9186 - val_loss: 1484.0685\n",
            "Epoch 10101/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1377.8858 - val_loss: 1464.7352\n",
            "Epoch 10102/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1589.5399 - val_loss: 1533.3619\n",
            "Epoch 10103/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1494.3755 - val_loss: 1527.9745\n",
            "Epoch 10104/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1596.0328 - val_loss: 1529.6173\n",
            "Epoch 10105/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1470.2798 - val_loss: 1515.3511\n",
            "Epoch 10106/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1561.0142 - val_loss: 1514.0258\n",
            "Epoch 10107/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1360.5142 - val_loss: 1507.4072\n",
            "Epoch 10108/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1660.0588 - val_loss: 1483.7743\n",
            "Epoch 10109/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1326.0178 - val_loss: 1476.3068\n",
            "Epoch 10110/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1570.8520 - val_loss: 1466.5630\n",
            "Epoch 10111/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1460.3456 - val_loss: 1453.8375\n",
            "Epoch 10112/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1363.5318 - val_loss: 1478.3113\n",
            "Epoch 10113/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1476.6331 - val_loss: 1438.6416\n",
            "Epoch 10114/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1233.6882 - val_loss: 1425.1028\n",
            "Epoch 10115/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1484.0562 - val_loss: 1439.2427\n",
            "Epoch 10116/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1525.5245 - val_loss: 1431.1785\n",
            "Epoch 10117/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1451.3858 - val_loss: 1414.7709\n",
            "Epoch 10118/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1498.5878 - val_loss: 1425.0800\n",
            "Epoch 10119/12000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1531.4272 - val_loss: 1419.3496\n",
            "Epoch 10120/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1695.1966 - val_loss: 1438.7091\n",
            "Epoch 10121/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1367.2171 - val_loss: 1428.4900\n",
            "Epoch 10122/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1568.1236 - val_loss: 1403.4733\n",
            "Epoch 10123/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1424.0953 - val_loss: 1397.8103\n",
            "Epoch 10124/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1397.2353 - val_loss: 1425.9635\n",
            "Epoch 10125/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1488.3185 - val_loss: 1405.5848\n",
            "Epoch 10126/12000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1377.8207 - val_loss: 1449.0664\n",
            "Epoch 10127/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1404.5396 - val_loss: 1468.4647\n",
            "Epoch 10128/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1274.9607 - val_loss: 1468.2008\n",
            "Epoch 10129/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1332.2911 - val_loss: 1449.1536\n",
            "Epoch 10130/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1455.3657 - val_loss: 1537.6541\n",
            "Epoch 10131/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1654.2956 - val_loss: 1699.5793\n",
            "Epoch 10132/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1573.0712 - val_loss: 1597.6935\n",
            "Epoch 10133/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1666.1238 - val_loss: 1607.0226\n",
            "Epoch 10134/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1658.1482 - val_loss: 1578.3828\n",
            "Epoch 10135/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1556.7382 - val_loss: 1596.6527\n",
            "Epoch 10136/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1659.7396 - val_loss: 1585.0377\n",
            "Epoch 10137/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1598.6151 - val_loss: 1671.8949\n",
            "Epoch 10138/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1567.9114 - val_loss: 1578.4945\n",
            "Epoch 10139/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1700.5509 - val_loss: 1766.6829\n",
            "Epoch 10140/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1638.2026 - val_loss: 1845.8955\n",
            "Epoch 10141/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1607.2983 - val_loss: 1645.8781\n",
            "Epoch 10142/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1679.6201 - val_loss: 1852.2766\n",
            "Epoch 10143/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2015.5876 - val_loss: 1937.5398\n",
            "Epoch 10144/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2069.3827 - val_loss: 2046.9509\n",
            "Epoch 10145/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2005.2064 - val_loss: 1998.9404\n",
            "Epoch 10146/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1888.8006 - val_loss: 1834.2334\n",
            "Epoch 10147/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2055.9900 - val_loss: 1971.7209\n",
            "Epoch 10148/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2224.0821 - val_loss: 2174.5234\n",
            "Epoch 10149/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2316.6923 - val_loss: 2168.6250\n",
            "Epoch 10150/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2022.7671 - val_loss: 2035.4150\n",
            "Epoch 10151/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2186.8810 - val_loss: 2061.8621\n",
            "Epoch 10152/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1972.0745 - val_loss: 1994.7013\n",
            "Epoch 10153/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1827.2347 - val_loss: 1948.7736\n",
            "Epoch 10154/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1682.7445 - val_loss: 1943.1902\n",
            "Epoch 10155/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1807.5123 - val_loss: 1871.7999\n",
            "Epoch 10156/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2015.8822 - val_loss: 1856.3827\n",
            "Epoch 10157/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1956.9387 - val_loss: 1841.1632\n",
            "Epoch 10158/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1787.5652 - val_loss: 1877.4871\n",
            "Epoch 10159/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2060.0005 - val_loss: 1924.6427\n",
            "Epoch 10160/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2185.5161 - val_loss: 1985.9266\n",
            "Epoch 10161/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1908.9707 - val_loss: 1960.5077\n",
            "Epoch 10162/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2060.3234 - val_loss: 1939.2218\n",
            "Epoch 10163/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 2084.3931 - val_loss: 1943.6132\n",
            "Epoch 10164/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1893.0846 - val_loss: 1854.6476\n",
            "Epoch 10165/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1921.2907 - val_loss: 1834.5977\n",
            "Epoch 10166/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1870.5175 - val_loss: 1892.5482\n",
            "Epoch 10167/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2068.8839 - val_loss: 1868.1117\n",
            "Epoch 10168/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1949.6169 - val_loss: 1875.7045\n",
            "Epoch 10169/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1955.8842 - val_loss: 1887.5851\n",
            "Epoch 10170/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2012.2656 - val_loss: 1869.9011\n",
            "Epoch 10171/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1885.9054 - val_loss: 1851.3975\n",
            "Epoch 10172/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1909.3152 - val_loss: 1848.7972\n",
            "Epoch 10173/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1876.3418 - val_loss: 1852.0695\n",
            "Epoch 10174/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1836.2147 - val_loss: 1974.8651\n",
            "Epoch 10175/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1947.5672 - val_loss: 1843.2538\n",
            "Epoch 10176/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1816.8026 - val_loss: 1904.9427\n",
            "Epoch 10177/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1893.1052 - val_loss: 2112.4243\n",
            "Epoch 10178/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2096.3537 - val_loss: 2122.5735\n",
            "Epoch 10179/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2101.6494 - val_loss: 2155.6140\n",
            "Epoch 10180/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1998.3616 - val_loss: 2109.7683\n",
            "Epoch 10181/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2058.4086 - val_loss: 2073.0173\n",
            "Epoch 10182/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1706.5801 - val_loss: 2032.5035\n",
            "Epoch 10183/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2175.9483 - val_loss: 2190.9485\n",
            "Epoch 10184/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2173.4053 - val_loss: 2121.3384\n",
            "Epoch 10185/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2103.5072 - val_loss: 2032.1853\n",
            "Epoch 10186/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2047.5267 - val_loss: 1918.0085\n",
            "Epoch 10187/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1917.8166 - val_loss: 1897.9045\n",
            "Epoch 10188/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1676.1650 - val_loss: 1896.1780\n",
            "Epoch 10189/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1977.8513 - val_loss: 1851.3190\n",
            "Epoch 10190/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2030.8301 - val_loss: 1783.3372\n",
            "Epoch 10191/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1927.6359 - val_loss: 1769.3329\n",
            "Epoch 10192/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1687.6374 - val_loss: 1831.5808\n",
            "Epoch 10193/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1887.3992 - val_loss: 1899.7373\n",
            "Epoch 10194/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1785.9483 - val_loss: 1865.5906\n",
            "Epoch 10195/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 2167.3206 - val_loss: 1885.7239\n",
            "Epoch 10196/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1835.0190 - val_loss: 1840.6619\n",
            "Epoch 10197/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1839.9578 - val_loss: 1815.4995\n",
            "Epoch 10198/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1658.8510 - val_loss: 1807.4597\n",
            "Epoch 10199/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1725.5323 - val_loss: 1842.1742\n",
            "Epoch 10200/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1568.7883 - val_loss: 1850.4144\n",
            "Epoch 10201/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1994.2896 - val_loss: 1784.9828\n",
            "Epoch 10202/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1882.1383 - val_loss: 1782.0344\n",
            "Epoch 10203/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1658.8604 - val_loss: 1723.2872\n",
            "Epoch 10204/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1730.7665 - val_loss: 1758.1547\n",
            "Epoch 10205/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1769.2426 - val_loss: 1770.6298\n",
            "Epoch 10206/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1734.4840 - val_loss: 1815.7711\n",
            "Epoch 10207/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1935.0292 - val_loss: 1800.0602\n",
            "Epoch 10208/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1725.0945 - val_loss: 1825.3291\n",
            "Epoch 10209/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1796.0521 - val_loss: 1688.1527\n",
            "Epoch 10210/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1745.3819 - val_loss: 1731.5487\n",
            "Epoch 10211/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1737.1910 - val_loss: 1848.1598\n",
            "Epoch 10212/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1855.5650 - val_loss: 1793.6210\n",
            "Epoch 10213/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1822.0105 - val_loss: 1842.4589\n",
            "Epoch 10214/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1886.3660 - val_loss: 1764.8420\n",
            "Epoch 10215/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1862.8605 - val_loss: 1743.9845\n",
            "Epoch 10216/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1621.7416 - val_loss: 1736.5668\n",
            "Epoch 10217/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1786.8499 - val_loss: 1732.5168\n",
            "Epoch 10218/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1675.7050 - val_loss: 1728.9596\n",
            "Epoch 10219/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1859.1522 - val_loss: 1699.1461\n",
            "Epoch 10220/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1681.9105 - val_loss: 1727.7483\n",
            "Epoch 10221/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1746.8532 - val_loss: 1770.1467\n",
            "Epoch 10222/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1578.7660 - val_loss: 1729.5026\n",
            "Epoch 10223/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1717.7850 - val_loss: 1738.6615\n",
            "Epoch 10224/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1789.5350 - val_loss: 1763.7141\n",
            "Epoch 10225/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1819.1087 - val_loss: 1840.2461\n",
            "Epoch 10226/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1751.7784 - val_loss: 1766.3994\n",
            "Epoch 10227/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1776.2118 - val_loss: 1834.3090\n",
            "Epoch 10228/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1877.9664 - val_loss: 1922.1907\n",
            "Epoch 10229/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1965.8410 - val_loss: 1827.1425\n",
            "Epoch 10230/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1760.5523 - val_loss: 1725.9817\n",
            "Epoch 10231/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1913.9451 - val_loss: 1779.9110\n",
            "Epoch 10232/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1908.8381 - val_loss: 1778.2833\n",
            "Epoch 10233/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1866.1357 - val_loss: 1756.7625\n",
            "Epoch 10234/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1915.5834 - val_loss: 1825.7045\n",
            "Epoch 10235/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1701.3768 - val_loss: 1735.2141\n",
            "Epoch 10236/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1753.5882 - val_loss: 1699.8235\n",
            "Epoch 10237/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1700.4731 - val_loss: 1758.8220\n",
            "Epoch 10238/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1751.1660 - val_loss: 1740.8038\n",
            "Epoch 10239/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1796.3003 - val_loss: 1743.1469\n",
            "Epoch 10240/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1654.2894 - val_loss: 1683.2236\n",
            "Epoch 10241/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1743.5420 - val_loss: 1668.7228\n",
            "Epoch 10242/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1900.9581 - val_loss: 1597.1362\n",
            "Epoch 10243/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1511.5242 - val_loss: 1594.3463\n",
            "Epoch 10244/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1602.4264 - val_loss: 1756.6055\n",
            "Epoch 10245/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1734.3914 - val_loss: 1763.0381\n",
            "Epoch 10246/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1607.3604 - val_loss: 1762.6000\n",
            "Epoch 10247/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1713.0258 - val_loss: 1754.1481\n",
            "Epoch 10248/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1698.9143 - val_loss: 1780.7992\n",
            "Epoch 10249/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1656.2626 - val_loss: 1786.8247\n",
            "Epoch 10250/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1804.2324 - val_loss: 1807.8879\n",
            "Epoch 10251/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1686.8336 - val_loss: 1763.7795\n",
            "Epoch 10252/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1685.9527 - val_loss: 1817.1771\n",
            "Epoch 10253/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1822.1666 - val_loss: 1854.3667\n",
            "Epoch 10254/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1975.1770 - val_loss: 1873.5016\n",
            "Epoch 10255/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1736.2775 - val_loss: 1825.9558\n",
            "Epoch 10256/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1637.5705 - val_loss: 1818.1450\n",
            "Epoch 10257/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1597.0546 - val_loss: 1811.9097\n",
            "Epoch 10258/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1945.0577 - val_loss: 1830.1919\n",
            "Epoch 10259/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1815.9787 - val_loss: 1756.2148\n",
            "Epoch 10260/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1729.4614 - val_loss: 1787.4387\n",
            "Epoch 10261/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1862.3338 - val_loss: 1680.5739\n",
            "Epoch 10262/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1624.3195 - val_loss: 1794.0593\n",
            "Epoch 10263/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1680.5969 - val_loss: 1790.1737\n",
            "Epoch 10264/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1919.8295 - val_loss: 1857.1641\n",
            "Epoch 10265/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2004.4516 - val_loss: 1765.7192\n",
            "Epoch 10266/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1700.0414 - val_loss: 1833.9700\n",
            "Epoch 10267/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1971.8542 - val_loss: 1823.4823\n",
            "Epoch 10268/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1784.3541 - val_loss: 1752.8109\n",
            "Epoch 10269/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1699.2010 - val_loss: 1634.8276\n",
            "Epoch 10270/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1644.1110 - val_loss: 1588.5334\n",
            "Epoch 10271/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1582.3263 - val_loss: 1567.7086\n",
            "Epoch 10272/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1862.9378 - val_loss: 2081.8931\n",
            "Epoch 10273/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2077.5963 - val_loss: 1989.0520\n",
            "Epoch 10274/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1766.2538 - val_loss: 1964.0732\n",
            "Epoch 10275/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2064.9223 - val_loss: 2028.4740\n",
            "Epoch 10276/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 2083.2895 - val_loss: 2004.1936\n",
            "Epoch 10277/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1963.6017 - val_loss: 2005.4274\n",
            "Epoch 10278/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1755.7331 - val_loss: 1998.8138\n",
            "Epoch 10279/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1963.2875 - val_loss: 2041.0875\n",
            "Epoch 10280/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2223.1644 - val_loss: 2091.6196\n",
            "Epoch 10281/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2217.8594 - val_loss: 2051.1228\n",
            "Epoch 10282/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2094.2905 - val_loss: 2003.8734\n",
            "Epoch 10283/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1969.5633 - val_loss: 2010.7695\n",
            "Epoch 10284/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1962.9717 - val_loss: 1927.8356\n",
            "Epoch 10285/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 2117.7920 - val_loss: 1910.7709\n",
            "Epoch 10286/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1990.2208 - val_loss: 1915.6528\n",
            "Epoch 10287/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2023.6029 - val_loss: 1867.0452\n",
            "Epoch 10288/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1967.3066 - val_loss: 1919.3007\n",
            "Epoch 10289/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1716.7992 - val_loss: 1918.2091\n",
            "Epoch 10290/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1816.8550 - val_loss: 1877.6522\n",
            "Epoch 10291/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1781.5487 - val_loss: 1866.8286\n",
            "Epoch 10292/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1807.0905 - val_loss: 1834.0961\n",
            "Epoch 10293/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1900.4872 - val_loss: 1818.9176\n",
            "Epoch 10294/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1833.7341 - val_loss: 1899.3337\n",
            "Epoch 10295/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1830.2749 - val_loss: 1861.1310\n",
            "Epoch 10296/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1924.2512 - val_loss: 1814.9640\n",
            "Epoch 10297/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1783.6296 - val_loss: 1762.8407\n",
            "Epoch 10298/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1632.3191 - val_loss: 1824.2721\n",
            "Epoch 10299/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1737.2902 - val_loss: 1776.4932\n",
            "Epoch 10300/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1920.0673 - val_loss: 1837.6731\n",
            "Epoch 10301/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1738.9785 - val_loss: 1802.1486\n",
            "Epoch 10302/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1698.5974 - val_loss: 1741.4812\n",
            "Epoch 10303/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1771.1658 - val_loss: 1708.9961\n",
            "Epoch 10304/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1961.8189 - val_loss: 1760.6158\n",
            "Epoch 10305/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1772.5600 - val_loss: 1858.5834\n",
            "Epoch 10306/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1764.1360 - val_loss: 1834.0800\n",
            "Epoch 10307/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1832.2756 - val_loss: 1834.9102\n",
            "Epoch 10308/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1849.4316 - val_loss: 1813.0635\n",
            "Epoch 10309/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1806.0122 - val_loss: 1812.0785\n",
            "Epoch 10310/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1806.5792 - val_loss: 1802.7960\n",
            "Epoch 10311/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1696.5393 - val_loss: 1782.5885\n",
            "Epoch 10312/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1804.7126 - val_loss: 1772.5785\n",
            "Epoch 10313/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1739.4055 - val_loss: 1805.2948\n",
            "Epoch 10314/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1904.3825 - val_loss: 1835.5330\n",
            "Epoch 10315/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1878.7955 - val_loss: 1864.0490\n",
            "Epoch 10316/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1868.1128 - val_loss: 1833.6700\n",
            "Epoch 10317/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1680.7098 - val_loss: 1825.2162\n",
            "Epoch 10318/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1994.6205 - val_loss: 1825.4348\n",
            "Epoch 10319/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1637.4129 - val_loss: 1811.8469\n",
            "Epoch 10320/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1811.5961 - val_loss: 1817.3945\n",
            "Epoch 10321/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1661.3045 - val_loss: 1777.2583\n",
            "Epoch 10322/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1952.3794 - val_loss: 1783.4766\n",
            "Epoch 10323/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1881.6811 - val_loss: 1779.4218\n",
            "Epoch 10324/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1600.5315 - val_loss: 1774.6884\n",
            "Epoch 10325/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1615.0692 - val_loss: 1754.7104\n",
            "Epoch 10326/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1801.3711 - val_loss: 1746.1115\n",
            "Epoch 10327/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1660.2506 - val_loss: 1749.1422\n",
            "Epoch 10328/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1693.6020 - val_loss: 1742.4996\n",
            "Epoch 10329/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1825.5622 - val_loss: 1742.4813\n",
            "Epoch 10330/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1738.1192 - val_loss: 1758.3196\n",
            "Epoch 10331/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1713.1186 - val_loss: 1745.6246\n",
            "Epoch 10332/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1820.1680 - val_loss: 1755.8718\n",
            "Epoch 10333/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1642.4596 - val_loss: 1773.2006\n",
            "Epoch 10334/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1738.7675 - val_loss: 1831.7196\n",
            "Epoch 10335/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1804.2597 - val_loss: 1857.7594\n",
            "Epoch 10336/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1828.8085 - val_loss: 1889.8079\n",
            "Epoch 10337/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1770.3943 - val_loss: 1875.8755\n",
            "Epoch 10338/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2042.8950 - val_loss: 1804.0461\n",
            "Epoch 10339/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1637.3752 - val_loss: 1693.8361\n",
            "Epoch 10340/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1662.6432 - val_loss: 1663.0321\n",
            "Epoch 10341/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1762.2692 - val_loss: 1706.9901\n",
            "Epoch 10342/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1431.0918 - val_loss: 1664.1427\n",
            "Epoch 10343/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1806.6020 - val_loss: 1643.3798\n",
            "Epoch 10344/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1704.3519 - val_loss: 1632.1207\n",
            "Epoch 10345/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1515.8777 - val_loss: 1604.1891\n",
            "Epoch 10346/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1461.6515 - val_loss: 1660.7751\n",
            "Epoch 10347/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1582.9474 - val_loss: 1618.7045\n",
            "Epoch 10348/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1418.4929 - val_loss: 1634.1128\n",
            "Epoch 10349/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1746.9602 - val_loss: 1631.5188\n",
            "Epoch 10350/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1605.0571 - val_loss: 1616.7186\n",
            "Epoch 10351/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1903.2226 - val_loss: 1707.7162\n",
            "Epoch 10352/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1680.1739 - val_loss: 1692.2218\n",
            "Epoch 10353/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1695.5215 - val_loss: 1669.7279\n",
            "Epoch 10354/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1665.8734 - val_loss: 1669.6112\n",
            "Epoch 10355/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1683.3899 - val_loss: 1665.9388\n",
            "Epoch 10356/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1612.7137 - val_loss: 1648.8988\n",
            "Epoch 10357/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1748.2943 - val_loss: 1645.9562\n",
            "Epoch 10358/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1566.5450 - val_loss: 1639.6508\n",
            "Epoch 10359/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1751.0390 - val_loss: 1642.6158\n",
            "Epoch 10360/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1967.7625 - val_loss: 1640.5663\n",
            "Epoch 10361/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1500.4932 - val_loss: 1638.3412\n",
            "Epoch 10362/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1716.6694 - val_loss: 1636.2053\n",
            "Epoch 10363/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1707.2838 - val_loss: 1634.6826\n",
            "Epoch 10364/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1658.5227 - val_loss: 1632.9158\n",
            "Epoch 10365/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1676.5569 - val_loss: 1631.9487\n",
            "Epoch 10366/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1681.8606 - val_loss: 1629.9539\n",
            "Epoch 10367/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1489.4468 - val_loss: 1628.5582\n",
            "Epoch 10368/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1539.6767 - val_loss: 1627.2306\n",
            "Epoch 10369/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1717.5840 - val_loss: 1625.3026\n",
            "Epoch 10370/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1464.7868 - val_loss: 1630.5173\n",
            "Epoch 10371/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1693.5427 - val_loss: 1622.3356\n",
            "Epoch 10372/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1649.1406 - val_loss: 1621.4259\n",
            "Epoch 10373/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1429.8021 - val_loss: 1619.9918\n",
            "Epoch 10374/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1472.9648 - val_loss: 1617.6935\n",
            "Epoch 10375/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1715.9131 - val_loss: 1622.8033\n",
            "Epoch 10376/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1750.2538 - val_loss: 1614.7670\n",
            "Epoch 10377/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1407.9130 - val_loss: 1613.5830\n",
            "Epoch 10378/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1664.1451 - val_loss: 1612.5375\n",
            "Epoch 10379/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1723.0890 - val_loss: 1610.9423\n",
            "Epoch 10380/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1798.6894 - val_loss: 1609.8060\n",
            "Epoch 10381/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1592.6395 - val_loss: 1608.6932\n",
            "Epoch 10382/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1466.7503 - val_loss: 1620.3485\n",
            "Epoch 10383/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1659.2088 - val_loss: 1630.4515\n",
            "Epoch 10384/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1513.9357 - val_loss: 1556.5959\n",
            "Epoch 10385/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1772.8776 - val_loss: 1924.5156\n",
            "Epoch 10386/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1889.4433 - val_loss: 1855.6503\n",
            "Epoch 10387/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1957.4308 - val_loss: 1778.4391\n",
            "Epoch 10388/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1688.4855 - val_loss: 1693.4797\n",
            "Epoch 10389/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1518.8099 - val_loss: 1653.1953\n",
            "Epoch 10390/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1571.1418 - val_loss: 1551.1333\n",
            "Epoch 10391/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1728.9667 - val_loss: 1670.2526\n",
            "Epoch 10392/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1994.2243 - val_loss: 1653.5854\n",
            "Epoch 10393/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1534.6399 - val_loss: 1676.4801\n",
            "Epoch 10394/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1651.9832 - val_loss: 1666.4957\n",
            "Epoch 10395/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1638.5540 - val_loss: 1680.9818\n",
            "Epoch 10396/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1821.0031 - val_loss: 1642.1898\n",
            "Epoch 10397/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1616.8132 - val_loss: 1636.2274\n",
            "Epoch 10398/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1696.8183 - val_loss: 1628.4015\n",
            "Epoch 10399/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1565.7588 - val_loss: 1615.0515\n",
            "Epoch 10400/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1635.7625 - val_loss: 1615.3328\n",
            "Epoch 10401/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1584.6552 - val_loss: 1565.0104\n",
            "Epoch 10402/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1587.0372 - val_loss: 1587.5500\n",
            "Epoch 10403/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1631.2710 - val_loss: 1587.8419\n",
            "Epoch 10404/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1691.2469 - val_loss: 1561.5450\n",
            "Epoch 10405/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1522.6104 - val_loss: 1548.4827\n",
            "Epoch 10406/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1516.6859 - val_loss: 1528.4912\n",
            "Epoch 10407/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1341.4974 - val_loss: 1547.0244\n",
            "Epoch 10408/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1569.4369 - val_loss: 1493.3135\n",
            "Epoch 10409/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1644.7291 - val_loss: 1472.1805\n",
            "Epoch 10410/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1362.7140 - val_loss: 1488.3790\n",
            "Epoch 10411/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1419.5573 - val_loss: 1477.1328\n",
            "Epoch 10412/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1360.6748 - val_loss: 1520.2019\n",
            "Epoch 10413/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1496.3353 - val_loss: 1507.9896\n",
            "Epoch 10414/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1575.8550 - val_loss: 1469.9995\n",
            "Epoch 10415/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1499.8017 - val_loss: 1439.9993\n",
            "Epoch 10416/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1474.4980 - val_loss: 1437.9430\n",
            "Epoch 10417/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1366.3978 - val_loss: 1593.2505\n",
            "Epoch 10418/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1696.3116 - val_loss: 1569.0613\n",
            "Epoch 10419/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1560.3373 - val_loss: 1529.5178\n",
            "Epoch 10420/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1645.7177 - val_loss: 1534.3124\n",
            "Epoch 10421/12000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1453.8302 - val_loss: 1519.4236\n",
            "Epoch 10422/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1474.6459 - val_loss: 1455.2024\n",
            "Epoch 10423/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1544.3408 - val_loss: 1495.8806\n",
            "Epoch 10424/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1566.4909 - val_loss: 1527.9279\n",
            "Epoch 10425/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1384.5667 - val_loss: 1505.7172\n",
            "Epoch 10426/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1430.8745 - val_loss: 1477.4735\n",
            "Epoch 10427/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1500.9561 - val_loss: 1500.2383\n",
            "Epoch 10428/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1520.0975 - val_loss: 1459.7139\n",
            "Epoch 10429/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1651.2333 - val_loss: 1521.0725\n",
            "Epoch 10430/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1568.2407 - val_loss: 1486.8107\n",
            "Epoch 10431/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1467.3972 - val_loss: 1487.4304\n",
            "Epoch 10432/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1410.1696 - val_loss: 1479.9692\n",
            "Epoch 10433/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1464.5192 - val_loss: 1465.7750\n",
            "Epoch 10434/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1401.2673 - val_loss: 1445.3568\n",
            "Epoch 10435/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1441.9750 - val_loss: 1418.4624\n",
            "Epoch 10436/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1339.2433 - val_loss: 1527.0005\n",
            "Epoch 10437/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1500.0626 - val_loss: 1560.2089\n",
            "Epoch 10438/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1459.2043 - val_loss: 1596.4337\n",
            "Epoch 10439/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1614.0219 - val_loss: 1500.3623\n",
            "Epoch 10440/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1422.9966 - val_loss: 1517.4540\n",
            "Epoch 10441/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1553.5382 - val_loss: 1651.0859\n",
            "Epoch 10442/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1665.3705 - val_loss: 1633.1501\n",
            "Epoch 10443/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1681.9756 - val_loss: 1594.9822\n",
            "Epoch 10444/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1698.7783 - val_loss: 1554.8195\n",
            "Epoch 10445/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1689.2474 - val_loss: 1524.3076\n",
            "Epoch 10446/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1458.2441 - val_loss: 1510.0177\n",
            "Epoch 10447/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1391.2034 - val_loss: 1492.3037\n",
            "Epoch 10448/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1555.4091 - val_loss: 1517.2036\n",
            "Epoch 10449/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1620.2129 - val_loss: 1518.2471\n",
            "Epoch 10450/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1636.6192 - val_loss: 1486.2139\n",
            "Epoch 10451/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1530.0087 - val_loss: 1519.3383\n",
            "Epoch 10452/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1431.9073 - val_loss: 1497.1919\n",
            "Epoch 10453/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1493.0938 - val_loss: 1549.9783\n",
            "Epoch 10454/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1591.9367 - val_loss: 1676.5646\n",
            "Epoch 10455/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1597.9684 - val_loss: 1632.5134\n",
            "Epoch 10456/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1590.9232 - val_loss: 1589.3303\n",
            "Epoch 10457/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1488.3370 - val_loss: 1573.5986\n",
            "Epoch 10458/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1468.7511 - val_loss: 1687.9532\n",
            "Epoch 10459/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1823.7087 - val_loss: 1635.0361\n",
            "Epoch 10460/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1796.2468 - val_loss: 1648.7228\n",
            "Epoch 10461/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1604.1933 - val_loss: 1634.0804\n",
            "Epoch 10462/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1541.1181 - val_loss: 1606.9471\n",
            "Epoch 10463/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1455.3421 - val_loss: 1617.7834\n",
            "Epoch 10464/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1641.8418 - val_loss: 1838.4071\n",
            "Epoch 10465/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1700.1127 - val_loss: 1606.2295\n",
            "Epoch 10466/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1408.4847 - val_loss: 1567.5518\n",
            "Epoch 10467/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1564.3340 - val_loss: 1617.0576\n",
            "Epoch 10468/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1891.0126 - val_loss: 1583.5708\n",
            "Epoch 10469/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1498.4373 - val_loss: 1557.6880\n",
            "Epoch 10470/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1460.2308 - val_loss: 1481.3375\n",
            "Epoch 10471/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1411.6138 - val_loss: 1444.5474\n",
            "Epoch 10472/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1484.8540 - val_loss: 1491.3102\n",
            "Epoch 10473/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1508.3509 - val_loss: 1472.0637\n",
            "Epoch 10474/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1443.4059 - val_loss: 1439.7178\n",
            "Epoch 10475/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1355.6361 - val_loss: 1455.5112\n",
            "Epoch 10476/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1458.8736 - val_loss: 1534.3472\n",
            "Epoch 10477/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1371.1996 - val_loss: 1533.6954\n",
            "Epoch 10478/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1444.9349 - val_loss: 1521.4662\n",
            "Epoch 10479/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1378.4355 - val_loss: 1523.9202\n",
            "Epoch 10480/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1653.5177 - val_loss: 1577.0131\n",
            "Epoch 10481/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1748.8246 - val_loss: 1529.3090\n",
            "Epoch 10482/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1643.7897 - val_loss: 1533.9691\n",
            "Epoch 10483/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1610.4518 - val_loss: 1505.6765\n",
            "Epoch 10484/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1346.0053 - val_loss: 1526.4120\n",
            "Epoch 10485/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1510.7563 - val_loss: 1653.9215\n",
            "Epoch 10486/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1746.2207 - val_loss: 1616.8718\n",
            "Epoch 10487/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1782.3613 - val_loss: 1580.8988\n",
            "Epoch 10488/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1478.5861 - val_loss: 1586.8550\n",
            "Epoch 10489/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1464.5887 - val_loss: 1570.9431\n",
            "Epoch 10490/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1473.4435 - val_loss: 1610.5295\n",
            "Epoch 10491/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1679.6255 - val_loss: 1576.2974\n",
            "Epoch 10492/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1554.6388 - val_loss: 1634.3290\n",
            "Epoch 10493/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1499.5394 - val_loss: 1686.2869\n",
            "Epoch 10494/12000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1942.4788 - val_loss: 1687.4167\n",
            "Epoch 10495/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1865.1021 - val_loss: 1691.9402\n",
            "Epoch 10496/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1633.5309 - val_loss: 1680.6125\n",
            "Epoch 10497/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1945.1962 - val_loss: 1630.1687\n",
            "Epoch 10498/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1537.6752 - val_loss: 1627.2250\n",
            "Epoch 10499/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1634.4419 - val_loss: 1630.2646\n",
            "Epoch 10500/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1715.9162 - val_loss: 1619.3936\n",
            "Epoch 10501/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1761.0759 - val_loss: 1650.4382\n",
            "Epoch 10502/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1690.7440 - val_loss: 1624.9023\n",
            "Epoch 10503/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1575.0080 - val_loss: 1613.4557\n",
            "Epoch 10504/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1615.0671 - val_loss: 1613.8854\n",
            "Epoch 10505/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1336.2472 - val_loss: 1538.4453\n",
            "Epoch 10506/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1495.0156 - val_loss: 1514.9789\n",
            "Epoch 10507/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1426.5735 - val_loss: 1457.0222\n",
            "Epoch 10508/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1447.8381 - val_loss: 1479.2678\n",
            "Epoch 10509/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1453.8918 - val_loss: 1469.1406\n",
            "Epoch 10510/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1650.4675 - val_loss: 1439.4779\n",
            "Epoch 10511/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1467.1813 - val_loss: 1502.4890\n",
            "Epoch 10512/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1629.7204 - val_loss: 1445.6904\n",
            "Epoch 10513/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1410.5399 - val_loss: 1401.3352\n",
            "Epoch 10514/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1275.8380 - val_loss: 1391.4532\n",
            "Epoch 10515/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1357.5160 - val_loss: 1376.8126\n",
            "Epoch 10516/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1344.7958 - val_loss: 1383.0367\n",
            "Epoch 10517/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1237.6741 - val_loss: 1387.9031\n",
            "Epoch 10518/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1490.8505 - val_loss: 1369.7762\n",
            "Epoch 10519/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1556.5238 - val_loss: 1352.5908\n",
            "Epoch 10520/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1437.1791 - val_loss: 1346.9139\n",
            "Epoch 10521/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1365.4868 - val_loss: 1410.5420\n",
            "Epoch 10522/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1341.2250 - val_loss: 1407.5967\n",
            "Epoch 10523/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1411.3603 - val_loss: 1395.1307\n",
            "Epoch 10524/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1418.4567 - val_loss: 1413.4236\n",
            "Epoch 10525/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1259.6085 - val_loss: 1356.2615\n",
            "Epoch 10526/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1320.1915 - val_loss: 1461.5275\n",
            "Epoch 10527/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1399.9463 - val_loss: 1382.4238\n",
            "Epoch 10528/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1537.4150 - val_loss: 1400.6682\n",
            "Epoch 10529/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1350.4713 - val_loss: 1350.0515\n",
            "Epoch 10530/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1350.1819 - val_loss: 1489.0365\n",
            "Epoch 10531/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1457.9053 - val_loss: 1493.3981\n",
            "Epoch 10532/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1451.1877 - val_loss: 1481.1128\n",
            "Epoch 10533/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1407.6059 - val_loss: 1504.6185\n",
            "Epoch 10534/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1617.1467 - val_loss: 1549.7836\n",
            "Epoch 10535/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1596.7074 - val_loss: 1440.7618\n",
            "Epoch 10536/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1391.2041 - val_loss: 1425.6259\n",
            "Epoch 10537/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1385.1705 - val_loss: 1400.4103\n",
            "Epoch 10538/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1407.2980 - val_loss: 1359.1807\n",
            "Epoch 10539/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1427.4940 - val_loss: 1378.6360\n",
            "Epoch 10540/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1487.4092 - val_loss: 1364.6140\n",
            "Epoch 10541/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1184.6986 - val_loss: 1360.9340\n",
            "Epoch 10542/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1179.4504 - val_loss: 1353.1215\n",
            "Epoch 10543/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1497.8237 - val_loss: 1312.9849\n",
            "Epoch 10544/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1334.1258 - val_loss: 1307.0309\n",
            "Epoch 10545/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1248.9137 - val_loss: 1309.2430\n",
            "Epoch 10546/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1275.8933 - val_loss: 1296.2286\n",
            "Epoch 10547/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1197.2151 - val_loss: 1317.9053\n",
            "Epoch 10548/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1459.1781 - val_loss: 1292.9753\n",
            "Epoch 10549/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1261.2982 - val_loss: 1297.8500\n",
            "Epoch 10550/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1263.0264 - val_loss: 1269.2878\n",
            "Epoch 10551/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1153.9354 - val_loss: 1282.9938\n",
            "Epoch 10552/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1324.1587 - val_loss: 1275.1609\n",
            "Epoch 10553/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1309.5307 - val_loss: 1298.1519\n",
            "Epoch 10554/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1471.8333 - val_loss: 1276.2911\n",
            "Epoch 10555/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1228.3049 - val_loss: 1271.3553\n",
            "Epoch 10556/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1076.2205 - val_loss: 1252.9326\n",
            "Epoch 10557/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1371.9721 - val_loss: 1331.0677\n",
            "Epoch 10558/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1422.2778 - val_loss: 1455.3438\n",
            "Epoch 10559/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1457.9973 - val_loss: 1569.3442\n",
            "Epoch 10560/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1391.1101 - val_loss: 1916.0442\n",
            "Epoch 10561/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1936.7475 - val_loss: 1975.1671\n",
            "Epoch 10562/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1934.0856 - val_loss: 1898.6023\n",
            "Epoch 10563/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2008.3189 - val_loss: 1762.5742\n",
            "Epoch 10564/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1902.9822 - val_loss: 1749.3677\n",
            "Epoch 10565/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1675.6741 - val_loss: 1735.0051\n",
            "Epoch 10566/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1761.5923 - val_loss: 1687.4808\n",
            "Epoch 10567/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1525.4329 - val_loss: 1564.8171\n",
            "Epoch 10568/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1533.2725 - val_loss: 1628.3130\n",
            "Epoch 10569/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1632.5762 - val_loss: 1603.5581\n",
            "Epoch 10570/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1529.7226 - val_loss: 1592.4940\n",
            "Epoch 10571/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1731.3687 - val_loss: 1583.9845\n",
            "Epoch 10572/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1605.4680 - val_loss: 1597.7334\n",
            "Epoch 10573/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1561.0808 - val_loss: 1617.2850\n",
            "Epoch 10574/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1447.5871 - val_loss: 1578.0867\n",
            "Epoch 10575/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1492.1376 - val_loss: 1585.7039\n",
            "Epoch 10576/12000\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 1565.2643 - val_loss: 1578.8623\n",
            "Epoch 10577/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1383.1204 - val_loss: 1575.4093\n",
            "Epoch 10578/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1679.5500 - val_loss: 1797.6305\n",
            "Epoch 10579/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1726.6991 - val_loss: 1828.9214\n",
            "Epoch 10580/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1799.7715 - val_loss: 1668.1320\n",
            "Epoch 10581/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1460.6920 - val_loss: 1549.9996\n",
            "Epoch 10582/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1561.2410 - val_loss: 1538.5939\n",
            "Epoch 10583/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1571.0314 - val_loss: 1516.1243\n",
            "Epoch 10584/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1663.6987 - val_loss: 1528.6029\n",
            "Epoch 10585/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1614.4052 - val_loss: 1502.1133\n",
            "Epoch 10586/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1524.0143 - val_loss: 1508.1625\n",
            "Epoch 10587/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1375.8921 - val_loss: 1512.9847\n",
            "Epoch 10588/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1501.5394 - val_loss: 1465.0071\n",
            "Epoch 10589/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1601.4493 - val_loss: 1447.8877\n",
            "Epoch 10590/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1363.4864 - val_loss: 1427.3281\n",
            "Epoch 10591/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1567.8542 - val_loss: 1522.1852\n",
            "Epoch 10592/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1626.3140 - val_loss: 1556.9397\n",
            "Epoch 10593/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1492.3062 - val_loss: 1519.9810\n",
            "Epoch 10594/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1515.6797 - val_loss: 1534.7938\n",
            "Epoch 10595/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1432.6466 - val_loss: 1521.6204\n",
            "Epoch 10596/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1521.4474 - val_loss: 1523.4636\n",
            "Epoch 10597/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1759.2293 - val_loss: 1510.6615\n",
            "Epoch 10598/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1495.4637 - val_loss: 1500.4683\n",
            "Epoch 10599/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1467.7986 - val_loss: 1480.3009\n",
            "Epoch 10600/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1558.3761 - val_loss: 1516.2583\n",
            "Epoch 10601/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1469.2958 - val_loss: 1548.1250\n",
            "Epoch 10602/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1604.1285 - val_loss: 1600.2375\n",
            "Epoch 10603/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1547.9392 - val_loss: 1587.5378\n",
            "Epoch 10604/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1539.9862 - val_loss: 1451.9513\n",
            "Epoch 10605/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1643.4708 - val_loss: 1448.3564\n",
            "Epoch 10606/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1535.2316 - val_loss: 1426.6545\n",
            "Epoch 10607/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1540.5956 - val_loss: 1436.6505\n",
            "Epoch 10608/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1226.0381 - val_loss: 1459.4156\n",
            "Epoch 10609/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1391.1396 - val_loss: 1521.6653\n",
            "Epoch 10610/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1732.3946 - val_loss: 1482.5114\n",
            "Epoch 10611/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1321.6434 - val_loss: 1380.9266\n",
            "Epoch 10612/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1417.1316 - val_loss: 1381.0364\n",
            "Epoch 10613/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1472.1447 - val_loss: 1385.3746\n",
            "Epoch 10614/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1397.9101 - val_loss: 1366.2762\n",
            "Epoch 10615/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1419.4592 - val_loss: 1345.4758\n",
            "Epoch 10616/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1277.2954 - val_loss: 1304.0132\n",
            "Epoch 10617/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1339.8988 - val_loss: 1264.6078\n",
            "Epoch 10618/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1155.7571 - val_loss: 1233.8492\n",
            "Epoch 10619/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1214.6706 - val_loss: 1204.0376\n",
            "Epoch 10620/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1420.0926 - val_loss: 1360.3346\n",
            "Epoch 10621/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1270.0846 - val_loss: 1511.2273\n",
            "Epoch 10622/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1500.8793 - val_loss: 1430.8923\n",
            "Epoch 10623/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1412.9571 - val_loss: 1405.1010\n",
            "Epoch 10624/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1386.8170 - val_loss: 1421.4958\n",
            "Epoch 10625/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1279.2587 - val_loss: 1410.9723\n",
            "Epoch 10626/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1357.1696 - val_loss: 1412.5151\n",
            "Epoch 10627/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1362.0510 - val_loss: 1384.9282\n",
            "Epoch 10628/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1343.5398 - val_loss: 1428.0573\n",
            "Epoch 10629/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1433.8790 - val_loss: 1452.3914\n",
            "Epoch 10630/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1396.1445 - val_loss: 1418.7271\n",
            "Epoch 10631/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1369.3453 - val_loss: 1371.6144\n",
            "Epoch 10632/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1381.5521 - val_loss: 1345.0293\n",
            "Epoch 10633/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1222.4867 - val_loss: 1365.0935\n",
            "Epoch 10634/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1361.6184 - val_loss: 1369.4047\n",
            "Epoch 10635/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1351.7190 - val_loss: 1356.0778\n",
            "Epoch 10636/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1354.1961 - val_loss: 1442.9927\n",
            "Epoch 10637/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1406.4253 - val_loss: 1430.4370\n",
            "Epoch 10638/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1280.9766 - val_loss: 1469.8055\n",
            "Epoch 10639/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1388.1603 - val_loss: 1467.6832\n",
            "Epoch 10640/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1364.6749 - val_loss: 1449.0035\n",
            "Epoch 10641/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1431.5457 - val_loss: 1434.8363\n",
            "Epoch 10642/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1587.0737 - val_loss: 1465.5833\n",
            "Epoch 10643/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1418.7247 - val_loss: 1476.7906\n",
            "Epoch 10644/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1535.3391 - val_loss: 1529.0621\n",
            "Epoch 10645/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1506.7148 - val_loss: 1504.8751\n",
            "Epoch 10646/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1546.3113 - val_loss: 1441.1666\n",
            "Epoch 10647/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1442.3956 - val_loss: 1405.0726\n",
            "Epoch 10648/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1358.2221 - val_loss: 1405.8293\n",
            "Epoch 10649/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1439.8676 - val_loss: 1407.8423\n",
            "Epoch 10650/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1376.4698 - val_loss: 1455.3545\n",
            "Epoch 10651/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1382.1696 - val_loss: 1379.4906\n",
            "Epoch 10652/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1264.4029 - val_loss: 1343.4047\n",
            "Epoch 10653/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1349.1105 - val_loss: 1321.9792\n",
            "Epoch 10654/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1367.9443 - val_loss: 1349.7134\n",
            "Epoch 10655/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1376.5951 - val_loss: 1363.9675\n",
            "Epoch 10656/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1213.0586 - val_loss: 1352.5692\n",
            "Epoch 10657/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1322.6823 - val_loss: 1339.7959\n",
            "Epoch 10658/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1205.2376 - val_loss: 1634.5283\n",
            "Epoch 10659/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1682.9387 - val_loss: 1523.9493\n",
            "Epoch 10660/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1425.2244 - val_loss: 1537.4611\n",
            "Epoch 10661/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1346.9665 - val_loss: 1546.5587\n",
            "Epoch 10662/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1519.9370 - val_loss: 1466.6080\n",
            "Epoch 10663/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1431.7929 - val_loss: 1389.3351\n",
            "Epoch 10664/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1360.8565 - val_loss: 1387.6807\n",
            "Epoch 10665/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1368.9778 - val_loss: 1345.9120\n",
            "Epoch 10666/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1229.8792 - val_loss: 1335.1943\n",
            "Epoch 10667/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1410.1448 - val_loss: 1313.7949\n",
            "Epoch 10668/12000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1400.7779 - val_loss: 1349.4758\n",
            "Epoch 10669/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1449.2254 - val_loss: 1349.0590\n",
            "Epoch 10670/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1322.4218 - val_loss: 1323.7378\n",
            "Epoch 10671/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1228.7263 - val_loss: 1334.3181\n",
            "Epoch 10672/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1278.1241 - val_loss: 1295.5460\n",
            "Epoch 10673/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1263.8572 - val_loss: 1265.1759\n",
            "Epoch 10674/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1349.7948 - val_loss: 1271.8269\n",
            "Epoch 10675/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1384.3961 - val_loss: 1285.2686\n",
            "Epoch 10676/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1209.5517 - val_loss: 1352.9424\n",
            "Epoch 10677/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1228.8244 - val_loss: 1300.7028\n",
            "Epoch 10678/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1019.5059 - val_loss: 1326.7516\n",
            "Epoch 10679/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1177.7883 - val_loss: 1364.1101\n",
            "Epoch 10680/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1445.0349 - val_loss: 1403.3091\n",
            "Epoch 10681/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1311.7434 - val_loss: 1354.1282\n",
            "Epoch 10682/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1490.1020 - val_loss: 1341.6189\n",
            "Epoch 10683/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1320.1832 - val_loss: 1348.2316\n",
            "Epoch 10684/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1416.2043 - val_loss: 1304.4879\n",
            "Epoch 10685/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1330.6716 - val_loss: 1282.9183\n",
            "Epoch 10686/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1284.7171 - val_loss: 1236.9764\n",
            "Epoch 10687/12000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1320.4774 - val_loss: 1237.6907\n",
            "Epoch 10688/12000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 1151.1588 - val_loss: 1239.7046\n",
            "Epoch 10689/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1216.9610 - val_loss: 1256.8434\n",
            "Epoch 10690/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1236.7092 - val_loss: 1246.9989\n",
            "Epoch 10691/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1494.4273 - val_loss: 1251.4031\n",
            "Epoch 10692/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1218.9118 - val_loss: 1256.7872\n",
            "Epoch 10693/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1336.9865 - val_loss: 1247.1650\n",
            "Epoch 10694/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1322.5536 - val_loss: 1265.0010\n",
            "Epoch 10695/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1402.4995 - val_loss: 1253.1212\n",
            "Epoch 10696/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1307.1498 - val_loss: 1246.9502\n",
            "Epoch 10697/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1118.5436 - val_loss: 1244.4686\n",
            "Epoch 10698/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1331.7205 - val_loss: 1243.5444\n",
            "Epoch 10699/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1288.8331 - val_loss: 1231.4435\n",
            "Epoch 10700/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1332.0439 - val_loss: 1221.2407\n",
            "Epoch 10701/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1214.9806 - val_loss: 1233.5986\n",
            "Epoch 10702/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1229.1744 - val_loss: 1270.0765\n",
            "Epoch 10703/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1199.7274 - val_loss: 1260.3447\n",
            "Epoch 10704/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1277.6293 - val_loss: 1274.5778\n",
            "Epoch 10705/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1344.9547 - val_loss: 1233.8196\n",
            "Epoch 10706/12000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1220.1526 - val_loss: 1247.9750\n",
            "Epoch 10707/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1259.3521 - val_loss: 1249.6978\n",
            "Epoch 10708/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1195.6089 - val_loss: 1240.2844\n",
            "Epoch 10709/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1250.6649 - val_loss: 1204.2853\n",
            "Epoch 10710/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1258.2440 - val_loss: 1254.4843\n",
            "Epoch 10711/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1175.5422 - val_loss: 1226.7017\n",
            "Epoch 10712/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1314.5966 - val_loss: 1152.6738\n",
            "Epoch 10713/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1092.1511 - val_loss: 1171.4607\n",
            "Epoch 10714/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1227.9660 - val_loss: 1451.4865\n",
            "Epoch 10715/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1258.3562 - val_loss: 1167.1848\n",
            "Epoch 10716/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1243.7168 - val_loss: 1175.7822\n",
            "Epoch 10717/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1116.7958 - val_loss: 1210.7452\n",
            "Epoch 10718/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1169.1750 - val_loss: 1209.1438\n",
            "Epoch 10719/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1162.2252 - val_loss: 1229.1808\n",
            "Epoch 10720/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1305.0760 - val_loss: 1243.6143\n",
            "Epoch 10721/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1332.1262 - val_loss: 1222.9917\n",
            "Epoch 10722/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1192.4877 - val_loss: 1204.8280\n",
            "Epoch 10723/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1113.0503 - val_loss: 1234.2136\n",
            "Epoch 10724/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1166.5062 - val_loss: 1221.3442\n",
            "Epoch 10725/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1187.0364 - val_loss: 1298.5481\n",
            "Epoch 10726/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1255.9476 - val_loss: 1262.7394\n",
            "Epoch 10727/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1269.5684 - val_loss: 1340.8997\n",
            "Epoch 10728/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1375.5754 - val_loss: 1323.9078\n",
            "Epoch 10729/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1353.6749 - val_loss: 1312.0746\n",
            "Epoch 10730/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1443.8961 - val_loss: 1292.6802\n",
            "Epoch 10731/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1217.4525 - val_loss: 1298.8519\n",
            "Epoch 10732/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1233.6090 - val_loss: 1306.2411\n",
            "Epoch 10733/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1177.4620 - val_loss: 1310.3320\n",
            "Epoch 10734/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1481.8898 - val_loss: 1305.3232\n",
            "Epoch 10735/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1380.3156 - val_loss: 1325.9307\n",
            "Epoch 10736/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1307.3902 - val_loss: 1338.6376\n",
            "Epoch 10737/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1283.9746 - val_loss: 1330.3427\n",
            "Epoch 10738/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1218.7122 - val_loss: 1319.3191\n",
            "Epoch 10739/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1357.6865 - val_loss: 1322.1300\n",
            "Epoch 10740/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1155.9116 - val_loss: 1337.1572\n",
            "Epoch 10741/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1428.7389 - val_loss: 1333.5917\n",
            "Epoch 10742/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1300.5731 - val_loss: 1373.9897\n",
            "Epoch 10743/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1399.8496 - val_loss: 1358.6855\n",
            "Epoch 10744/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1223.3645 - val_loss: 1321.4117\n",
            "Epoch 10745/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1243.7313 - val_loss: 1315.7570\n",
            "Epoch 10746/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1411.2858 - val_loss: 1241.5160\n",
            "Epoch 10747/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1192.4513 - val_loss: 1351.2144\n",
            "Epoch 10748/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1371.5223 - val_loss: 1288.0961\n",
            "Epoch 10749/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1272.0830 - val_loss: 1319.2921\n",
            "Epoch 10750/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1211.2199 - val_loss: 1293.5111\n",
            "Epoch 10751/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1270.5809 - val_loss: 1299.4098\n",
            "Epoch 10752/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1269.2976 - val_loss: 1308.2015\n",
            "Epoch 10753/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1273.6006 - val_loss: 1386.6541\n",
            "Epoch 10754/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1553.6827 - val_loss: 1370.4054\n",
            "Epoch 10755/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1411.7304 - val_loss: 1376.8641\n",
            "Epoch 10756/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1384.6163 - val_loss: 1363.8180\n",
            "Epoch 10757/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1310.8110 - val_loss: 1291.0237\n",
            "Epoch 10758/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1527.4395 - val_loss: 1320.0676\n",
            "Epoch 10759/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1234.2795 - val_loss: 1307.7980\n",
            "Epoch 10760/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1198.1855 - val_loss: 1294.6790\n",
            "Epoch 10761/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1257.6074 - val_loss: 1301.3739\n",
            "Epoch 10762/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1174.5129 - val_loss: 1287.7981\n",
            "Epoch 10763/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1394.9513 - val_loss: 1314.3076\n",
            "Epoch 10764/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1326.8754 - val_loss: 1484.0808\n",
            "Epoch 10765/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1461.3867 - val_loss: 1376.2822\n",
            "Epoch 10766/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1305.0280 - val_loss: 1369.4900\n",
            "Epoch 10767/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1302.7076 - val_loss: 1404.3605\n",
            "Epoch 10768/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1703.1845 - val_loss: 1587.1176\n",
            "Epoch 10769/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1627.4636 - val_loss: 1660.5066\n",
            "Epoch 10770/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1510.0614 - val_loss: 1657.2092\n",
            "Epoch 10771/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1588.4965 - val_loss: 1538.5754\n",
            "Epoch 10772/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1444.2930 - val_loss: 1666.9470\n",
            "Epoch 10773/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1335.9260 - val_loss: 1513.4205\n",
            "Epoch 10774/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1488.0834 - val_loss: 1762.7566\n",
            "Epoch 10775/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1706.0519 - val_loss: 1860.2672\n",
            "Epoch 10776/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1867.3437 - val_loss: 1788.1790\n",
            "Epoch 10777/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1796.5482 - val_loss: 1851.2916\n",
            "Epoch 10778/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2058.3575 - val_loss: 2376.3020\n",
            "Epoch 10779/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2357.1519 - val_loss: 2164.9165\n",
            "Epoch 10780/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 2365.8280 - val_loss: 2061.9829\n",
            "Epoch 10781/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2051.6657 - val_loss: 1898.5353\n",
            "Epoch 10782/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1697.1545 - val_loss: 1991.9962\n",
            "Epoch 10783/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2053.7681 - val_loss: 2029.4285\n",
            "Epoch 10784/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2126.7833 - val_loss: 2029.9050\n",
            "Epoch 10785/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2178.5901 - val_loss: 1968.8961\n",
            "Epoch 10786/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1877.0933 - val_loss: 1987.8134\n",
            "Epoch 10787/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1997.1514 - val_loss: 2016.9810\n",
            "Epoch 10788/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2933.4774 - val_loss: 3568.0989\n",
            "Epoch 10789/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 3172.4234 - val_loss: 2680.2051\n",
            "Epoch 10790/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 2648.6840 - val_loss: 3033.8562\n",
            "Epoch 10791/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 3059.6712 - val_loss: 2760.8445\n",
            "Epoch 10792/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2846.3982 - val_loss: 2752.5923\n",
            "Epoch 10793/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 2559.4845 - val_loss: 2850.3550\n",
            "Epoch 10794/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2548.6007 - val_loss: 2504.8904\n",
            "Epoch 10795/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2543.0542 - val_loss: 2434.8555\n",
            "Epoch 10796/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2353.7599 - val_loss: 2243.0571\n",
            "Epoch 10797/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2037.2272 - val_loss: 2372.3809\n",
            "Epoch 10798/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2324.2120 - val_loss: 2180.3083\n",
            "Epoch 10799/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2091.2646 - val_loss: 2171.6533\n",
            "Epoch 10800/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2245.7810 - val_loss: 2097.9236\n",
            "Epoch 10801/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1893.4576 - val_loss: 2062.6196\n",
            "Epoch 10802/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2210.3511 - val_loss: 2067.7886\n",
            "Epoch 10803/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 2106.3187 - val_loss: 1963.2655\n",
            "Epoch 10804/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2246.7851 - val_loss: 2005.4648\n",
            "Epoch 10805/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2148.6588 - val_loss: 1961.8165\n",
            "Epoch 10806/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1968.2106 - val_loss: 1801.3135\n",
            "Epoch 10807/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1746.9749 - val_loss: 2077.3809\n",
            "Epoch 10808/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2113.6563 - val_loss: 2076.6348\n",
            "Epoch 10809/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1902.7802 - val_loss: 2019.4493\n",
            "Epoch 10810/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2073.3413 - val_loss: 1932.9882\n",
            "Epoch 10811/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2019.8893 - val_loss: 2084.0791\n",
            "Epoch 10812/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2119.2390 - val_loss: 2131.6538\n",
            "Epoch 10813/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2009.8261 - val_loss: 2015.5078\n",
            "Epoch 10814/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 2216.2193 - val_loss: 2077.5156\n",
            "Epoch 10815/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2037.8383 - val_loss: 2049.2615\n",
            "Epoch 10816/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 2149.5689 - val_loss: 2163.1050\n",
            "Epoch 10817/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2106.1360 - val_loss: 2151.5227\n",
            "Epoch 10818/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2179.1740 - val_loss: 2089.1609\n",
            "Epoch 10819/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2177.1124 - val_loss: 2123.8003\n",
            "Epoch 10820/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1935.2039 - val_loss: 1942.8378\n",
            "Epoch 10821/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1972.4793 - val_loss: 1885.7887\n",
            "Epoch 10822/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1845.0669 - val_loss: 1803.8142\n",
            "Epoch 10823/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1825.6573 - val_loss: 1748.8378\n",
            "Epoch 10824/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1570.6957 - val_loss: 1736.6488\n",
            "Epoch 10825/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1695.6323 - val_loss: 1727.4240\n",
            "Epoch 10826/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1576.5447 - val_loss: 1699.2938\n",
            "Epoch 10827/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1720.1702 - val_loss: 1714.8112\n",
            "Epoch 10828/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1807.8459 - val_loss: 1675.3958\n",
            "Epoch 10829/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1743.2323 - val_loss: 1670.2531\n",
            "Epoch 10830/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1650.8054 - val_loss: 1595.3866\n",
            "Epoch 10831/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1613.8464 - val_loss: 1624.6165\n",
            "Epoch 10832/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1661.1957 - val_loss: 1550.4814\n",
            "Epoch 10833/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1415.3029 - val_loss: 1555.0217\n",
            "Epoch 10834/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1683.7284 - val_loss: 1551.8810\n",
            "Epoch 10835/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1694.5412 - val_loss: 1638.3077\n",
            "Epoch 10836/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1596.4586 - val_loss: 1556.9146\n",
            "Epoch 10837/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1622.9261 - val_loss: 1679.4250\n",
            "Epoch 10838/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1590.5805 - val_loss: 1554.3347\n",
            "Epoch 10839/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1584.3371 - val_loss: 1676.4236\n",
            "Epoch 10840/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1537.5308 - val_loss: 1590.9103\n",
            "Epoch 10841/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1499.0468 - val_loss: 1617.5842\n",
            "Epoch 10842/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1792.3853 - val_loss: 1582.0507\n",
            "Epoch 10843/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1584.2109 - val_loss: 1607.4653\n",
            "Epoch 10844/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1554.8587 - val_loss: 1590.4329\n",
            "Epoch 10845/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1600.1686 - val_loss: 1556.7440\n",
            "Epoch 10846/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1522.9566 - val_loss: 1549.6659\n",
            "Epoch 10847/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1489.8412 - val_loss: 1534.3524\n",
            "Epoch 10848/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1710.3425 - val_loss: 1542.6051\n",
            "Epoch 10849/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1646.4423 - val_loss: 1524.7948\n",
            "Epoch 10850/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1449.7584 - val_loss: 1523.3020\n",
            "Epoch 10851/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1721.3755 - val_loss: 1526.8521\n",
            "Epoch 10852/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1577.8267 - val_loss: 1518.3734\n",
            "Epoch 10853/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1439.6016 - val_loss: 1526.0027\n",
            "Epoch 10854/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1476.9728 - val_loss: 1490.2004\n",
            "Epoch 10855/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1597.7010 - val_loss: 1485.5161\n",
            "Epoch 10856/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1648.5296 - val_loss: 1494.1914\n",
            "Epoch 10857/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1439.2627 - val_loss: 1550.7008\n",
            "Epoch 10858/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1431.9325 - val_loss: 1525.9105\n",
            "Epoch 10859/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1312.9175 - val_loss: 1512.8093\n",
            "Epoch 10860/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1401.4654 - val_loss: 1509.3116\n",
            "Epoch 10861/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1432.2666 - val_loss: 1506.8624\n",
            "Epoch 10862/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1358.9204 - val_loss: 1503.4757\n",
            "Epoch 10863/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1436.4744 - val_loss: 1523.4023\n",
            "Epoch 10864/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1374.6283 - val_loss: 1529.6240\n",
            "Epoch 10865/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1621.5274 - val_loss: 1584.5565\n",
            "Epoch 10866/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1568.5382 - val_loss: 1531.2634\n",
            "Epoch 10867/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1481.9772 - val_loss: 1465.7460\n",
            "Epoch 10868/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1384.4166 - val_loss: 1453.4460\n",
            "Epoch 10869/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1475.4460 - val_loss: 1459.5499\n",
            "Epoch 10870/12000\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 1488.2760 - val_loss: 1471.1168\n",
            "Epoch 10871/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1507.5588 - val_loss: 1461.5942\n",
            "Epoch 10872/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1499.7959 - val_loss: 1459.1335\n",
            "Epoch 10873/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1409.7487 - val_loss: 1456.9978\n",
            "Epoch 10874/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1489.6706 - val_loss: 1451.7535\n",
            "Epoch 10875/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1259.3041 - val_loss: 1460.9873\n",
            "Epoch 10876/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1652.0725 - val_loss: 1464.1870\n",
            "Epoch 10877/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1620.4304 - val_loss: 1450.7526\n",
            "Epoch 10878/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1420.8165 - val_loss: 1486.7310\n",
            "Epoch 10879/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1467.5328 - val_loss: 1474.0844\n",
            "Epoch 10880/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1561.8602 - val_loss: 1479.4375\n",
            "Epoch 10881/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1262.1955 - val_loss: 1470.1299\n",
            "Epoch 10882/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1513.9761 - val_loss: 1460.6946\n",
            "Epoch 10883/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1358.0133 - val_loss: 1450.7892\n",
            "Epoch 10884/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1468.5295 - val_loss: 1483.3252\n",
            "Epoch 10885/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1430.2626 - val_loss: 1414.8610\n",
            "Epoch 10886/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1524.1963 - val_loss: 1396.2976\n",
            "Epoch 10887/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1195.3069 - val_loss: 1390.2913\n",
            "Epoch 10888/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1159.1627 - val_loss: 1380.0782\n",
            "Epoch 10889/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1437.7403 - val_loss: 1364.6625\n",
            "Epoch 10890/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1331.4817 - val_loss: 1354.0864\n",
            "Epoch 10891/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1365.0097 - val_loss: 1350.4528\n",
            "Epoch 10892/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1469.9835 - val_loss: 1364.2618\n",
            "Epoch 10893/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1302.8529 - val_loss: 1358.9452\n",
            "Epoch 10894/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1529.9034 - val_loss: 1359.9094\n",
            "Epoch 10895/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1324.8035 - val_loss: 1486.5304\n",
            "Epoch 10896/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1639.0446 - val_loss: 1866.0472\n",
            "Epoch 10897/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2013.4723 - val_loss: 1738.5129\n",
            "Epoch 10898/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1817.4630 - val_loss: 2627.9558\n",
            "Epoch 10899/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2767.7515 - val_loss: 2184.7026\n",
            "Epoch 10900/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1869.9895 - val_loss: 1510.3560\n",
            "Epoch 10901/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1431.4688 - val_loss: 1630.2091\n",
            "Epoch 10902/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1553.4399 - val_loss: 1468.7529\n",
            "Epoch 10903/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1364.9919 - val_loss: 1464.3665\n",
            "Epoch 10904/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1343.7149 - val_loss: 1456.2429\n",
            "Epoch 10905/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1505.5347 - val_loss: 1468.4188\n",
            "Epoch 10906/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1494.0559 - val_loss: 1463.9246\n",
            "Epoch 10907/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1325.2004 - val_loss: 1460.2892\n",
            "Epoch 10908/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1383.1473 - val_loss: 1453.7518\n",
            "Epoch 10909/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1533.5327 - val_loss: 1448.9789\n",
            "Epoch 10910/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1398.9044 - val_loss: 1439.1101\n",
            "Epoch 10911/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1421.5026 - val_loss: 1445.8164\n",
            "Epoch 10912/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1504.3755 - val_loss: 1433.1555\n",
            "Epoch 10913/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1362.3127 - val_loss: 1434.9142\n",
            "Epoch 10914/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1466.5756 - val_loss: 1428.0073\n",
            "Epoch 10915/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1469.3244 - val_loss: 1426.3676\n",
            "Epoch 10916/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1380.0480 - val_loss: 1421.9385\n",
            "Epoch 10917/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1572.4664 - val_loss: 1416.0575\n",
            "Epoch 10918/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1549.3085 - val_loss: 1411.3322\n",
            "Epoch 10919/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1310.9961 - val_loss: 1391.0386\n",
            "Epoch 10920/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1143.4720 - val_loss: 1401.7712\n",
            "Epoch 10921/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1416.8852 - val_loss: 1448.3519\n",
            "Epoch 10922/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1535.1184 - val_loss: 1443.9789\n",
            "Epoch 10923/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1399.1258 - val_loss: 1441.2047\n",
            "Epoch 10924/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1543.5695 - val_loss: 1473.3165\n",
            "Epoch 10925/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1338.8141 - val_loss: 1491.7797\n",
            "Epoch 10926/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1598.2121 - val_loss: 1480.2343\n",
            "Epoch 10927/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1430.0427 - val_loss: 1466.3961\n",
            "Epoch 10928/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1371.6508 - val_loss: 1460.3219\n",
            "Epoch 10929/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1581.9361 - val_loss: 1466.1633\n",
            "Epoch 10930/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1537.0941 - val_loss: 1452.9305\n",
            "Epoch 10931/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1463.1585 - val_loss: 1443.3512\n",
            "Epoch 10932/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1424.4800 - val_loss: 1437.4713\n",
            "Epoch 10933/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1306.0991 - val_loss: 1428.7908\n",
            "Epoch 10934/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1277.8325 - val_loss: 1428.1077\n",
            "Epoch 10935/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1541.5541 - val_loss: 1423.7604\n",
            "Epoch 10936/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1402.9224 - val_loss: 1420.8601\n",
            "Epoch 10937/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1465.5131 - val_loss: 1416.3580\n",
            "Epoch 10938/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1603.0156 - val_loss: 1410.6543\n",
            "Epoch 10939/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1315.5267 - val_loss: 1406.3087\n",
            "Epoch 10940/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1362.8360 - val_loss: 1406.6577\n",
            "Epoch 10941/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1544.4527 - val_loss: 1396.4984\n",
            "Epoch 10942/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1523.3718 - val_loss: 1391.8452\n",
            "Epoch 10943/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1518.3579 - val_loss: 1392.7570\n",
            "Epoch 10944/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1381.7665 - val_loss: 1390.6039\n",
            "Epoch 10945/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1370.0582 - val_loss: 1390.7946\n",
            "Epoch 10946/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1494.2398 - val_loss: 1377.5671\n",
            "Epoch 10947/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1405.3588 - val_loss: 1380.4836\n",
            "Epoch 10948/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1662.0033 - val_loss: 1390.4684\n",
            "Epoch 10949/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1513.9503 - val_loss: 1383.2467\n",
            "Epoch 10950/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1359.4994 - val_loss: 1389.2594\n",
            "Epoch 10951/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1347.3751 - val_loss: 1409.3916\n",
            "Epoch 10952/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1388.9618 - val_loss: 1327.0787\n",
            "Epoch 10953/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1459.8893 - val_loss: 1321.0713\n",
            "Epoch 10954/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1372.8554 - val_loss: 1318.4333\n",
            "Epoch 10955/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1268.7696 - val_loss: 1381.7988\n",
            "Epoch 10956/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1498.3478 - val_loss: 1332.3877\n",
            "Epoch 10957/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1407.8670 - val_loss: 1327.0719\n",
            "Epoch 10958/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1292.2790 - val_loss: 1277.3676\n",
            "Epoch 10959/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1189.5383 - val_loss: 1250.2244\n",
            "Epoch 10960/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1295.4137 - val_loss: 1262.6243\n",
            "Epoch 10961/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1515.7531 - val_loss: 1258.4056\n",
            "Epoch 10962/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1279.1949 - val_loss: 1259.9181\n",
            "Epoch 10963/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1297.4242 - val_loss: 1267.0886\n",
            "Epoch 10964/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1417.2347 - val_loss: 1263.5236\n",
            "Epoch 10965/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1406.1315 - val_loss: 1258.7417\n",
            "Epoch 10966/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1130.0704 - val_loss: 1249.4723\n",
            "Epoch 10967/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1141.3706 - val_loss: 1246.6305\n",
            "Epoch 10968/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1160.3724 - val_loss: 1238.9495\n",
            "Epoch 10969/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1335.8026 - val_loss: 1254.1743\n",
            "Epoch 10970/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1261.5276 - val_loss: 1232.5027\n",
            "Epoch 10971/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1339.8015 - val_loss: 1248.2990\n",
            "Epoch 10972/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1330.3191 - val_loss: 1233.4342\n",
            "Epoch 10973/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1182.0016 - val_loss: 1237.1210\n",
            "Epoch 10974/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1186.7742 - val_loss: 1235.9915\n",
            "Epoch 10975/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1288.7888 - val_loss: 1252.8702\n",
            "Epoch 10976/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1298.5037 - val_loss: 1255.3815\n",
            "Epoch 10977/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1209.2504 - val_loss: 1255.0710\n",
            "Epoch 10978/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1294.3331 - val_loss: 1234.0839\n",
            "Epoch 10979/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1073.8702 - val_loss: 1221.0535\n",
            "Epoch 10980/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1353.9893 - val_loss: 1217.8293\n",
            "Epoch 10981/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1116.0380 - val_loss: 1216.1567\n",
            "Epoch 10982/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1158.3723 - val_loss: 1218.9250\n",
            "Epoch 10983/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1339.0155 - val_loss: 1212.2744\n",
            "Epoch 10984/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1213.4409 - val_loss: 1206.5791\n",
            "Epoch 10985/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1186.9080 - val_loss: 1207.6788\n",
            "Epoch 10986/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1282.7201 - val_loss: 1212.4449\n",
            "Epoch 10987/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1109.9055 - val_loss: 1189.6332\n",
            "Epoch 10988/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1070.6446 - val_loss: 1178.0900\n",
            "Epoch 10989/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1105.2423 - val_loss: 1175.3964\n",
            "Epoch 10990/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1277.4477 - val_loss: 1184.2714\n",
            "Epoch 10991/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1186.7569 - val_loss: 1173.4703\n",
            "Epoch 10992/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1257.4425 - val_loss: 1158.7415\n",
            "Epoch 10993/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1160.6198 - val_loss: 1171.4608\n",
            "Epoch 10994/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1254.8095 - val_loss: 1183.8888\n",
            "Epoch 10995/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1200.3044 - val_loss: 1175.4060\n",
            "Epoch 10996/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1107.6981 - val_loss: 1168.6779\n",
            "Epoch 10997/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1152.3730 - val_loss: 1168.6993\n",
            "Epoch 10998/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1120.2986 - val_loss: 1166.7683\n",
            "Epoch 10999/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1101.4727 - val_loss: 1164.8914\n",
            "Epoch 11000/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1290.6239 - val_loss: 1167.3992\n",
            "Epoch 11001/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1200.9434 - val_loss: 1166.5005\n",
            "Epoch 11002/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1212.5184 - val_loss: 1164.9376\n",
            "Epoch 11003/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1117.0728 - val_loss: 1160.4211\n",
            "Epoch 11004/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1303.5946 - val_loss: 1157.5544\n",
            "Epoch 11005/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1175.4447 - val_loss: 1158.4189\n",
            "Epoch 11006/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1140.4768 - val_loss: 1163.2867\n",
            "Epoch 11007/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1062.4789 - val_loss: 1167.6527\n",
            "Epoch 11008/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1161.4636 - val_loss: 1171.0586\n",
            "Epoch 11009/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1194.2249 - val_loss: 1156.9357\n",
            "Epoch 11010/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 990.0624 - val_loss: 1154.0289\n",
            "Epoch 11011/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1128.4528 - val_loss: 1154.6442\n",
            "Epoch 11012/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1075.1887 - val_loss: 1171.1576\n",
            "Epoch 11013/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1258.1927 - val_loss: 1159.9022\n",
            "Epoch 11014/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1194.3367 - val_loss: 1171.9287\n",
            "Epoch 11015/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1177.6069 - val_loss: 1160.5253\n",
            "Epoch 11016/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1077.4173 - val_loss: 1170.7887\n",
            "Epoch 11017/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 990.3944 - val_loss: 1162.7142\n",
            "Epoch 11018/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1262.9794 - val_loss: 2410.9114\n",
            "Epoch 11019/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2291.9976 - val_loss: 1448.0291\n",
            "Epoch 11020/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1399.2438 - val_loss: 1325.4363\n",
            "Epoch 11021/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1297.7288 - val_loss: 1257.1481\n",
            "Epoch 11022/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1253.5384 - val_loss: 1289.1500\n",
            "Epoch 11023/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1185.7444 - val_loss: 1291.2797\n",
            "Epoch 11024/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1405.1744 - val_loss: 1278.0140\n",
            "Epoch 11025/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1388.1448 - val_loss: 1269.6587\n",
            "Epoch 11026/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1206.0032 - val_loss: 1282.1415\n",
            "Epoch 11027/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1186.8949 - val_loss: 1282.8719\n",
            "Epoch 11028/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1191.0444 - val_loss: 1284.3629\n",
            "Epoch 11029/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1117.5591 - val_loss: 1274.6083\n",
            "Epoch 11030/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1221.4318 - val_loss: 1261.0219\n",
            "Epoch 11031/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1265.3395 - val_loss: 1251.8773\n",
            "Epoch 11032/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1251.3659 - val_loss: 1242.9646\n",
            "Epoch 11033/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1323.2041 - val_loss: 1243.6469\n",
            "Epoch 11034/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1255.1272 - val_loss: 1246.9717\n",
            "Epoch 11035/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1235.6185 - val_loss: 1217.8998\n",
            "Epoch 11036/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1225.6177 - val_loss: 1206.7384\n",
            "Epoch 11037/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1304.8244 - val_loss: 1197.4617\n",
            "Epoch 11038/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1017.6961 - val_loss: 1189.4210\n",
            "Epoch 11039/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1123.9130 - val_loss: 1244.6366\n",
            "Epoch 11040/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1165.5416 - val_loss: 1309.7448\n",
            "Epoch 11041/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1366.7739 - val_loss: 1239.5897\n",
            "Epoch 11042/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1345.9774 - val_loss: 1222.1635\n",
            "Epoch 11043/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1232.8445 - val_loss: 1221.2682\n",
            "Epoch 11044/12000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1310.1935 - val_loss: 1276.0581\n",
            "Epoch 11045/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1155.2501 - val_loss: 1242.8550\n",
            "Epoch 11046/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1202.9771 - val_loss: 1227.0099\n",
            "Epoch 11047/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1246.6969 - val_loss: 1224.0630\n",
            "Epoch 11048/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1229.8934 - val_loss: 1213.7941\n",
            "Epoch 11049/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1196.8495 - val_loss: 1233.1104\n",
            "Epoch 11050/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1261.3314 - val_loss: 1226.6067\n",
            "Epoch 11051/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1281.2753 - val_loss: 1212.0325\n",
            "Epoch 11052/12000\n",
            "12/12 [==============================] - 0s 43ms/step - loss: 1208.9678 - val_loss: 1205.4366\n",
            "Epoch 11053/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1140.5410 - val_loss: 1191.7451\n",
            "Epoch 11054/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1172.3238 - val_loss: 1206.7102\n",
            "Epoch 11055/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1129.1746 - val_loss: 1186.5548\n",
            "Epoch 11056/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1064.2580 - val_loss: 1181.7963\n",
            "Epoch 11057/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1176.8486 - val_loss: 1183.9492\n",
            "Epoch 11058/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1277.2159 - val_loss: 1180.0947\n",
            "Epoch 11059/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1192.2082 - val_loss: 1169.9320\n",
            "Epoch 11060/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1082.5595 - val_loss: 1175.9282\n",
            "Epoch 11061/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1175.1560 - val_loss: 1169.1191\n",
            "Epoch 11062/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1189.2251 - val_loss: 1164.8363\n",
            "Epoch 11063/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1135.5998 - val_loss: 1161.9675\n",
            "Epoch 11064/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1132.7548 - val_loss: 1160.6249\n",
            "Epoch 11065/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1192.7144 - val_loss: 1158.0635\n",
            "Epoch 11066/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1110.7180 - val_loss: 1155.0925\n",
            "Epoch 11067/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1103.7212 - val_loss: 1138.3777\n",
            "Epoch 11068/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1159.8357 - val_loss: 1144.2098\n",
            "Epoch 11069/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1245.1090 - val_loss: 1148.3671\n",
            "Epoch 11070/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1080.0867 - val_loss: 1154.9136\n",
            "Epoch 11071/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1326.4165 - val_loss: 1159.0101\n",
            "Epoch 11072/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1033.5471 - val_loss: 1172.4554\n",
            "Epoch 11073/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1300.5931 - val_loss: 1166.2657\n",
            "Epoch 11074/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1198.1849 - val_loss: 1166.9209\n",
            "Epoch 11075/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1014.2792 - val_loss: 1162.6617\n",
            "Epoch 11076/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1195.8475 - val_loss: 1156.4767\n",
            "Epoch 11077/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1209.9715 - val_loss: 1166.5125\n",
            "Epoch 11078/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1123.1959 - val_loss: 1175.6754\n",
            "Epoch 11079/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1296.3197 - val_loss: 1152.3810\n",
            "Epoch 11080/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1268.9418 - val_loss: 1146.4164\n",
            "Epoch 11081/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1138.6166 - val_loss: 1151.9982\n",
            "Epoch 11082/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1156.9986 - val_loss: 1146.6262\n",
            "Epoch 11083/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1274.0277 - val_loss: 1143.2703\n",
            "Epoch 11084/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1261.1615 - val_loss: 1135.7823\n",
            "Epoch 11085/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1311.2234 - val_loss: 1145.9098\n",
            "Epoch 11086/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1042.2677 - val_loss: 1136.6171\n",
            "Epoch 11087/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1129.7985 - val_loss: 1136.4452\n",
            "Epoch 11088/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1119.4045 - val_loss: 1133.5198\n",
            "Epoch 11089/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1192.4965 - val_loss: 1142.9172\n",
            "Epoch 11090/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1264.2553 - val_loss: 1110.3225\n",
            "Epoch 11091/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1032.3635 - val_loss: 1102.9681\n",
            "Epoch 11092/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1121.1872 - val_loss: 1127.5065\n",
            "Epoch 11093/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1071.2765 - val_loss: 1111.7961\n",
            "Epoch 11094/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1074.4887 - val_loss: 1106.5312\n",
            "Epoch 11095/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1167.4626 - val_loss: 1101.2627\n",
            "Epoch 11096/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1214.8532 - val_loss: 1124.6121\n",
            "Epoch 11097/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1316.2905 - val_loss: 1140.1570\n",
            "Epoch 11098/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1288.7097 - val_loss: 1160.3864\n",
            "Epoch 11099/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1223.3970 - val_loss: 1139.3424\n",
            "Epoch 11100/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1010.9022 - val_loss: 1151.6969\n",
            "Epoch 11101/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1137.4789 - val_loss: 1231.1608\n",
            "Epoch 11102/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1122.3260 - val_loss: 1211.0123\n",
            "Epoch 11103/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1045.8457 - val_loss: 1206.8126\n",
            "Epoch 11104/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1357.1790 - val_loss: 1205.0485\n",
            "Epoch 11105/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1214.8497 - val_loss: 1200.7555\n",
            "Epoch 11106/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1263.9848 - val_loss: 1208.1768\n",
            "Epoch 11107/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1240.9365 - val_loss: 1184.3658\n",
            "Epoch 11108/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1252.8089 - val_loss: 1220.3799\n",
            "Epoch 11109/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1079.5530 - val_loss: 1192.2468\n",
            "Epoch 11110/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1259.5782 - val_loss: 1147.0675\n",
            "Epoch 11111/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1236.9724 - val_loss: 1272.6499\n",
            "Epoch 11112/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1253.4443 - val_loss: 1133.5571\n",
            "Epoch 11113/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1250.9212 - val_loss: 1844.1418\n",
            "Epoch 11114/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1757.9291 - val_loss: 1355.9357\n",
            "Epoch 11115/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1304.3214 - val_loss: 1232.3525\n",
            "Epoch 11116/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1294.1198 - val_loss: 1229.9878\n",
            "Epoch 11117/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1234.8101 - val_loss: 1201.2900\n",
            "Epoch 11118/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1135.3011 - val_loss: 1193.7145\n",
            "Epoch 11119/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1300.8078 - val_loss: 1187.0911\n",
            "Epoch 11120/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1192.4956 - val_loss: 1191.4645\n",
            "Epoch 11121/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1180.3670 - val_loss: 1186.1396\n",
            "Epoch 11122/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1208.6703 - val_loss: 1237.5205\n",
            "Epoch 11123/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1454.8251 - val_loss: 1369.7103\n",
            "Epoch 11124/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1241.4250 - val_loss: 1385.0319\n",
            "Epoch 11125/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1286.1338 - val_loss: 1329.0861\n",
            "Epoch 11126/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1173.0428 - val_loss: 1286.1560\n",
            "Epoch 11127/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1375.5564 - val_loss: 1267.4800\n",
            "Epoch 11128/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1372.3791 - val_loss: 1254.1488\n",
            "Epoch 11129/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1145.2981 - val_loss: 1250.9773\n",
            "Epoch 11130/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1337.3925 - val_loss: 1254.2266\n",
            "Epoch 11131/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1283.3333 - val_loss: 1260.3636\n",
            "Epoch 11132/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1297.3352 - val_loss: 1247.8698\n",
            "Epoch 11133/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1144.3888 - val_loss: 1242.4098\n",
            "Epoch 11134/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1243.3141 - val_loss: 1244.1720\n",
            "Epoch 11135/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1175.9741 - val_loss: 1239.6996\n",
            "Epoch 11136/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1295.5246 - val_loss: 1221.7173\n",
            "Epoch 11137/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1244.8482 - val_loss: 1215.1611\n",
            "Epoch 11138/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1228.5457 - val_loss: 1264.4767\n",
            "Epoch 11139/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1191.3996 - val_loss: 1253.1305\n",
            "Epoch 11140/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1222.0372 - val_loss: 1249.9128\n",
            "Epoch 11141/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1237.8050 - val_loss: 1250.7502\n",
            "Epoch 11142/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1102.7532 - val_loss: 1173.7758\n",
            "Epoch 11143/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1150.3020 - val_loss: 1189.0243\n",
            "Epoch 11144/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1264.2158 - val_loss: 1160.8099\n",
            "Epoch 11145/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1215.3526 - val_loss: 1155.7034\n",
            "Epoch 11146/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1245.2778 - val_loss: 1185.8708\n",
            "Epoch 11147/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1149.2748 - val_loss: 1179.5077\n",
            "Epoch 11148/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1102.8834 - val_loss: 1179.2750\n",
            "Epoch 11149/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1092.8107 - val_loss: 1168.7184\n",
            "Epoch 11150/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1204.6580 - val_loss: 1155.6770\n",
            "Epoch 11151/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1195.3118 - val_loss: 1148.3492\n",
            "Epoch 11152/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1151.6452 - val_loss: 1155.3054\n",
            "Epoch 11153/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1116.5609 - val_loss: 1129.8448\n",
            "Epoch 11154/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1085.4435 - val_loss: 1123.0789\n",
            "Epoch 11155/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1279.2710 - val_loss: 1116.4309\n",
            "Epoch 11156/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1086.2600 - val_loss: 1121.1028\n",
            "Epoch 11157/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1045.7980 - val_loss: 1090.6383\n",
            "Epoch 11158/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1074.4994 - val_loss: 1073.4198\n",
            "Epoch 11159/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1034.0366 - val_loss: 1081.3512\n",
            "Epoch 11160/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1081.8738 - val_loss: 1090.5886\n",
            "Epoch 11161/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1054.4332 - val_loss: 1077.8608\n",
            "Epoch 11162/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1045.6226 - val_loss: 1076.7164\n",
            "Epoch 11163/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1100.5785 - val_loss: 1101.3582\n",
            "Epoch 11164/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1171.3858 - val_loss: 1122.7697\n",
            "Epoch 11165/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1063.5434 - val_loss: 1119.2133\n",
            "Epoch 11166/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1135.7780 - val_loss: 1118.4231\n",
            "Epoch 11167/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1203.6098 - val_loss: 1112.3777\n",
            "Epoch 11168/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1076.1598 - val_loss: 1102.8368\n",
            "Epoch 11169/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1126.5105 - val_loss: 1100.8304\n",
            "Epoch 11170/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1126.6087 - val_loss: 1103.2229\n",
            "Epoch 11171/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1150.7160 - val_loss: 1096.6093\n",
            "Epoch 11172/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1240.5542 - val_loss: 1092.4871\n",
            "Epoch 11173/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1094.8913 - val_loss: 1092.9312\n",
            "Epoch 11174/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1026.6147 - val_loss: 1088.6516\n",
            "Epoch 11175/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1059.0826 - val_loss: 1089.7887\n",
            "Epoch 11176/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 923.1566 - val_loss: 1093.2092\n",
            "Epoch 11177/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1129.3803 - val_loss: 1086.1217\n",
            "Epoch 11178/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1111.0771 - val_loss: 1131.0847\n",
            "Epoch 11179/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1262.4168 - val_loss: 1111.5133\n",
            "Epoch 11180/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 943.6030 - val_loss: 1100.6473\n",
            "Epoch 11181/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1074.5240 - val_loss: 1065.0143\n",
            "Epoch 11182/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 980.6578 - val_loss: 1061.4600\n",
            "Epoch 11183/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1008.8446 - val_loss: 1057.1895\n",
            "Epoch 11184/12000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1067.8056 - val_loss: 1059.2028\n",
            "Epoch 11185/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 998.3657 - val_loss: 1057.6543\n",
            "Epoch 11186/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1046.1960 - val_loss: 1085.8075\n",
            "Epoch 11187/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1166.0566 - val_loss: 1069.2036\n",
            "Epoch 11188/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1054.0766 - val_loss: 1094.0746\n",
            "Epoch 11189/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1160.5126 - val_loss: 1066.0250\n",
            "Epoch 11190/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 969.5578 - val_loss: 1046.8558\n",
            "Epoch 11191/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 979.2782 - val_loss: 1084.9014\n",
            "Epoch 11192/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1065.7949 - val_loss: 1040.1235\n",
            "Epoch 11193/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1016.7973 - val_loss: 1029.5343\n",
            "Epoch 11194/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 923.0318 - val_loss: 1024.5905\n",
            "Epoch 11195/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 963.8817 - val_loss: 1042.1638\n",
            "Epoch 11196/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1091.9489 - val_loss: 1042.5750\n",
            "Epoch 11197/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1157.9087 - val_loss: 1072.2775\n",
            "Epoch 11198/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1254.1419 - val_loss: 1023.1710\n",
            "Epoch 11199/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 990.6053 - val_loss: 1027.3448\n",
            "Epoch 11200/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1110.2975 - val_loss: 1027.6702\n",
            "Epoch 11201/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 965.1440 - val_loss: 1056.1251\n",
            "Epoch 11202/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 939.2119 - val_loss: 1053.6115\n",
            "Epoch 11203/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 978.5629 - val_loss: 1079.4036\n",
            "Epoch 11204/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 875.9841 - val_loss: 1081.4901\n",
            "Epoch 11205/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1159.3449 - val_loss: 1034.9530\n",
            "Epoch 11206/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 985.7103 - val_loss: 1077.9841\n",
            "Epoch 11207/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1041.4741 - val_loss: 1037.7869\n",
            "Epoch 11208/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 866.2488 - val_loss: 1069.4452\n",
            "Epoch 11209/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1035.5954 - val_loss: 1086.1976\n",
            "Epoch 11210/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1091.3023 - val_loss: 1022.9376\n",
            "Epoch 11211/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1014.0035 - val_loss: 1007.8467\n",
            "Epoch 11212/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1062.7822 - val_loss: 1018.2396\n",
            "Epoch 11213/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1022.0644 - val_loss: 1021.6661\n",
            "Epoch 11214/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1048.4172 - val_loss: 1013.4422\n",
            "Epoch 11215/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1017.5952 - val_loss: 1004.1531\n",
            "Epoch 11216/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1054.6032 - val_loss: 1000.6679\n",
            "Epoch 11217/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 883.9719 - val_loss: 1026.6650\n",
            "Epoch 11218/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1017.4154 - val_loss: 1029.9213\n",
            "Epoch 11219/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1132.4347 - val_loss: 1052.2125\n",
            "Epoch 11220/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1102.0672 - val_loss: 1168.7286\n",
            "Epoch 11221/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1123.1175 - val_loss: 1247.4921\n",
            "Epoch 11222/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1351.8894 - val_loss: 1399.6107\n",
            "Epoch 11223/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1446.8707 - val_loss: 1474.5531\n",
            "Epoch 11224/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1427.8680 - val_loss: 1368.0995\n",
            "Epoch 11225/12000\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 1459.5690 - val_loss: 1253.6953\n",
            "Epoch 11226/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1227.0680 - val_loss: 1330.4829\n",
            "Epoch 11227/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1327.5816 - val_loss: 1315.3657\n",
            "Epoch 11228/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1434.0601 - val_loss: 1599.0149\n",
            "Epoch 11229/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1554.5587 - val_loss: 1564.8777\n",
            "Epoch 11230/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1543.7383 - val_loss: 1341.5939\n",
            "Epoch 11231/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1581.1304 - val_loss: 1431.0980\n",
            "Epoch 11232/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1516.3256 - val_loss: 1406.3710\n",
            "Epoch 11233/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1248.3524 - val_loss: 1363.7893\n",
            "Epoch 11234/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1245.9607 - val_loss: 1339.5049\n",
            "Epoch 11235/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1251.2512 - val_loss: 1335.6025\n",
            "Epoch 11236/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1355.2922 - val_loss: 1344.0497\n",
            "Epoch 11237/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1459.1780 - val_loss: 1337.1632\n",
            "Epoch 11238/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1403.6672 - val_loss: 1319.0095\n",
            "Epoch 11239/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1582.3913 - val_loss: 2610.5813\n",
            "Epoch 11240/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2672.1721 - val_loss: 2249.0232\n",
            "Epoch 11241/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1996.4957 - val_loss: 1859.9023\n",
            "Epoch 11242/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1897.5945 - val_loss: 1621.1564\n",
            "Epoch 11243/12000\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 1586.3033 - val_loss: 1530.9250\n",
            "Epoch 11244/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1533.6411 - val_loss: 1415.5276\n",
            "Epoch 11245/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1439.3183 - val_loss: 1463.8220\n",
            "Epoch 11246/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1471.0086 - val_loss: 1455.1333\n",
            "Epoch 11247/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1478.4210 - val_loss: 1401.4741\n",
            "Epoch 11248/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1448.0555 - val_loss: 1388.8593\n",
            "Epoch 11249/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1392.5763 - val_loss: 1410.8860\n",
            "Epoch 11250/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1374.6094 - val_loss: 1412.2305\n",
            "Epoch 11251/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1561.1578 - val_loss: 1370.7336\n",
            "Epoch 11252/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1340.1352 - val_loss: 1358.9285\n",
            "Epoch 11253/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1377.5417 - val_loss: 1348.1448\n",
            "Epoch 11254/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1325.8599 - val_loss: 1300.7910\n",
            "Epoch 11255/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1308.3251 - val_loss: 1261.0450\n",
            "Epoch 11256/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1440.9801 - val_loss: 1325.2000\n",
            "Epoch 11257/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1541.6533 - val_loss: 1993.4006\n",
            "Epoch 11258/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2417.5982 - val_loss: 2768.4846\n",
            "Epoch 11259/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2918.3339 - val_loss: 3273.9299\n",
            "Epoch 11260/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 3457.9830 - val_loss: 3055.5659\n",
            "Epoch 11261/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2668.6250 - val_loss: 2999.5784\n",
            "Epoch 11262/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 3043.3382 - val_loss: 3169.4980\n",
            "Epoch 11263/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 3038.3391 - val_loss: 2853.3967\n",
            "Epoch 11264/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2929.9310 - val_loss: 2864.5896\n",
            "Epoch 11265/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2507.2673 - val_loss: 2858.4062\n",
            "Epoch 11266/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 3035.5262 - val_loss: 2517.3132\n",
            "Epoch 11267/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2267.6433 - val_loss: 2427.0696\n",
            "Epoch 11268/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2519.3415 - val_loss: 2274.3962\n",
            "Epoch 11269/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2106.3524 - val_loss: 2197.3406\n",
            "Epoch 11270/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1923.6497 - val_loss: 2175.2148\n",
            "Epoch 11271/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2308.8745 - val_loss: 2150.6521\n",
            "Epoch 11272/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2331.6854 - val_loss: 2000.0698\n",
            "Epoch 11273/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2080.9148 - val_loss: 1916.0525\n",
            "Epoch 11274/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2159.2066 - val_loss: 1937.8824\n",
            "Epoch 11275/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1986.5499 - val_loss: 1833.2023\n",
            "Epoch 11276/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2049.7689 - val_loss: 1820.1815\n",
            "Epoch 11277/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2087.7019 - val_loss: 1778.3250\n",
            "Epoch 11278/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1989.1106 - val_loss: 1745.8528\n",
            "Epoch 11279/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2136.0605 - val_loss: 1677.9633\n",
            "Epoch 11280/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1967.9313 - val_loss: 1759.7087\n",
            "Epoch 11281/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1669.9229 - val_loss: 1667.9968\n",
            "Epoch 11282/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1636.2942 - val_loss: 1640.6754\n",
            "Epoch 11283/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1583.9467 - val_loss: 1642.2495\n",
            "Epoch 11284/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1809.9109 - val_loss: 1560.2847\n",
            "Epoch 11285/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1416.4618 - val_loss: 1479.5048\n",
            "Epoch 11286/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1625.7861 - val_loss: 1378.9338\n",
            "Epoch 11287/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1368.5493 - val_loss: 1415.0715\n",
            "Epoch 11288/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1508.1341 - val_loss: 1346.7050\n",
            "Epoch 11289/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1390.9158 - val_loss: 1350.5321\n",
            "Epoch 11290/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1297.3529 - val_loss: 1326.4711\n",
            "Epoch 11291/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1404.5934 - val_loss: 1325.3269\n",
            "Epoch 11292/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1278.3711 - val_loss: 1303.7061\n",
            "Epoch 11293/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1371.3976 - val_loss: 1494.4808\n",
            "Epoch 11294/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1747.6435 - val_loss: 1402.7283\n",
            "Epoch 11295/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1474.8435 - val_loss: 1376.5272\n",
            "Epoch 11296/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1537.6872 - val_loss: 1413.2854\n",
            "Epoch 11297/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1425.4226 - val_loss: 1341.5342\n",
            "Epoch 11298/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1334.3328 - val_loss: 1493.6727\n",
            "Epoch 11299/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1629.2292 - val_loss: 1282.2394\n",
            "Epoch 11300/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1388.1393 - val_loss: 1250.2102\n",
            "Epoch 11301/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1151.0480 - val_loss: 1206.5265\n",
            "Epoch 11302/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1174.7329 - val_loss: 1185.2151\n",
            "Epoch 11303/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1027.1824 - val_loss: 1150.1322\n",
            "Epoch 11304/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1184.2650 - val_loss: 1145.0774\n",
            "Epoch 11305/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1117.8801 - val_loss: 1124.5355\n",
            "Epoch 11306/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1141.0259 - val_loss: 1124.0334\n",
            "Epoch 11307/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1257.5495 - val_loss: 1120.2513\n",
            "Epoch 11308/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1299.2208 - val_loss: 1104.0605\n",
            "Epoch 11309/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1178.3661 - val_loss: 1098.5759\n",
            "Epoch 11310/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 997.6534 - val_loss: 1099.4059\n",
            "Epoch 11311/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1124.9538 - val_loss: 1104.5031\n",
            "Epoch 11312/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1038.5868 - val_loss: 1112.9323\n",
            "Epoch 11313/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1217.0620 - val_loss: 1131.5345\n",
            "Epoch 11314/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1143.1576 - val_loss: 1125.1287\n",
            "Epoch 11315/12000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1247.5248 - val_loss: 1117.7568\n",
            "Epoch 11316/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1010.6584 - val_loss: 1127.8384\n",
            "Epoch 11317/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1060.0481 - val_loss: 1152.6279\n",
            "Epoch 11318/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1195.2424 - val_loss: 1175.7565\n",
            "Epoch 11319/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1264.0489 - val_loss: 1185.9208\n",
            "Epoch 11320/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1188.1182 - val_loss: 1183.3018\n",
            "Epoch 11321/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1177.2531 - val_loss: 1185.7666\n",
            "Epoch 11322/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1147.5473 - val_loss: 1170.2074\n",
            "Epoch 11323/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1135.4571 - val_loss: 1155.2374\n",
            "Epoch 11324/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1256.0117 - val_loss: 1164.8235\n",
            "Epoch 11325/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1072.4628 - val_loss: 1159.7560\n",
            "Epoch 11326/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1103.9079 - val_loss: 1149.7716\n",
            "Epoch 11327/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1148.6312 - val_loss: 1142.9354\n",
            "Epoch 11328/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1133.2339 - val_loss: 1148.5615\n",
            "Epoch 11329/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1410.3617 - val_loss: 1508.1578\n",
            "Epoch 11330/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1284.6258 - val_loss: 1178.4694\n",
            "Epoch 11331/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1155.3243 - val_loss: 1195.3809\n",
            "Epoch 11332/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1205.7586 - val_loss: 1419.2045\n",
            "Epoch 11333/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1682.8212 - val_loss: 1392.0596\n",
            "Epoch 11334/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1308.4242 - val_loss: 1614.7239\n",
            "Epoch 11335/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1311.7620 - val_loss: 1554.1698\n",
            "Epoch 11336/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1548.6362 - val_loss: 1489.7119\n",
            "Epoch 11337/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1416.9628 - val_loss: 1388.0466\n",
            "Epoch 11338/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1472.0415 - val_loss: 1403.1515\n",
            "Epoch 11339/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1470.6602 - val_loss: 1786.0170\n",
            "Epoch 11340/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1595.4988 - val_loss: 1586.2330\n",
            "Epoch 11341/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1570.0357 - val_loss: 1509.4105\n",
            "Epoch 11342/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1497.9736 - val_loss: 1537.4172\n",
            "Epoch 11343/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1565.5023 - val_loss: 1519.2574\n",
            "Epoch 11344/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1582.8600 - val_loss: 1495.7496\n",
            "Epoch 11345/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1375.8590 - val_loss: 1478.4991\n",
            "Epoch 11346/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1546.2161 - val_loss: 1461.7067\n",
            "Epoch 11347/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1408.9981 - val_loss: 1478.4993\n",
            "Epoch 11348/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1617.0159 - val_loss: 1470.4672\n",
            "Epoch 11349/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1457.7100 - val_loss: 1463.6047\n",
            "Epoch 11350/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1556.9547 - val_loss: 1452.0061\n",
            "Epoch 11351/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1641.9637 - val_loss: 1443.7609\n",
            "Epoch 11352/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1388.8728 - val_loss: 1467.1158\n",
            "Epoch 11353/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1594.4993 - val_loss: 1356.6313\n",
            "Epoch 11354/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1478.5092 - val_loss: 1420.3239\n",
            "Epoch 11355/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1429.9106 - val_loss: 1413.4504\n",
            "Epoch 11356/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1320.3170 - val_loss: 1385.5526\n",
            "Epoch 11357/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1458.4648 - val_loss: 1353.6364\n",
            "Epoch 11358/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1267.7150 - val_loss: 1473.6982\n",
            "Epoch 11359/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1544.5765 - val_loss: 1409.0453\n",
            "Epoch 11360/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1434.3043 - val_loss: 1406.9274\n",
            "Epoch 11361/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1464.1867 - val_loss: 1396.4692\n",
            "Epoch 11362/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1461.3167 - val_loss: 1417.6084\n",
            "Epoch 11363/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1265.5223 - val_loss: 1460.5582\n",
            "Epoch 11364/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1304.7672 - val_loss: 1439.1038\n",
            "Epoch 11365/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1275.9294 - val_loss: 1417.3037\n",
            "Epoch 11366/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1484.4079 - val_loss: 1416.9828\n",
            "Epoch 11367/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1370.9027 - val_loss: 1419.9989\n",
            "Epoch 11368/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1439.2159 - val_loss: 1408.5793\n",
            "Epoch 11369/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1470.1896 - val_loss: 1381.1295\n",
            "Epoch 11370/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1433.3298 - val_loss: 1370.9973\n",
            "Epoch 11371/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1597.5886 - val_loss: 1368.7546\n",
            "Epoch 11372/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1426.0629 - val_loss: 1321.3204\n",
            "Epoch 11373/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1323.2969 - val_loss: 1336.9749\n",
            "Epoch 11374/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1320.3539 - val_loss: 1328.7972\n",
            "Epoch 11375/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1321.4742 - val_loss: 1315.8445\n",
            "Epoch 11376/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1437.3420 - val_loss: 1311.4200\n",
            "Epoch 11377/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1198.5060 - val_loss: 1297.7230\n",
            "Epoch 11378/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1403.6232 - val_loss: 1286.4326\n",
            "Epoch 11379/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1163.9060 - val_loss: 1262.5270\n",
            "Epoch 11380/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1128.1237 - val_loss: 1258.3320\n",
            "Epoch 11381/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1356.2054 - val_loss: 1265.5604\n",
            "Epoch 11382/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1340.1681 - val_loss: 1239.2271\n",
            "Epoch 11383/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1176.7231 - val_loss: 1227.1915\n",
            "Epoch 11384/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1281.2333 - val_loss: 1261.8881\n",
            "Epoch 11385/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1257.9020 - val_loss: 1221.8282\n",
            "Epoch 11386/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1324.1296 - val_loss: 1256.6763\n",
            "Epoch 11387/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1101.7904 - val_loss: 1375.8688\n",
            "Epoch 11388/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1400.5550 - val_loss: 1411.9272\n",
            "Epoch 11389/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1301.6320 - val_loss: 1415.4200\n",
            "Epoch 11390/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1398.7087 - val_loss: 1458.9844\n",
            "Epoch 11391/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1312.0807 - val_loss: 1404.2043\n",
            "Epoch 11392/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1281.1748 - val_loss: 1288.2604\n",
            "Epoch 11393/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1152.0333 - val_loss: 1265.5859\n",
            "Epoch 11394/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1288.0001 - val_loss: 1239.8425\n",
            "Epoch 11395/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1447.3026 - val_loss: 1238.9512\n",
            "Epoch 11396/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1272.3759 - val_loss: 1231.7961\n",
            "Epoch 11397/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1266.7683 - val_loss: 1218.1312\n",
            "Epoch 11398/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1282.2337 - val_loss: 1217.4456\n",
            "Epoch 11399/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1314.3812 - val_loss: 1210.2705\n",
            "Epoch 11400/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1104.4143 - val_loss: 1193.5598\n",
            "Epoch 11401/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1304.9545 - val_loss: 1185.1086\n",
            "Epoch 11402/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1115.3943 - val_loss: 1172.4589\n",
            "Epoch 11403/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1190.5016 - val_loss: 1206.2128\n",
            "Epoch 11404/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1180.4108 - val_loss: 1205.9938\n",
            "Epoch 11405/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1246.0300 - val_loss: 1183.3379\n",
            "Epoch 11406/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1149.8536 - val_loss: 1182.0936\n",
            "Epoch 11407/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1094.0150 - val_loss: 1178.0101\n",
            "Epoch 11408/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1222.1416 - val_loss: 1167.4601\n",
            "Epoch 11409/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1235.7461 - val_loss: 1178.4005\n",
            "Epoch 11410/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1375.0997 - val_loss: 1176.2152\n",
            "Epoch 11411/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1228.5202 - val_loss: 1183.8070\n",
            "Epoch 11412/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1197.6037 - val_loss: 1172.3539\n",
            "Epoch 11413/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1225.9666 - val_loss: 1187.7957\n",
            "Epoch 11414/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1181.4421 - val_loss: 1244.8188\n",
            "Epoch 11415/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1117.0850 - val_loss: 1332.3478\n",
            "Epoch 11416/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1207.8963 - val_loss: 1354.2725\n",
            "Epoch 11417/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1436.9077 - val_loss: 1279.5453\n",
            "Epoch 11418/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1215.8644 - val_loss: 1253.5808\n",
            "Epoch 11419/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1203.2099 - val_loss: 1249.3287\n",
            "Epoch 11420/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1289.1361 - val_loss: 1240.9916\n",
            "Epoch 11421/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1215.7470 - val_loss: 1228.1512\n",
            "Epoch 11422/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1341.9573 - val_loss: 1198.1899\n",
            "Epoch 11423/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1254.9208 - val_loss: 1198.6854\n",
            "Epoch 11424/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1074.2384 - val_loss: 1215.5510\n",
            "Epoch 11425/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1239.1813 - val_loss: 1209.3982\n",
            "Epoch 11426/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1135.2141 - val_loss: 1201.0253\n",
            "Epoch 11427/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1214.3741 - val_loss: 1171.3717\n",
            "Epoch 11428/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1203.9392 - val_loss: 1242.8925\n",
            "Epoch 11429/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1314.0760 - val_loss: 1241.8651\n",
            "Epoch 11430/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1132.2354 - val_loss: 1223.0989\n",
            "Epoch 11431/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1146.3567 - val_loss: 1207.6859\n",
            "Epoch 11432/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1244.3521 - val_loss: 1185.5060\n",
            "Epoch 11433/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1246.5263 - val_loss: 1204.2985\n",
            "Epoch 11434/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1040.9128 - val_loss: 1165.5382\n",
            "Epoch 11435/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1179.5325 - val_loss: 1182.2938\n",
            "Epoch 11436/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1075.3852 - val_loss: 1168.7920\n",
            "Epoch 11437/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1315.0142 - val_loss: 1150.8845\n",
            "Epoch 11438/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1340.7694 - val_loss: 1150.0126\n",
            "Epoch 11439/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1135.7620 - val_loss: 1137.6345\n",
            "Epoch 11440/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1103.4965 - val_loss: 1147.7512\n",
            "Epoch 11441/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1123.3380 - val_loss: 1485.6598\n",
            "Epoch 11442/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1617.1228 - val_loss: 1725.4261\n",
            "Epoch 11443/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1480.1825 - val_loss: 1698.7108\n",
            "Epoch 11444/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1752.7389 - val_loss: 1462.6469\n",
            "Epoch 11445/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1327.6123 - val_loss: 1459.2388\n",
            "Epoch 11446/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1449.7968 - val_loss: 1381.8900\n",
            "Epoch 11447/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1430.5408 - val_loss: 1266.8177\n",
            "Epoch 11448/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1227.2047 - val_loss: 1316.8165\n",
            "Epoch 11449/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1275.2196 - val_loss: 1300.4612\n",
            "Epoch 11450/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1345.0171 - val_loss: 1292.1837\n",
            "Epoch 11451/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1393.1978 - val_loss: 1282.5260\n",
            "Epoch 11452/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1225.7359 - val_loss: 1270.9869\n",
            "Epoch 11453/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1237.2399 - val_loss: 1329.2386\n",
            "Epoch 11454/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1306.1729 - val_loss: 1354.7477\n",
            "Epoch 11455/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1444.6234 - val_loss: 1325.2507\n",
            "Epoch 11456/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1539.5826 - val_loss: 1261.5789\n",
            "Epoch 11457/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1162.1072 - val_loss: 1337.2109\n",
            "Epoch 11458/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1342.0297 - val_loss: 1281.6740\n",
            "Epoch 11459/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1174.4894 - val_loss: 1280.4706\n",
            "Epoch 11460/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1209.8276 - val_loss: 1330.1775\n",
            "Epoch 11461/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1232.1246 - val_loss: 1312.6464\n",
            "Epoch 11462/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1399.7830 - val_loss: 1297.8754\n",
            "Epoch 11463/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1307.4158 - val_loss: 1222.2621\n",
            "Epoch 11464/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1281.6633 - val_loss: 1216.6418\n",
            "Epoch 11465/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1247.4465 - val_loss: 1211.7079\n",
            "Epoch 11466/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1080.1202 - val_loss: 1196.8812\n",
            "Epoch 11467/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1088.8719 - val_loss: 1200.7930\n",
            "Epoch 11468/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1055.4094 - val_loss: 1175.0966\n",
            "Epoch 11469/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1193.8017 - val_loss: 1136.7490\n",
            "Epoch 11470/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1155.3712 - val_loss: 1130.5289\n",
            "Epoch 11471/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1122.8304 - val_loss: 1130.6895\n",
            "Epoch 11472/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1104.6244 - val_loss: 1129.1433\n",
            "Epoch 11473/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1157.2651 - val_loss: 1125.0432\n",
            "Epoch 11474/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1113.1021 - val_loss: 1146.3691\n",
            "Epoch 11475/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1225.4685 - val_loss: 1231.0901\n",
            "Epoch 11476/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1291.4763 - val_loss: 1273.3289\n",
            "Epoch 11477/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1269.9510 - val_loss: 1221.3610\n",
            "Epoch 11478/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1443.3556 - val_loss: 1219.3142\n",
            "Epoch 11479/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1297.4374 - val_loss: 1463.0500\n",
            "Epoch 11480/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1543.5359 - val_loss: 1678.0299\n",
            "Epoch 11481/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1705.7764 - val_loss: 1681.1835\n",
            "Epoch 11482/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1743.9156 - val_loss: 1923.4418\n",
            "Epoch 11483/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1870.3453 - val_loss: 2070.3403\n",
            "Epoch 11484/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2239.8192 - val_loss: 1969.2289\n",
            "Epoch 11485/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1878.8739 - val_loss: 1551.9224\n",
            "Epoch 11486/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1483.4771 - val_loss: 1426.9374\n",
            "Epoch 11487/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1470.1139 - val_loss: 1361.8143\n",
            "Epoch 11488/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1345.5709 - val_loss: 1446.2847\n",
            "Epoch 11489/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1417.0460 - val_loss: 1412.1912\n",
            "Epoch 11490/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1191.0017 - val_loss: 1370.3060\n",
            "Epoch 11491/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1399.3409 - val_loss: 1379.0292\n",
            "Epoch 11492/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1450.1025 - val_loss: 1363.4137\n",
            "Epoch 11493/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1337.9357 - val_loss: 1430.5846\n",
            "Epoch 11494/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1430.3979 - val_loss: 1421.9834\n",
            "Epoch 11495/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1521.7121 - val_loss: 1453.8091\n",
            "Epoch 11496/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1423.3328 - val_loss: 1464.0258\n",
            "Epoch 11497/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1407.8034 - val_loss: 1373.6493\n",
            "Epoch 11498/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1218.9045 - val_loss: 1360.3329\n",
            "Epoch 11499/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1341.0070 - val_loss: 1395.8010\n",
            "Epoch 11500/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1421.8678 - val_loss: 1420.3829\n",
            "Epoch 11501/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1434.3299 - val_loss: 1492.4475\n",
            "Epoch 11502/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1529.1713 - val_loss: 1407.3011\n",
            "Epoch 11503/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1374.8538 - val_loss: 1473.8578\n",
            "Epoch 11504/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1414.7934 - val_loss: 1415.2968\n",
            "Epoch 11505/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1271.5126 - val_loss: 1362.2540\n",
            "Epoch 11506/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1402.7549 - val_loss: 1372.1930\n",
            "Epoch 11507/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1466.5896 - val_loss: 1416.4625\n",
            "Epoch 11508/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1495.9090 - val_loss: 1450.3516\n",
            "Epoch 11509/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1410.1145 - val_loss: 1384.4869\n",
            "Epoch 11510/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1302.5752 - val_loss: 1383.1853\n",
            "Epoch 11511/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1404.9089 - val_loss: 1333.6011\n",
            "Epoch 11512/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1352.9606 - val_loss: 1352.8971\n",
            "Epoch 11513/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1424.8101 - val_loss: 1323.9131\n",
            "Epoch 11514/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1391.0098 - val_loss: 1310.5183\n",
            "Epoch 11515/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1146.8189 - val_loss: 1277.2135\n",
            "Epoch 11516/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1296.0036 - val_loss: 1300.7277\n",
            "Epoch 11517/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1166.6526 - val_loss: 1285.7937\n",
            "Epoch 11518/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1140.1422 - val_loss: 1290.9427\n",
            "Epoch 11519/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1159.9044 - val_loss: 1294.2030\n",
            "Epoch 11520/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1295.5646 - val_loss: 1282.3480\n",
            "Epoch 11521/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1299.4623 - val_loss: 1192.4889\n",
            "Epoch 11522/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1314.5324 - val_loss: 1216.3383\n",
            "Epoch 11523/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1131.7179 - val_loss: 1215.9547\n",
            "Epoch 11524/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1207.9481 - val_loss: 1160.8180\n",
            "Epoch 11525/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1133.7188 - val_loss: 1137.8428\n",
            "Epoch 11526/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1226.1121 - val_loss: 1195.9465\n",
            "Epoch 11527/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1318.8906 - val_loss: 1214.4366\n",
            "Epoch 11528/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1121.7142 - val_loss: 1188.9136\n",
            "Epoch 11529/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1159.7294 - val_loss: 1170.0988\n",
            "Epoch 11530/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1242.4633 - val_loss: 1187.9860\n",
            "Epoch 11531/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1255.8518 - val_loss: 1182.0719\n",
            "Epoch 11532/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1313.1399 - val_loss: 1162.8220\n",
            "Epoch 11533/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1099.9411 - val_loss: 1150.3943\n",
            "Epoch 11534/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1217.5889 - val_loss: 1148.3452\n",
            "Epoch 11535/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1229.8196 - val_loss: 1161.6273\n",
            "Epoch 11536/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1083.5239 - val_loss: 1148.0844\n",
            "Epoch 11537/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1110.2996 - val_loss: 1137.1816\n",
            "Epoch 11538/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1116.2411 - val_loss: 1129.6937\n",
            "Epoch 11539/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1366.4514 - val_loss: 1131.5029\n",
            "Epoch 11540/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1141.0380 - val_loss: 1130.3011\n",
            "Epoch 11541/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1130.6155 - val_loss: 1109.6290\n",
            "Epoch 11542/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 987.6414 - val_loss: 1095.2179\n",
            "Epoch 11543/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1030.7786 - val_loss: 1082.5518\n",
            "Epoch 11544/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1073.0454 - val_loss: 1077.3481\n",
            "Epoch 11545/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1099.7408 - val_loss: 1071.0692\n",
            "Epoch 11546/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 985.9312 - val_loss: 1072.2548\n",
            "Epoch 11547/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1039.5219 - val_loss: 1068.3447\n",
            "Epoch 11548/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1041.5381 - val_loss: 1060.8221\n",
            "Epoch 11549/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1127.0439 - val_loss: 1075.0018\n",
            "Epoch 11550/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1061.0838 - val_loss: 1059.4871\n",
            "Epoch 11551/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1035.5840 - val_loss: 1068.0096\n",
            "Epoch 11552/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1107.3588 - val_loss: 1101.2766\n",
            "Epoch 11553/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1069.0847 - val_loss: 1101.2578\n",
            "Epoch 11554/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1042.2678 - val_loss: 1090.7155\n",
            "Epoch 11555/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1074.9577 - val_loss: 1090.4014\n",
            "Epoch 11556/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1172.1828 - val_loss: 1084.1359\n",
            "Epoch 11557/12000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1154.9609 - val_loss: 1082.0475\n",
            "Epoch 11558/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1151.5402 - val_loss: 1056.3295\n",
            "Epoch 11559/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 992.0966 - val_loss: 1051.0812\n",
            "Epoch 11560/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 962.7591 - val_loss: 1046.9299\n",
            "Epoch 11561/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1144.1732 - val_loss: 1047.4486\n",
            "Epoch 11562/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1043.0587 - val_loss: 1045.9061\n",
            "Epoch 11563/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1015.9334 - val_loss: 1042.6116\n",
            "Epoch 11564/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 942.3888 - val_loss: 1041.3734\n",
            "Epoch 11565/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 979.2760 - val_loss: 1034.4109\n",
            "Epoch 11566/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1096.5208 - val_loss: 1024.4618\n",
            "Epoch 11567/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1079.5122 - val_loss: 1032.9939\n",
            "Epoch 11568/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 974.3900 - val_loss: 1031.2460\n",
            "Epoch 11569/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 995.8946 - val_loss: 1028.2675\n",
            "Epoch 11570/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1273.7004 - val_loss: 1038.0048\n",
            "Epoch 11571/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1209.9664 - val_loss: 1038.8822\n",
            "Epoch 11572/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1075.5328 - val_loss: 1038.1938\n",
            "Epoch 11573/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1089.8520 - val_loss: 1045.5731\n",
            "Epoch 11574/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1190.8828 - val_loss: 1044.5659\n",
            "Epoch 11575/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1212.4038 - val_loss: 1039.2479\n",
            "Epoch 11576/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1048.8994 - val_loss: 1035.5872\n",
            "Epoch 11577/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 978.8234 - val_loss: 1039.8527\n",
            "Epoch 11578/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1160.8491 - val_loss: 1043.0569\n",
            "Epoch 11579/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 980.1187 - val_loss: 1034.7628\n",
            "Epoch 11580/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1069.6820 - val_loss: 1049.6272\n",
            "Epoch 11581/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1048.4747 - val_loss: 1044.6089\n",
            "Epoch 11582/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1121.4598 - val_loss: 1044.1199\n",
            "Epoch 11583/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1056.2344 - val_loss: 1030.4413\n",
            "Epoch 11584/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 871.2805 - val_loss: 1035.0100\n",
            "Epoch 11585/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1317.5079 - val_loss: 1033.8314\n",
            "Epoch 11586/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1066.5355 - val_loss: 1035.3571\n",
            "Epoch 11587/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1035.7326 - val_loss: 1033.6239\n",
            "Epoch 11588/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1126.7316 - val_loss: 1027.1058\n",
            "Epoch 11589/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 940.7020 - val_loss: 1029.9489\n",
            "Epoch 11590/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1142.5957 - val_loss: 1051.1578\n",
            "Epoch 11591/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 995.1620 - val_loss: 1042.6290\n",
            "Epoch 11592/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1053.3101 - val_loss: 1058.5688\n",
            "Epoch 11593/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1036.8730 - val_loss: 1063.5837\n",
            "Epoch 11594/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1062.1576 - val_loss: 1050.9856\n",
            "Epoch 11595/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1022.9892 - val_loss: 1075.8964\n",
            "Epoch 11596/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1072.8218 - val_loss: 1050.7603\n",
            "Epoch 11597/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1243.6034 - val_loss: 1356.4379\n",
            "Epoch 11598/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1098.1970 - val_loss: 1206.0867\n",
            "Epoch 11599/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1361.1494 - val_loss: 1165.1234\n",
            "Epoch 11600/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1110.1262 - val_loss: 1133.5548\n",
            "Epoch 11601/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1062.7153 - val_loss: 1129.3339\n",
            "Epoch 11602/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1229.8119 - val_loss: 1294.8857\n",
            "Epoch 11603/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1318.1002 - val_loss: 1386.0374\n",
            "Epoch 11604/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1430.1948 - val_loss: 1555.2092\n",
            "Epoch 11605/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1622.5610 - val_loss: 1729.2799\n",
            "Epoch 11606/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1914.0796 - val_loss: 2350.7056\n",
            "Epoch 11607/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2516.1205 - val_loss: 2003.9514\n",
            "Epoch 11608/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1955.1897 - val_loss: 1812.2665\n",
            "Epoch 11609/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1810.5954 - val_loss: 1648.7456\n",
            "Epoch 11610/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1558.1987 - val_loss: 1545.6809\n",
            "Epoch 11611/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1521.0834 - val_loss: 1506.9625\n",
            "Epoch 11612/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1568.6624 - val_loss: 1487.4003\n",
            "Epoch 11613/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1636.4111 - val_loss: 1540.3594\n",
            "Epoch 11614/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1441.8121 - val_loss: 1592.7496\n",
            "Epoch 11615/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1463.5303 - val_loss: 1566.2084\n",
            "Epoch 11616/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1679.6813 - val_loss: 1506.5043\n",
            "Epoch 11617/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1550.9947 - val_loss: 1511.0925\n",
            "Epoch 11618/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1541.6544 - val_loss: 1496.1571\n",
            "Epoch 11619/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1296.2549 - val_loss: 1500.0265\n",
            "Epoch 11620/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1412.6455 - val_loss: 1514.1167\n",
            "Epoch 11621/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1503.7237 - val_loss: 1504.6041\n",
            "Epoch 11622/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1632.0764 - val_loss: 1496.7300\n",
            "Epoch 11623/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1469.1914 - val_loss: 1517.2595\n",
            "Epoch 11624/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1665.6227 - val_loss: 1560.4869\n",
            "Epoch 11625/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1623.7056 - val_loss: 1524.9153\n",
            "Epoch 11626/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1518.1349 - val_loss: 1480.0317\n",
            "Epoch 11627/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1562.6462 - val_loss: 1512.2301\n",
            "Epoch 11628/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1658.6776 - val_loss: 1611.1970\n",
            "Epoch 11629/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1595.7356 - val_loss: 1607.0695\n",
            "Epoch 11630/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1600.6715 - val_loss: 1455.5287\n",
            "Epoch 11631/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1539.7268 - val_loss: 1439.9530\n",
            "Epoch 11632/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1717.5066 - val_loss: 1511.6050\n",
            "Epoch 11633/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1347.2701 - val_loss: 1525.2167\n",
            "Epoch 11634/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1662.5592 - val_loss: 1534.8690\n",
            "Epoch 11635/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1744.8614 - val_loss: 1526.5778\n",
            "Epoch 11636/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1676.7271 - val_loss: 1567.0604\n",
            "Epoch 11637/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1577.2837 - val_loss: 1398.9185\n",
            "Epoch 11638/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1602.8428 - val_loss: 1417.3525\n",
            "Epoch 11639/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1324.7644 - val_loss: 1385.0540\n",
            "Epoch 11640/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1457.0967 - val_loss: 1363.8079\n",
            "Epoch 11641/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1243.2024 - val_loss: 1452.1364\n",
            "Epoch 11642/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1589.1418 - val_loss: 1757.7856\n",
            "Epoch 11643/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1760.0214 - val_loss: 1842.0430\n",
            "Epoch 11644/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1817.4959 - val_loss: 1656.2814\n",
            "Epoch 11645/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1659.5363 - val_loss: 1600.0981\n",
            "Epoch 11646/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1478.4784 - val_loss: 1695.3745\n",
            "Epoch 11647/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1620.4110 - val_loss: 1667.6233\n",
            "Epoch 11648/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1806.8349 - val_loss: 1696.0780\n",
            "Epoch 11649/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1614.7465 - val_loss: 1633.8464\n",
            "Epoch 11650/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1746.5908 - val_loss: 1676.8528\n",
            "Epoch 11651/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1731.4424 - val_loss: 1600.7203\n",
            "Epoch 11652/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1405.1397 - val_loss: 1557.4912\n",
            "Epoch 11653/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1634.4397 - val_loss: 1584.6416\n",
            "Epoch 11654/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1568.9295 - val_loss: 1563.7795\n",
            "Epoch 11655/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1556.2112 - val_loss: 1505.3475\n",
            "Epoch 11656/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1461.7049 - val_loss: 1543.5916\n",
            "Epoch 11657/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1650.5336 - val_loss: 1514.5978\n",
            "Epoch 11658/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1370.9754 - val_loss: 1473.6611\n",
            "Epoch 11659/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1282.5967 - val_loss: 1531.6433\n",
            "Epoch 11660/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1682.0024 - val_loss: 1499.9921\n",
            "Epoch 11661/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1499.6631 - val_loss: 1467.7756\n",
            "Epoch 11662/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1492.3223 - val_loss: 1459.5487\n",
            "Epoch 11663/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1546.7398 - val_loss: 1517.4304\n",
            "Epoch 11664/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1537.3041 - val_loss: 1816.5822\n",
            "Epoch 11665/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1903.6035 - val_loss: 1843.3944\n",
            "Epoch 11666/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2002.8192 - val_loss: 1773.5333\n",
            "Epoch 11667/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1731.3847 - val_loss: 1618.1885\n",
            "Epoch 11668/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1501.9241 - val_loss: 1768.1882\n",
            "Epoch 11669/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1659.8507 - val_loss: 1727.2140\n",
            "Epoch 11670/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1720.8387 - val_loss: 1697.9501\n",
            "Epoch 11671/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1678.1941 - val_loss: 1680.5079\n",
            "Epoch 11672/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1861.2329 - val_loss: 1820.7722\n",
            "Epoch 11673/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1698.7984 - val_loss: 1726.8658\n",
            "Epoch 11674/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1779.6672 - val_loss: 1688.7935\n",
            "Epoch 11675/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1965.0643 - val_loss: 1695.0760\n",
            "Epoch 11676/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1803.7809 - val_loss: 1630.4661\n",
            "Epoch 11677/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1764.1975 - val_loss: 1597.7322\n",
            "Epoch 11678/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1953.4274 - val_loss: 1605.7725\n",
            "Epoch 11679/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1453.3242 - val_loss: 1715.7244\n",
            "Epoch 11680/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1944.7807 - val_loss: 1748.0356\n",
            "Epoch 11681/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1769.6834 - val_loss: 1686.7349\n",
            "Epoch 11682/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1651.5185 - val_loss: 1628.4265\n",
            "Epoch 11683/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1805.7748 - val_loss: 1632.8489\n",
            "Epoch 11684/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1623.5451 - val_loss: 1577.3212\n",
            "Epoch 11685/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1395.2175 - val_loss: 1691.0891\n",
            "Epoch 11686/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1805.2194 - val_loss: 1701.5591\n",
            "Epoch 11687/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1682.8649 - val_loss: 1704.8906\n",
            "Epoch 11688/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1593.5275 - val_loss: 1720.1383\n",
            "Epoch 11689/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1899.2772 - val_loss: 1908.2357\n",
            "Epoch 11690/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1784.5616 - val_loss: 1679.9480\n",
            "Epoch 11691/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1704.0640 - val_loss: 1645.7789\n",
            "Epoch 11692/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1621.4229 - val_loss: 1850.1796\n",
            "Epoch 11693/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1737.0704 - val_loss: 1670.1711\n",
            "Epoch 11694/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1532.4853 - val_loss: 1624.5455\n",
            "Epoch 11695/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1519.2936 - val_loss: 1832.8196\n",
            "Epoch 11696/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1922.1562 - val_loss: 2022.1016\n",
            "Epoch 11697/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1894.4223 - val_loss: 1982.2167\n",
            "Epoch 11698/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1822.8442 - val_loss: 1896.7438\n",
            "Epoch 11699/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1836.6287 - val_loss: 1911.8293\n",
            "Epoch 11700/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2004.2526 - val_loss: 1856.7716\n",
            "Epoch 11701/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1801.6776 - val_loss: 1912.6729\n",
            "Epoch 11702/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1811.8121 - val_loss: 1911.2675\n",
            "Epoch 11703/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1659.8420 - val_loss: 1764.4326\n",
            "Epoch 11704/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1635.9322 - val_loss: 1697.0850\n",
            "Epoch 11705/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1699.1677 - val_loss: 1703.3806\n",
            "Epoch 11706/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1801.6263 - val_loss: 1815.7922\n",
            "Epoch 11707/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1793.8755 - val_loss: 1775.5715\n",
            "Epoch 11708/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1852.4253 - val_loss: 1770.6212\n",
            "Epoch 11709/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2139.6123 - val_loss: 1776.5978\n",
            "Epoch 11710/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1736.7543 - val_loss: 1698.3890\n",
            "Epoch 11711/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1663.4074 - val_loss: 1743.6941\n",
            "Epoch 11712/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1763.3169 - val_loss: 1812.7128\n",
            "Epoch 11713/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1866.2351 - val_loss: 1832.9709\n",
            "Epoch 11714/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1781.3966 - val_loss: 1801.5281\n",
            "Epoch 11715/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1552.9341 - val_loss: 1798.5459\n",
            "Epoch 11716/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1811.2041 - val_loss: 1692.0082\n",
            "Epoch 11717/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1771.4707 - val_loss: 1702.6746\n",
            "Epoch 11718/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1688.3867 - val_loss: 1644.3486\n",
            "Epoch 11719/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1804.7877 - val_loss: 1643.0243\n",
            "Epoch 11720/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1511.2787 - val_loss: 1609.7123\n",
            "Epoch 11721/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1511.0304 - val_loss: 1596.5331\n",
            "Epoch 11722/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1475.5562 - val_loss: 1561.7065\n",
            "Epoch 11723/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1598.0467 - val_loss: 1587.2617\n",
            "Epoch 11724/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1423.0715 - val_loss: 1541.8361\n",
            "Epoch 11725/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1772.2018 - val_loss: 1574.4008\n",
            "Epoch 11726/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1476.5987 - val_loss: 1504.5903\n",
            "Epoch 11727/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1508.7620 - val_loss: 1590.2214\n",
            "Epoch 11728/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1541.2231 - val_loss: 1583.8180\n",
            "Epoch 11729/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1748.1572 - val_loss: 1591.0460\n",
            "Epoch 11730/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1499.1918 - val_loss: 1557.9792\n",
            "Epoch 11731/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1626.3738 - val_loss: 1586.4111\n",
            "Epoch 11732/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1371.2868 - val_loss: 1574.3755\n",
            "Epoch 11733/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1704.1882 - val_loss: 1550.5273\n",
            "Epoch 11734/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1504.1778 - val_loss: 1574.6891\n",
            "Epoch 11735/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1694.1337 - val_loss: 1588.6471\n",
            "Epoch 11736/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1605.1405 - val_loss: 1624.5756\n",
            "Epoch 11737/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1500.1300 - val_loss: 1734.5010\n",
            "Epoch 11738/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1630.7115 - val_loss: 1704.3616\n",
            "Epoch 11739/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1836.8028 - val_loss: 1845.4554\n",
            "Epoch 11740/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2080.7385 - val_loss: 1757.9867\n",
            "Epoch 11741/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1688.2238 - val_loss: 1762.8289\n",
            "Epoch 11742/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1759.9464 - val_loss: 1787.2351\n",
            "Epoch 11743/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1659.8783 - val_loss: 1794.2211\n",
            "Epoch 11744/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1570.5316 - val_loss: 1737.8723\n",
            "Epoch 11745/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1586.6669 - val_loss: 1786.5374\n",
            "Epoch 11746/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1596.5752 - val_loss: 1756.5546\n",
            "Epoch 11747/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1942.3867 - val_loss: 1768.2742\n",
            "Epoch 11748/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1533.7700 - val_loss: 1784.9340\n",
            "Epoch 11749/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1793.9955 - val_loss: 1781.0975\n",
            "Epoch 11750/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1388.8626 - val_loss: 1743.4098\n",
            "Epoch 11751/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1560.1204 - val_loss: 1628.7072\n",
            "Epoch 11752/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1496.1619 - val_loss: 1701.6631\n",
            "Epoch 11753/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1785.8417 - val_loss: 1836.5305\n",
            "Epoch 11754/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1760.3180 - val_loss: 1761.2769\n",
            "Epoch 11755/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1818.3803 - val_loss: 1633.6862\n",
            "Epoch 11756/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1750.3419 - val_loss: 1787.6671\n",
            "Epoch 11757/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1632.7588 - val_loss: 1908.2922\n",
            "Epoch 11758/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2043.4320 - val_loss: 1858.4409\n",
            "Epoch 11759/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1970.5763 - val_loss: 2006.6094\n",
            "Epoch 11760/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2415.3649 - val_loss: 1765.5710\n",
            "Epoch 11761/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1865.7485 - val_loss: 1687.7727\n",
            "Epoch 11762/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1667.0365 - val_loss: 2196.6196\n",
            "Epoch 11763/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2074.9409 - val_loss: 2894.7073\n",
            "Epoch 11764/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2562.5970 - val_loss: 2521.3765\n",
            "Epoch 11765/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 2678.6741 - val_loss: 2914.0530\n",
            "Epoch 11766/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2924.0031 - val_loss: 2991.0701\n",
            "Epoch 11767/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 2946.9885 - val_loss: 2813.1685\n",
            "Epoch 11768/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2959.7557 - val_loss: 2494.7976\n",
            "Epoch 11769/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2334.7746 - val_loss: 2275.2939\n",
            "Epoch 11770/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2329.4099 - val_loss: 2177.4875\n",
            "Epoch 11771/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2376.3830 - val_loss: 2238.3560\n",
            "Epoch 11772/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2090.1351 - val_loss: 2273.0371\n",
            "Epoch 11773/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1923.6845 - val_loss: 2130.3416\n",
            "Epoch 11774/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2363.1992 - val_loss: 2045.4987\n",
            "Epoch 11775/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1845.1123 - val_loss: 1953.8439\n",
            "Epoch 11776/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1802.9713 - val_loss: 1862.3779\n",
            "Epoch 11777/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2076.7720 - val_loss: 2049.2571\n",
            "Epoch 11778/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 2003.8619 - val_loss: 2009.1736\n",
            "Epoch 11779/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1590.1081 - val_loss: 1824.8190\n",
            "Epoch 11780/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1874.1711 - val_loss: 1780.7972\n",
            "Epoch 11781/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1717.0171 - val_loss: 1738.6575\n",
            "Epoch 11782/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1740.5936 - val_loss: 1760.3497\n",
            "Epoch 11783/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1564.1781 - val_loss: 1743.4413\n",
            "Epoch 11784/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1576.4891 - val_loss: 1878.8702\n",
            "Epoch 11785/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1805.5699 - val_loss: 1807.9977\n",
            "Epoch 11786/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1867.2269 - val_loss: 1754.0299\n",
            "Epoch 11787/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1565.2044 - val_loss: 1701.5895\n",
            "Epoch 11788/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1795.3304 - val_loss: 1727.3051\n",
            "Epoch 11789/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1965.6730 - val_loss: 1655.7045\n",
            "Epoch 11790/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1545.6217 - val_loss: 1545.4843\n",
            "Epoch 11791/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1584.8655 - val_loss: 1546.9683\n",
            "Epoch 11792/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1364.9280 - val_loss: 1550.8451\n",
            "Epoch 11793/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1492.6614 - val_loss: 1488.7708\n",
            "Epoch 11794/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1396.9639 - val_loss: 1503.0898\n",
            "Epoch 11795/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1792.0649 - val_loss: 1548.4167\n",
            "Epoch 11796/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1832.7941 - val_loss: 1544.2089\n",
            "Epoch 11797/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1709.0483 - val_loss: 1605.7627\n",
            "Epoch 11798/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1779.6164 - val_loss: 1780.0973\n",
            "Epoch 11799/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1860.0583 - val_loss: 1813.7577\n",
            "Epoch 11800/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1735.5935 - val_loss: 1844.4133\n",
            "Epoch 11801/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1779.0012 - val_loss: 1871.6644\n",
            "Epoch 11802/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1693.7549 - val_loss: 1836.6809\n",
            "Epoch 11803/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1896.0156 - val_loss: 1819.7614\n",
            "Epoch 11804/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1833.3710 - val_loss: 1612.3064\n",
            "Epoch 11805/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1426.6558 - val_loss: 1587.5919\n",
            "Epoch 11806/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1526.1892 - val_loss: 1568.8536\n",
            "Epoch 11807/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1420.8639 - val_loss: 1587.6589\n",
            "Epoch 11808/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1563.3611 - val_loss: 1584.2639\n",
            "Epoch 11809/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1610.5781 - val_loss: 1653.5890\n",
            "Epoch 11810/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1609.4504 - val_loss: 1630.3180\n",
            "Epoch 11811/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1622.5364 - val_loss: 1730.7648\n",
            "Epoch 11812/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1941.6462 - val_loss: 1547.7900\n",
            "Epoch 11813/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1470.0728 - val_loss: 1498.3065\n",
            "Epoch 11814/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1319.8754 - val_loss: 1425.7982\n",
            "Epoch 11815/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1442.7397 - val_loss: 1481.8619\n",
            "Epoch 11816/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1619.6219 - val_loss: 1461.3993\n",
            "Epoch 11817/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1391.5356 - val_loss: 1520.9979\n",
            "Epoch 11818/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1668.8658 - val_loss: 1479.1025\n",
            "Epoch 11819/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1624.1327 - val_loss: 1480.8220\n",
            "Epoch 11820/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1504.5905 - val_loss: 1417.2611\n",
            "Epoch 11821/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1426.4230 - val_loss: 1524.4298\n",
            "Epoch 11822/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1623.9134 - val_loss: 1554.9570\n",
            "Epoch 11823/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1417.4163 - val_loss: 1489.0331\n",
            "Epoch 11824/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1490.4983 - val_loss: 1456.8514\n",
            "Epoch 11825/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1442.6223 - val_loss: 1440.3646\n",
            "Epoch 11826/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1555.6256 - val_loss: 1529.4346\n",
            "Epoch 11827/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1480.2901 - val_loss: 1593.0027\n",
            "Epoch 11828/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1711.8281 - val_loss: 1704.3575\n",
            "Epoch 11829/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1851.4267 - val_loss: 1675.1234\n",
            "Epoch 11830/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1780.4799 - val_loss: 1697.2322\n",
            "Epoch 11831/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1689.0951 - val_loss: 1749.3801\n",
            "Epoch 11832/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1990.4290 - val_loss: 1687.3169\n",
            "Epoch 11833/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1561.8280 - val_loss: 1656.7716\n",
            "Epoch 11834/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1701.5557 - val_loss: 1736.3551\n",
            "Epoch 11835/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1778.6497 - val_loss: 1736.5374\n",
            "Epoch 11836/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1871.0867 - val_loss: 1684.5984\n",
            "Epoch 11837/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1735.8602 - val_loss: 1616.3142\n",
            "Epoch 11838/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1550.8348 - val_loss: 1614.6115\n",
            "Epoch 11839/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1653.0704 - val_loss: 1583.7920\n",
            "Epoch 11840/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1612.8484 - val_loss: 1584.4666\n",
            "Epoch 11841/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1552.5136 - val_loss: 1602.0421\n",
            "Epoch 11842/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1530.5858 - val_loss: 1552.1006\n",
            "Epoch 11843/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1435.1190 - val_loss: 1607.1429\n",
            "Epoch 11844/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1575.7421 - val_loss: 1570.6053\n",
            "Epoch 11845/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1510.5506 - val_loss: 1607.7218\n",
            "Epoch 11846/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1447.5879 - val_loss: 1744.0959\n",
            "Epoch 11847/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1878.9591 - val_loss: 1732.9023\n",
            "Epoch 11848/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1515.9566 - val_loss: 1659.8811\n",
            "Epoch 11849/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1702.3474 - val_loss: 1702.5599\n",
            "Epoch 11850/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1596.4862 - val_loss: 1644.4015\n",
            "Epoch 11851/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1611.1821 - val_loss: 1643.6368\n",
            "Epoch 11852/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1733.4885 - val_loss: 1797.2695\n",
            "Epoch 11853/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1694.8986 - val_loss: 1633.3550\n",
            "Epoch 11854/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1567.9965 - val_loss: 2041.8441\n",
            "Epoch 11855/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1998.1237 - val_loss: 1903.6453\n",
            "Epoch 11856/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1964.4736 - val_loss: 1857.7488\n",
            "Epoch 11857/12000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1895.7897 - val_loss: 1801.0275\n",
            "Epoch 11858/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 2013.6627 - val_loss: 1829.6375\n",
            "Epoch 11859/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1980.7667 - val_loss: 1725.5577\n",
            "Epoch 11860/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1618.5787 - val_loss: 1736.2878\n",
            "Epoch 11861/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 2086.2572 - val_loss: 1817.6578\n",
            "Epoch 11862/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1825.4188 - val_loss: 1772.1555\n",
            "Epoch 11863/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1594.7003 - val_loss: 1738.9630\n",
            "Epoch 11864/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1545.2782 - val_loss: 1728.6921\n",
            "Epoch 11865/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1636.9026 - val_loss: 1711.6927\n",
            "Epoch 11866/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1609.9251 - val_loss: 1644.7677\n",
            "Epoch 11867/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1604.4904 - val_loss: 1665.2839\n",
            "Epoch 11868/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1515.2846 - val_loss: 1654.0621\n",
            "Epoch 11869/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1712.1854 - val_loss: 1761.6854\n",
            "Epoch 11870/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1600.2560 - val_loss: 1756.0172\n",
            "Epoch 11871/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1781.4289 - val_loss: 1716.0087\n",
            "Epoch 11872/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1901.0201 - val_loss: 1773.3339\n",
            "Epoch 11873/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1705.8262 - val_loss: 1827.8356\n",
            "Epoch 11874/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1917.1020 - val_loss: 1773.3688\n",
            "Epoch 11875/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1760.4303 - val_loss: 1768.4630\n",
            "Epoch 11876/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1699.0875 - val_loss: 1717.6243\n",
            "Epoch 11877/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1660.6509 - val_loss: 1707.9045\n",
            "Epoch 11878/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1680.3410 - val_loss: 1784.7133\n",
            "Epoch 11879/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1744.7667 - val_loss: 1736.3506\n",
            "Epoch 11880/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1703.1629 - val_loss: 1647.0825\n",
            "Epoch 11881/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1675.2864 - val_loss: 1606.8680\n",
            "Epoch 11882/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1527.2419 - val_loss: 1743.0408\n",
            "Epoch 11883/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1840.8667 - val_loss: 1708.0017\n",
            "Epoch 11884/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1786.3716 - val_loss: 1782.0299\n",
            "Epoch 11885/12000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 1892.4777 - val_loss: 1655.1863\n",
            "Epoch 11886/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1596.1768 - val_loss: 1559.5439\n",
            "Epoch 11887/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1510.6739 - val_loss: 1648.9055\n",
            "Epoch 11888/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1797.1142 - val_loss: 1714.2794\n",
            "Epoch 11889/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1660.7287 - val_loss: 1683.9332\n",
            "Epoch 11890/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1678.8205 - val_loss: 1688.3148\n",
            "Epoch 11891/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1777.1373 - val_loss: 1689.1321\n",
            "Epoch 11892/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1546.1970 - val_loss: 1702.6338\n",
            "Epoch 11893/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1695.1511 - val_loss: 1598.8373\n",
            "Epoch 11894/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1667.6788 - val_loss: 1597.7496\n",
            "Epoch 11895/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1561.5117 - val_loss: 1708.5297\n",
            "Epoch 11896/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1573.4706 - val_loss: 1640.6707\n",
            "Epoch 11897/12000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1725.2491 - val_loss: 1594.0624\n",
            "Epoch 11898/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1518.0469 - val_loss: 1581.8372\n",
            "Epoch 11899/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1542.7254 - val_loss: 1563.6323\n",
            "Epoch 11900/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1576.2845 - val_loss: 1503.1750\n",
            "Epoch 11901/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1454.7878 - val_loss: 1477.4032\n",
            "Epoch 11902/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1347.5428 - val_loss: 1480.0330\n",
            "Epoch 11903/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1466.9428 - val_loss: 1475.9258\n",
            "Epoch 11904/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1503.9960 - val_loss: 1466.1090\n",
            "Epoch 11905/12000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1371.4677 - val_loss: 1488.9388\n",
            "Epoch 11906/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1457.2003 - val_loss: 1482.3446\n",
            "Epoch 11907/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1465.7912 - val_loss: 1683.4971\n",
            "Epoch 11908/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1788.9428 - val_loss: 1763.3539\n",
            "Epoch 11909/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1863.8631 - val_loss: 1735.9285\n",
            "Epoch 11910/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1704.9489 - val_loss: 1754.6335\n",
            "Epoch 11911/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1688.0290 - val_loss: 1646.9027\n",
            "Epoch 11912/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1478.9045 - val_loss: 1592.6742\n",
            "Epoch 11913/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1704.2935 - val_loss: 1584.1790\n",
            "Epoch 11914/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1381.6905 - val_loss: 1532.1383\n",
            "Epoch 11915/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1515.9639 - val_loss: 1523.8507\n",
            "Epoch 11916/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1603.2340 - val_loss: 1529.1268\n",
            "Epoch 11917/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1443.6741 - val_loss: 1444.4626\n",
            "Epoch 11918/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1616.4154 - val_loss: 1445.9847\n",
            "Epoch 11919/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1479.0145 - val_loss: 1476.8572\n",
            "Epoch 11920/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1474.2611 - val_loss: 1471.3749\n",
            "Epoch 11921/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1536.5686 - val_loss: 1458.2296\n",
            "Epoch 11922/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1415.3027 - val_loss: 1445.2479\n",
            "Epoch 11923/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1407.5415 - val_loss: 1437.1093\n",
            "Epoch 11924/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1450.2478 - val_loss: 1436.5602\n",
            "Epoch 11925/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1474.1111 - val_loss: 1683.9783\n",
            "Epoch 11926/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1546.7693 - val_loss: 1721.8176\n",
            "Epoch 11927/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1790.5367 - val_loss: 1650.5038\n",
            "Epoch 11928/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1577.5040 - val_loss: 1662.2921\n",
            "Epoch 11929/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1600.2871 - val_loss: 1674.2030\n",
            "Epoch 11930/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1538.5964 - val_loss: 1719.1472\n",
            "Epoch 11931/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1651.1965 - val_loss: 1710.6428\n",
            "Epoch 11932/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1818.7815 - val_loss: 1728.8656\n",
            "Epoch 11933/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1989.2848 - val_loss: 1742.6809\n",
            "Epoch 11934/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1791.4443 - val_loss: 1826.2833\n",
            "Epoch 11935/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1772.4549 - val_loss: 1809.0642\n",
            "Epoch 11936/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1771.7250 - val_loss: 1808.6458\n",
            "Epoch 11937/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1954.4259 - val_loss: 1754.1104\n",
            "Epoch 11938/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1558.7410 - val_loss: 1732.0026\n",
            "Epoch 11939/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1665.8216 - val_loss: 1730.5222\n",
            "Epoch 11940/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1701.3524 - val_loss: 1676.7935\n",
            "Epoch 11941/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1763.8379 - val_loss: 1593.3232\n",
            "Epoch 11942/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1758.2785 - val_loss: 1453.1354\n",
            "Epoch 11943/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1343.0775 - val_loss: 1404.1130\n",
            "Epoch 11944/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1488.7867 - val_loss: 1390.2046\n",
            "Epoch 11945/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1522.6757 - val_loss: 1408.9711\n",
            "Epoch 11946/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1402.4357 - val_loss: 1405.0272\n",
            "Epoch 11947/12000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1325.7227 - val_loss: 1441.7804\n",
            "Epoch 11948/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1229.5194 - val_loss: 1379.4825\n",
            "Epoch 11949/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1277.3441 - val_loss: 1391.6143\n",
            "Epoch 11950/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1396.3162 - val_loss: 1360.0801\n",
            "Epoch 11951/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1276.8051 - val_loss: 1405.2510\n",
            "Epoch 11952/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1541.8906 - val_loss: 1447.1729\n",
            "Epoch 11953/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1616.7929 - val_loss: 1503.8329\n",
            "Epoch 11954/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1439.5840 - val_loss: 1462.7432\n",
            "Epoch 11955/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1304.4082 - val_loss: 1437.9862\n",
            "Epoch 11956/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1322.5887 - val_loss: 1450.0591\n",
            "Epoch 11957/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1386.1403 - val_loss: 1462.4800\n",
            "Epoch 11958/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1425.5624 - val_loss: 1480.7960\n",
            "Epoch 11959/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1437.6535 - val_loss: 1442.4341\n",
            "Epoch 11960/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1547.9065 - val_loss: 1426.8341\n",
            "Epoch 11961/12000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1585.2776 - val_loss: 1514.4388\n",
            "Epoch 11962/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1478.0835 - val_loss: 1481.8789\n",
            "Epoch 11963/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1551.1831 - val_loss: 1468.8920\n",
            "Epoch 11964/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1413.8997 - val_loss: 1442.6290\n",
            "Epoch 11965/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1458.9955 - val_loss: 1417.4493\n",
            "Epoch 11966/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1392.1016 - val_loss: 1379.9772\n",
            "Epoch 11967/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1447.7984 - val_loss: 1354.5410\n",
            "Epoch 11968/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1359.7516 - val_loss: 1359.6522\n",
            "Epoch 11969/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1354.5658 - val_loss: 1366.6498\n",
            "Epoch 11970/12000\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 1229.6592 - val_loss: 1433.2739\n",
            "Epoch 11971/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1331.6219 - val_loss: 1432.7323\n",
            "Epoch 11972/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1442.9489 - val_loss: 1391.1583\n",
            "Epoch 11973/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1340.9486 - val_loss: 1391.8322\n",
            "Epoch 11974/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1392.3146 - val_loss: 1381.5093\n",
            "Epoch 11975/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1487.5249 - val_loss: 1368.9114\n",
            "Epoch 11976/12000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1392.9721 - val_loss: 1365.8899\n",
            "Epoch 11977/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1334.7814 - val_loss: 1353.1815\n",
            "Epoch 11978/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1403.3955 - val_loss: 1353.4493\n",
            "Epoch 11979/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1141.0122 - val_loss: 1346.5363\n",
            "Epoch 11980/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1232.5773 - val_loss: 1342.6648\n",
            "Epoch 11981/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1453.1618 - val_loss: 1334.7490\n",
            "Epoch 11982/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1284.1197 - val_loss: 1331.9686\n",
            "Epoch 11983/12000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1402.2139 - val_loss: 1298.5094\n",
            "Epoch 11984/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1322.7336 - val_loss: 1272.3884\n",
            "Epoch 11985/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1427.7645 - val_loss: 1302.9312\n",
            "Epoch 11986/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1354.7672 - val_loss: 1301.1199\n",
            "Epoch 11987/12000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1182.4370 - val_loss: 1304.2654\n",
            "Epoch 11988/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1318.4618 - val_loss: 1280.6539\n",
            "Epoch 11989/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1314.8385 - val_loss: 1257.5829\n",
            "Epoch 11990/12000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1317.3889 - val_loss: 1264.6598\n",
            "Epoch 11991/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1201.3619 - val_loss: 1285.7876\n",
            "Epoch 11992/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1297.1098 - val_loss: 1284.5638\n",
            "Epoch 11993/12000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1372.6744 - val_loss: 1274.9469\n",
            "Epoch 11994/12000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1253.7704 - val_loss: 1275.8955\n",
            "Epoch 11995/12000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1280.5393 - val_loss: 1274.5138\n",
            "Epoch 11996/12000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1263.2540 - val_loss: 1238.3608\n",
            "Epoch 11997/12000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1181.2142 - val_loss: 1234.3969\n",
            "Epoch 11998/12000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1168.0030 - val_loss: 1225.1207\n",
            "Epoch 11999/12000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1209.2348 - val_loss: 1216.1962\n",
            "Epoch 12000/12000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1232.7971 - val_loss: 1183.0790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMlcJAHyMHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c9281b0a-cbe2-4cb2-a69f-6feb2a56e3aa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training'])\n",
        "plt.legend(['validation'])\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st5kqsO19Q96",
        "outputId": "333d3e38-79d3-422e-e846-8bde76887934"
      },
      "source": [
        "print(min(history.history['val_loss']))\n",
        "print(history.history['val_loss'].index(min(history.history['val_loss'])))\n",
        "print()\n",
        "print(min(history.history['loss']))\n",
        "print(history.history['loss'].index(min(history.history['loss'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800.2272338867188\n",
            "1368\n",
            "\n",
            "794.69775390625\n",
            "9009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTcpQhNZYAH"
      },
      "source": [
        "#saving a model\n",
        "\n",
        "model.save(\"covid_prediction.h5\")\n",
        "!cp \"covid_prediction.h5\" \"/content/gdrive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAfI5HUVapfP",
        "outputId": "5d3d411b-7446-486e-c51b-488764c90399"
      },
      "source": [
        "#loading a model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/gdrive/My Drive/covid_prediction.h5\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "UlZ9xkvTFg3N",
        "outputId": "50bedd76-4c75-4a1c-dcad-ea85a6d2fcd5"
      },
      "source": [
        "Test_X, Test_Y = split_sequence(cases, n)\n",
        "Test_X = np.array(Test_X)\n",
        "Test_Y = np.array(Test_Y)\n",
        "Test_Y = Test_Y.reshape((Test_Y.shape[0], 1, n_features))\n",
        "Test_X = Test_X.reshape((Test_X.shape[0], Test_X.shape[1], n_features))\n",
        "Test_Y = Test_Y.reshape((Test_Y.shape[0], 1, n_features))\n",
        "prediction = model.predict(Test_X)\n",
        "\n",
        "close_test = Test_Y.reshape((-1))\n",
        "prediction = prediction.reshape((-1))\n",
        "\n",
        "absolute_errors = np.abs(np.subtract(close_test, prediction))\n",
        "relative_errors = np.divide(absolute_errors, close_test) * 100\n",
        "\n",
        "trace2 = go.Scatter(\n",
        "    x = [i for i in range (0, len(Test_Y))],\n",
        "    y = prediction,\n",
        "    name = 'Prediction',\n",
        "    mode='lines',\n",
        "    line=dict(width=4, color='Green')\n",
        ")\n",
        "trace3 = go.Scatter(\n",
        "    x = [i for i in range (0, len(Test_Y))],\n",
        "    y = close_test,\n",
        "    mode='markers+lines',\n",
        "    name = 'Test Data'\n",
        ")\n",
        "layout = go.Layout(\n",
        "    title = \"Covid Cases\",\n",
        "    xaxis = {'title' : \"Date\"},\n",
        "    yaxis = {'title' : \"Cases\"}\n",
        ")\n",
        "fig = go.Figure(data=[trace2, trace3], layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"60ccf37f-af8d-431a-98b2-2692275888ce\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"60ccf37f-af8d-431a-98b2-2692275888ce\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '60ccf37f-af8d-431a-98b2-2692275888ce',\n",
              "                        [{\"line\": {\"color\": \"Green\", \"width\": 4}, \"mode\": \"lines\", \"name\": \"Prediction\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462], \"y\": [19.754985809326172, 17.335975646972656, 36.109619140625, 21.25259780883789, 41.71734619140625, 61.299659729003906, 68.06541442871094, 68.10345458984375, 68.745361328125, 111.185302734375, 97.38764953613281, 102.16647338867188, 151.64883422851562, 169.64170837402344, 173.00454711914062, 202.3566436767578, 214.48446655273438, 308.3165588378906, 257.8457946777344, 232.27276611328125, 319.18975830078125, 303.6707458496094, 427.7639465332031, 412.671875, 362.4794006347656, 520.1307373046875, 363.5805969238281, 385.761474609375, 373.5903015136719, 461.1573181152344, 381.4608459472656, 381.2564392089844, 364.8565979003906, 343.3144226074219, 331.1470031738281, 406.6937561035156, 402.4573669433594, 438.4564514160156, 387.3764343261719, 464.9808654785156, 410.429931640625, 313.3685607910156, 332.0650939941406, 364.677001953125, 378.3105163574219, 354.8749084472656, 316.5225524902344, 310.40423583984375, 372.9195251464844, 428.2249450683594, 400.7232666015625, 329.44097900390625, 366.609375, 315.95123291015625, 302.84906005859375, 376.9907531738281, 310.906982421875, 349.0567932128906, 344.7395324707031, 364.36102294921875, 373.3568115234375, 342.5940856933594, 574.3016357421875, 368.2203369140625, 390.03009033203125, 386.0873718261719, 350.23602294921875, 300.1747741699219, 336.78167724609375, 381.9853210449219, 466.147705078125, 377.1936950683594, 553.2398071289062, 329.6264343261719, 408.694091796875, 465.7417297363281, 487.7320861816406, 414.5577087402344, 396.6349792480469, 379.2701721191406, 376.29461669921875, 309.5651550292969, 350.0372009277344, 325.2760925292969, 338.092529296875, 353.2198181152344, 344.285400390625, 492.48394775390625, 503.8109436035156, 604.6923217773438, 496.9771423339844, 451.2757263183594, 426.7892761230469, 458.8114929199219, 521.1371459960938, 437.5873107910156, 428.31304931640625, 379.6607666015625, 342.3229675292969, 340.2215270996094, 477.2402038574219, 486.8586730957031, 372.5877380371094, 338.1217956542969, 304.425537109375, 305.290283203125, 314.55364990234375, 317.557373046875, 300.64605712890625, 293.64776611328125, 300.8336486816406, 335.2314758300781, 338.5967712402344, 358.7618103027344, 295.6424255371094, 330.0466613769531, 286.15045166015625, 275.3295593261719, 296.94976806640625, 327.9539794921875, 270.6754150390625, 318.4023132324219, 288.64276123046875, 302.8953857421875, 295.3663024902344, 364.8650817871094, 358.3457336425781, 337.8920593261719, 352.4137878417969, 353.2435607910156, 369.5350646972656, 302.7231750488281, 354.8725891113281, 390.9413757324219, 432.7721862792969, 461.3492736816406, 538.3878784179688, 479.1716613769531, 402.3075866699219, 525.8839111328125, 514.2750244140625, 633.0082397460938, 644.82958984375, 669.5441284179688, 599.4148559570312, 545.9164428710938, 735.1892700195312, 685.6808471679688, 731.7736206054688, 716.3888549804688, 754.5921020507812, 714.3910522460938, 588.633544921875, 638.1773071289062, 697.8623046875, 751.1500854492188, 793.5732421875, 718.6686401367188, 571.65673828125, 613.0513305664062, 638.7844848632812, 727.9844970703125, 752.3696899414062, 834.0592041015625, 738.953125, 572.291748046875, 604.6434326171875, 689.583740234375, 720.8331909179688, 792.935546875, 819.6541137695312, 702.0087280273438, 524.2215576171875, 590.8651733398438, 548.0297241210938, 713.84423828125, 710.3097534179688, 543.5414428710938, 461.2268981933594, 477.0793151855469, 498.086181640625, 469.6011047363281, 529.3722534179688, 525.664306640625, 530.6575317382812, 580.7821655273438, 448.78460693359375, 427.445556640625, 529.6596069335938, 642.8530883789062, 723.2085571289062, 663.0443115234375, 986.4141235351562, 939.5435180664062, 884.0344848632812, 866.4373168945312, 1004.612548828125, 1196.924072265625, 1457.5157470703125, 1400.8265380859375, 1389.256591796875, 1351.895751953125, 1482.968505859375, 1545.642333984375, 1951.210205078125, 2254.3271484375, 2288.666748046875, 2130.658203125, 2314.525390625, 2269.5302734375, 2885.99365234375, 3844.999755859375, 4541.1064453125, 3184.859375, 4280.39111328125, 5111.8349609375, 5516.8955078125, 6630.0576171875, 7674.375, 7564.298828125, 8635.67578125, 10992.9052734375, 9319.9580078125, 10123.876953125, 10490.6630859375, 11581.4248046875, 13146.2724609375, 11950.5380859375, 13367.9658203125, 12290.18359375, 15901.404296875, 17522.333984375, 20919.537109375, 21716.01171875, 18784.814453125, 20445.837890625, 19067.75390625, 20539.58203125, 22435.314453125, 25662.5, 23957.451171875, 24333.525390625, 23970.400390625, 22347.75390625, 26271.876953125, 25265.1953125, 22557.033203125, 23250.376953125, 19420.349609375, 21074.49609375, 19471.767578125, 17997.919921875, 18501.36328125, 22045.875, 21124.74609375, 21500.30078125, 19898.93359375, 20702.482421875, 27514.001953125, 18754.794921875, 19104.763671875, 19921.884765625, 17213.865234375, 13171.2724609375, 10737.9462890625, 12960.0166015625, 16129.8837890625, 13471.9677734375, 8245.9521484375, 10005.5732421875, 13888.056640625, 11141.1337890625, 8597.1884765625, 13817.63671875, 12135.068359375, 14722.37890625, 9728.3515625, 8881.759765625, 6854.6552734375, 8948.6806640625, 11872.0556640625, 12286.4248046875, 10112.4140625, 9498.7958984375, 7257.8857421875, 6363.931640625, 7634.17529296875, 14214.4228515625, 11394.154296875, 10080.4990234375, 7934.064453125, 5460.8251953125, 3779.9169921875, 6459.01953125, 14525.8076171875, 11884.9423828125, 10009.5595703125, 8929.3134765625, 6310.6328125, 6363.5283203125, 11636.31640625, 12537.65625, 11266.111328125, 8742.2578125, 8297.1787109375, 6958.9130859375, 6166.1708984375, 7959.7529296875, 9052.6650390625, 8564.11328125, 7124.8134765625, 6140.0498046875, 4586.056640625, 4057.716796875, 6470.73095703125, 8343.25390625, 6568.82373046875, 6573.2392578125, 4537.0166015625, 4478.154296875, 3294.4404296875, 6581.06494140625, 7381.61474609375, 6239.26513671875, 5417.2587890625, 5232.970703125, 4352.77880859375, 3803.62451171875, 4611.88427734375, 7811.42236328125, 6322.7314453125, 5345.05029296875, 4912.1337890625, 4287.99951171875, 3684.02880859375, 4436.77587890625, 7788.57861328125, 6452.83203125, 5435.69189453125, 5256.49658203125, 4718.20458984375, 3827.59716796875, 4952.7333984375, 8456.7666015625, 8968.9345703125, 9257.328125, 6957.4794921875, 5737.9169921875, 4660.88671875, 5520.84228515625, 11882.2744140625, 11523.1904296875, 9989.1064453125, 12001.7236328125, 8406.8466796875, 6540.9755859375, 7730.6416015625, 15041.1708984375, 14535.6728515625, 15483.4091796875, 13345.333984375, 10430.517578125, 10591.13671875, 9499.048828125, 16697.240234375, 19440.26171875, 18066.8828125, 17093.341796875, 13384.62890625, 11464.3271484375, 13542.4287109375, 24187.595703125, 26813.732421875, 24599.865234375, 20247.169921875, 22292.255859375, 16465.830078125, 16266.2099609375, 28623.513671875, 31114.537109375, 31960.087890625, 30258.37109375, 27844.052734375, 18179.23828125, 20718.0859375, 27741.294921875, 35006.53515625, 29634.69921875, 31979.759765625, 23341.453125, 15221.9736328125, 13030.3173828125, 30883.369140625, 25416.1875, 24000.423828125, 21280.259765625, 17881.208984375, 13007.1494140625, 22012.51171875, 25172.51953125, 20659.978515625, 15417.0224609375, 18846.876953125, 10892.6572265625, 8676.0810546875, 6181.4755859375, 18820.3203125, 15751.3740234375, 14426.4951171875, 8096.7724609375, 5960.5166015625, 5221.2294921875, 9818.5517578125, 7346.0166015625, 11398.4306640625, 8356.9716796875, 4544.68359375, 3885.6669921875, 4549.2265625, 6382.22119140625, 7012.9794921875, 6458.42333984375, 7117.4560546875, 4419.458984375, 3343.96826171875, 2561.4169921875, 4522.408203125, 5821.3251953125, 4451.58642578125, 3282.315185546875, 3224.23828125, 2193.7529296875, 2163.178955078125, 2142.46435546875, 2129.510498046875, 1819.1904296875, 2466.747802734375, 1123.0712890625, 869.6362915039062, 872.4671020507812, 1688.12060546875, 1204.735107421875, 1617.8294677734375, 1354.52099609375, 670.1165161132812, 458.1379699707031, 561.7230834960938, 934.2980346679688, 627.0257568359375, 989.3486328125, 786.6638793945312, 558.9984130859375, 223.21636962890625, 482.47491455078125, 493.5073547363281, 423.4375, 300.9648132324219, 411.33343505859375, 369.9954528808594, 271.3277282714844, 312.2431335449219, 336.82928466796875, 351.3811340332031]}, {\"mode\": \"markers+lines\", \"name\": \"Test Data\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462], \"y\": [20, 17, 36, 21, 52, 61, 49, 68, 70, 111, 98, 116, 152, 150, 170, 168, 249, 224, 193, 256, 243, 392, 437, 244, 475, 311, 435, 357, 370, 380, 401, 318, 260, 268, 380, 336, 457, 334, 515, 306, 263, 313, 342, 381, 381, 344, 285, 316, 422, 300, 228, 270, 318, 313, 406, 311, 303, 337, 288, 345, 330, 556, 322, 411, 401, 241, 272, 356, 382, 471, 403, 472, 316, 361, 341, 443, 396, 352, 333, 412, 219, 374, 236, 292, 361, 362, 576, 575, 599, 400, 282, 359, 376, 440, 375, 396, 407, 450, 314, 352, 309, 311, 296, 300, 294, 298, 276, 319, 193, 247, 239, 382, 371, 259, 314, 231, 205, 257, 277, 262, 265, 305, 370, 299, 267, 264, 333, 353, 339, 358, 279, 399, 380, 418, 458, 584, 443, 337, 502, 512, 615, 657, 658, 548, 575, 680, 640, 726, 809, 843, 624, 619, 551, 715, 811, 825, 778, 594, 595, 597, 735, 767, 903, 900, 581, 548, 763, 729, 887, 791, 759, 631, 502, 550, 595, 612, 691, 567, 437, 302, 400, 421, 506, 594, 603, 502, 377, 605, 600, 837, 757, 1002, 910, 748, 711, 974, 1136, 1587, 1584, 1350, 1306, 1326, 1552, 1967, 2292, 2367, 1934, 2006, 2236, 3003, 4280, 4739, 5300, 4178, 4394, 5068, 6526, 8099, 7705, 9622, 8536, 7482, 9291, 10040, 12107, 13632, 13628, 11742, 10241, 16300, 18820, 20156, 21629, 21897, 17171, 15578, 19364, 24692, 27143, 27086, 27875, 24785, 21713, 25454, 25221, 22683, 24051, 25571, 21854, 20816, 19152, 19883, 23975, 22464, 24213, 17856, 15002, 32733, 15356, 16690, 17304, 15177, 11482, 5736, 9113, 13823, 14863, 13236, 12427, 9176, 4421, 8310, 12166, 13750, 13105, 11499, 8976, 4896, 6874, 12455, 11953, 11010, 11246, 8590, 4633, 7192, 12358, 13115, 9081, 4878, 3842, 3211, 7624, 12780, 13464, 10896, 7006, 5782, 4385, 7596, 14220, 12119, 8763, 10744, 9133, 4863, 5394, 9126, 9436, 7979, 7292, 5970, 3332, 4890, 6943, 7008, 6693, 6304, 4566, 2674, 4603, 6790, 7153, 6145, 5864, 4711, 2504, 4326, 6801, 6495, 6053, 5966, 4725, 2431, 3999, 6960, 7013, 6378, 6585, 5334, 2542, 5176, 8699, 9074, 8772, 8509, 7040, 3891, 6304, 12147, 12143, 11536, 12097, 10101, 4786, 7936, 15698, 15253, 15831, 14855, 13569, 6169, 9953, 17277, 21111, 18873, 21063, 17272, 10895, 14394, 25053, 27274, 25996, 26456, 21850, 14579, 16740, 30802, 34150, 35145, 31759, 29266, 16973, 20862, 32891, 35253, 30541, 28073, 22958, 9921, 8246, 14908, 27890, 28499, 24892, 21733, 12016, 13203, 21266, 21126, 17846, 15786, 12151, 7302, 9244, 13922, 12763, 10866, 9510, 7224, 3467, 5711, 8893, 8426, 6789, 6475, 4616, 2523, 2296, 3899, 6427, 6047, 4771, 3856, 2031, 3097, 3948, 3694, 3289, 2897, 2169, 1111, 1727, 2348, 2087, 1678, 1517, 1075, 559, 1000, 1267, 1227, 946, 775, 579, 333, 588, 659, 572, 317, 415, 310, 195, 532, 428, 382, 341, 238, 226, 140, 215, 238, 218]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Covid Cases\"}, \"xaxis\": {\"title\": {\"text\": \"Date\"}}, \"yaxis\": {\"title\": {\"text\": \"Cases\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('60ccf37f-af8d-431a-98b2-2692275888ce');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooUlmXTzEDPZ",
        "outputId": "081aa128-232e-4d9b-80f8-806b8d47d7d3"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "370"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SB61ErudFyu",
        "outputId": "0e248341-c666-4167-d6a3-7b7795ef3bf9"
      },
      "source": [
        "Test_Y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOL9XdBIdIMl",
        "outputId": "47aff103-030e-4a32-cddd-bb438745a16c"
      },
      "source": [
        "prediction[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.66411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkM4Jt9-6ssT",
        "outputId": "0a4946e1-33ce-4ee6-e35f-4700eb7eed10"
      },
      "source": [
        "# The median of absolute errors\n",
        "print(\"Mediana błedu bezwzględnego wynosi: \" + str(np.median(absolute_errors)))\n",
        "print(\"Najwieksza pomyłka wynosi blisko: \"+ str(int(np.ceil(max(relative_errors)))) + \" % i jest dla argumentu o wartości: \" + str(Test_Y[np.argmax(relative_errors)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mediana błedu bezwzględnego wynosi: 184.0625\n",
            "Najwieksza pomyłka wynosi blisko: 215 % i jest dla argumentu o wartości: [[4421]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqAnI6LoVAn_",
        "outputId": "e54e89a2-7ae0-4097-d54c-ac1119ccb938"
      },
      "source": [
        "np.argmax(relative_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO6Cq23g805i",
        "outputId": "ef1e2d0e-1d22-4501-801a-2cc2a48ad9f2"
      },
      "source": [
        "# Relative errors [%]\n",
        "np.round(relative_errors, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.2300e+00, 1.9800e+00, 3.0000e-01, 1.2000e+00, 4.9000e-01,\n",
              "       1.5000e-01, 1.7900e+00, 1.7000e-01, 6.2000e-01, 2.3000e-01,\n",
              "       1.7700e+00, 2.0450e+01, 3.7640e+01, 3.3600e+01, 9.2700e+00,\n",
              "       3.1350e+01, 2.2530e+01, 2.3690e+01, 6.7240e+01, 1.6420e+01,\n",
              "       9.7000e-01, 4.8700e+00, 1.9890e+01, 4.0330e+01, 2.8100e+01,\n",
              "       1.2860e+01, 2.1040e+01, 1.1930e+01, 3.1270e+01, 1.2000e-01,\n",
              "       2.9000e+00, 4.2800e+00, 7.1000e-01, 3.1600e+00, 1.1060e+01,\n",
              "       1.7700e+00, 1.1630e+01, 4.2740e+01, 2.2020e+01, 1.5290e+01,\n",
              "       9.4000e-01, 2.5410e+01, 2.1220e+01, 2.6100e+00, 3.5800e+00,\n",
              "       1.9700e+01, 5.6100e+00, 1.3140e+01, 3.8380e+01, 7.8350e+01,\n",
              "       1.0410e+01, 2.7400e+00, 6.0200e+01, 2.8760e+01, 1.5680e+01,\n",
              "       1.5670e+01, 2.0090e+01, 7.5080e+01, 5.1300e+00, 2.3160e+01,\n",
              "       1.9110e+01, 7.9400e+00, 7.1820e+01, 1.7230e+01, 4.8320e+01,\n",
              "       1.1400e+01, 2.4300e+00, 4.0230e+01, 1.5890e+01, 5.1170e+01,\n",
              "       7.6230e+01, 2.5700e+01, 1.3510e+01, 4.2800e+00, 3.8970e+01,\n",
              "       1.0500e+01, 5.2400e+00, 1.5630e+01, 9.0200e+00, 3.3500e+00,\n",
              "       5.4450e+01, 5.6550e+01, 2.5870e+01, 1.2710e+01, 3.5500e+00,\n",
              "       2.4500e+00, 1.3970e+01, 4.5000e-01, 5.5780e+01, 2.5870e+01,\n",
              "       1.2240e+01, 3.8520e+01, 5.8500e+00, 4.2880e+01, 3.9590e+01,\n",
              "       7.1300e+00, 7.2000e+00, 2.5170e+01, 2.1400e+00, 4.3900e+00,\n",
              "       2.1990e+01, 1.3000e+00, 1.0620e+01, 3.8210e+01, 4.2800e+00,\n",
              "       3.9600e+00, 1.3300e+00, 6.4700e+00, 2.1000e+01, 2.1530e+01,\n",
              "       4.2190e+01, 1.9860e+01, 2.7100e+00, 1.6380e+01, 3.6500e+00,\n",
              "       1.9720e+01, 1.4870e+01, 5.5500e+00, 9.5500e+00, 1.5410e+01,\n",
              "       6.8300e+00, 1.0740e+01, 1.3950e+01, 8.9500e+00, 2.0000e+00,\n",
              "       2.0990e+01, 3.9200e+00, 1.3090e+01, 5.0900e+00, 1.6680e+01,\n",
              "       7.3300e+00, 4.4300e+00, 2.0750e+01, 1.8730e+01, 2.4000e-01,\n",
              "       7.9900e+00, 1.1250e+01, 4.4300e+00, 7.4300e+00, 7.8900e+00,\n",
              "       1.6640e+01, 2.7900e+00, 5.5400e+00, 2.4520e+01, 4.6200e+00,\n",
              "       1.1500e+01, 1.2000e+01, 1.5690e+01, 1.9040e+01, 2.9350e+01,\n",
              "       2.3200e+01, 4.4600e+00, 3.3830e+01, 8.4000e+00, 2.5610e+01,\n",
              "       1.1040e+01, 1.1570e+01, 2.4580e+01, 7.9900e+00, 3.7600e+00,\n",
              "       4.4500e+00, 2.1420e+01, 4.7600e+00, 1.8340e+01, 6.2100e+00,\n",
              "       3.5100e+00, 2.4420e+01, 3.2570e+01, 2.3770e+01, 2.5900e+00,\n",
              "       8.6000e-01, 1.5460e+01, 1.8140e+01, 4.0000e-01, 1.1700e+00,\n",
              "       4.6920e+01, 3.1000e-01, 8.4000e-01, 1.3350e+01, 1.5040e+01,\n",
              "       3.5300e+00, 1.7800e+00, 3.0530e+01, 1.5510e+01, 3.2800e+00,\n",
              "       8.3000e-01, 3.1250e+01, 1.5300e+00, 1.6820e+01, 1.7340e+01,\n",
              "       5.2600e+00, 1.4050e+01, 1.0400e+01, 1.2200e+01, 1.1380e+01,\n",
              "       6.2100e+00, 9.0800e+00, 1.1140e+01, 1.6700e+00, 9.4800e+00,\n",
              "       1.8600e+00, 1.2750e+01, 2.0410e+01, 3.2640e+01, 3.6750e+01,\n",
              "       7.9170e+01, 1.2370e+01, 3.1260e+01, 4.9920e+01, 1.2962e+02,\n",
              "       1.7830e+01, 6.2400e+00, 8.5200e+00, 1.7800e+00, 9.0400e+00,\n",
              "       2.1414e+02, 3.4070e+01, 2.9330e+01, 4.9000e-01, 2.8030e+01,\n",
              "       8.3800e+00, 8.1410e+01, 2.8000e-01, 2.8150e+01, 6.8000e-01,\n",
              "       1.0080e+01, 1.0580e+01, 5.6660e+01, 1.1510e+01, 3.8220e+01,\n",
              "       8.3800e+00, 1.0665e+02, 1.0651e+02, 7.0070e+01, 4.9460e+01,\n",
              "       7.8900e+00, 9.0800e+00, 4.3910e+01, 1.6230e+01, 1.8170e+01,\n",
              "       3.4500e+00, 2.8560e+01, 9.1500e+00, 4.3100e+01, 1.4320e+01,\n",
              "       1.2780e+01, 7.3300e+00, 2.2900e+00, 2.8500e+00, 3.7640e+01,\n",
              "       1.7020e+01, 6.8000e+00, 1.9050e+01, 1.8600e+00, 6.3000e-01,\n",
              "       2.8430e+01, 3.2000e+00, 7.6200e+00, 1.1080e+01, 7.3830e+01,\n",
              "       1.2080e+01, 3.2190e+01, 2.0270e+01, 4.4600e+00, 1.0410e+01,\n",
              "       3.9600e+00, 7.6390e+01, 7.8800e+00, 3.6250e+01, 1.1060e+01,\n",
              "       1.7450e+01, 1.4500e+00, 8.5610e+01, 2.6050e+01, 4.3070e+01,\n",
              "       6.8000e+00, 2.2500e+00, 8.7900e+00, 1.1700e+00, 2.6060e+01,\n",
              "       5.4550e+01, 2.1500e+00, 1.1000e-01, 1.7420e+01, 1.8820e+01,\n",
              "       7.5650e+01, 1.7580e+01, 5.0750e+01, 8.1800e+00, 4.2300e+00,\n",
              "       6.9080e+01, 4.5020e+01, 3.0100e+00, 1.4220e+01, 2.2850e+01,\n",
              "       2.0350e+01, 4.5940e+01, 1.1320e+01, 3.1500e+00, 7.0200e+00,\n",
              "       7.3400e+00, 5.2910e+01, 1.6400e+00, 4.7190e+01, 1.6180e+01,\n",
              "       1.1470e+01, 6.3000e-01, 1.2860e+01, 1.4620e+01, 5.5600e+00,\n",
              "       1.3527e+02, 8.4600e+01, 1.2600e+01, 1.0730e+01, 1.0820e+01,\n",
              "       3.5800e+00, 2.0800e+00, 4.8810e+01, 1.4800e+00, 3.5100e+00,\n",
              "       1.9150e+01, 1.5770e+01, 2.3400e+00, 4.9170e+01, 6.1400e+00,\n",
              "       5.5600e+01, 4.7460e+01, 4.4960e+01, 5.1700e+01, 1.2080e+01,\n",
              "       7.1920e+01, 8.5800e+00, 1.2820e+01, 2.9070e+01, 1.5500e+00,\n",
              "       5.4010e+01, 6.3690e+01, 9.1200e+00, 6.8000e+00, 1.4610e+01,\n",
              "       6.4650e+01, 1.7290e+01, 1.4550e+01, 5.7590e+01, 1.3300e+01,\n",
              "       4.8650e+01, 2.5260e+01, 8.7500e+00, 8.4100e+00, 6.2610e+01,\n",
              "       4.4700e+00, 5.5570e+01, 1.2750e+01, 3.3240e+01, 1.8100e+00,\n",
              "       7.1020e+01, 1.5740e+01, 3.7580e+01, 4.4700e+00, 4.1780e+01,\n",
              "       9.6200e+00, 8.9560e+01, 8.0320e+01, 1.4470e+01, 9.3100e+00,\n",
              "       1.0850e+01, 7.2830e+01, 4.5230e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lppqRsrHyGaI",
        "outputId": "35af1918-bbab-4e79-8c19-5cdf366d5512"
      },
      "source": [
        "#next day covid cases prediction\n",
        "def predict_next_day(test_data):\n",
        "  test_data = test_data.reshape((1, 14, n_features))\n",
        "  return int(np.round(model.predict(test_data, verbose=1)))\n",
        "next_day = predict_next_day(np.array(cases[-15:-1]))\n",
        "print(next_day)\n",
        "print(\"Przewidywany margines błędu: [\" + str(np.round(next_day - np.median((relative_errors/100)*next_day))) + \" ; \" +  str(np.round(next_day + np.median((relative_errors/100)*next_day))) + \"]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "312\n",
            "Przewidywany margines błędu: [272.0 ; 352.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4DX3Lh2d3YN",
        "outputId": "5afd34c6-4029-4a35-e008-55fd8ceab601"
      },
      "source": [
        "np.array(cases[-14:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([659, 572, 317, 415, 310, 195, 532, 428, 382, 341, 238, 226, 140,\n",
              "       215])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ed_oBnUWJb-",
        "outputId": "8c3a0e49-2f56-405c-cb68-94ba1fae10df"
      },
      "source": [
        "np.median(absolute_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183.345703125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsHbfapDLaa5",
        "outputId": "198d8400-5e84-4d70-ad44-13ef825b4497"
      },
      "source": [
        "#coefficient of variance\n",
        "np.std(cases)/np.mean(cases) * 100 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131.9895062886979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLKkytzdHg8k",
        "outputId": "78ac8e7e-ed69-4ca6-f946-4b8920f5c13c"
      },
      "source": [
        "len(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPRke2yOEhq3",
        "outputId": "4ccd9cfa-ed3f-4c89-9816-c7233f4dea4a"
      },
      "source": [
        "len(close_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}